<!DOCTYPE html>



<html lang="en">
	<head>
		<meta charset="utf-8">	
		<meta name="viewport" content="width=device-width, initial_scale=1">
		<title>DH 2016 Abstracts</title>
		<link rel="stylesheet" href="/static/bootstrap/css/bootstrap.min.css">
		<link rel="stylesheet" href="/static/bootstrap/css/bootstrap-theme.min.css">
		<link rel="stylesheet" href="/static/css/abstracts.css">
		<script src="/static/jquery/jquery-2.2.4.min.js"></script>
		<script src="/static/bootstrap/js/bootstrap.min.js"></script>
	</head>
	<body>
		<div class="container">
			<div class="row">
				<a href="http://dh2016.adho.org"><img src="/static/images/logo_4.png" class="img-responsive"></a>
			</div>
			<div class="row">
				<ol class="breadcrumb">
					
						<li><a href="http://www.dh2016.adho.org">DH Home</a></li>
					
						<li><a href="/abstracts/">Abstracts</a></li>
					
						<li><a href="/abstracts/402">402</a></li>
					
				</ol>
			</div>
					
			
	<div class="row">
		<div class="col-lg-2">
		</div>
		<div class="col-lg-8 col-xs-12">
			<button class="btn btn-default" data-toggle="collapse" data-target="#head" style="margin-bottom: 5px;">Show info</button>
			<button class="btn btn-default" data-toggle="collapse" data-target="#cite" style="margin-bottom: 5px;">How to cite</button>
			<a href="/static/data/515.xml" class="btn btn-default" role="button" style="margin-bottom: 5px;" download="402.xml">XML Version</a>
			<div class="panel panel-success collapse" style="padding: 10px; border=none;" id="head">
				<div>
					<b>Title: </b>Authorship Verification with the Ruzicka Metric
					<br>
					<b>Authors: </b>
					Mike Kestemont, Justin Stover, Moshe Koppel, Folgert Karsdorp, Walter Daelemans
					<br>
					<b>Category: </b>Paper:Long Paper
					<br>
					<b>Keywords: </b>stylometry, authorship verification, classical antiquity, julius caesar
				</div>
			</div>
			<div class="collapse" id="cite">
				<b>Kestemont, M., Stover, J., Koppel, M., Karsdorp, F., Daelemans, W.</b> (2016). Authorship Verification with the Ruzicka Metric. In <i>Digital Humanities 2016: Conference Abstracts</i>. Jagiellonian University & Pedagogical University, Kraków, 
				
					pp. 246-249.
				
			</div>
		</div>
		<div class="col-lg-2">
		</div>
	</div>
	<div class="row">
		<div class="col-lg-2">
		</div>
		<div class="col-lg-8">	
			<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8" /><!--THIS FILE IS GENERATED FROM AN XML MASTER. DO NOT EDIT (5)--><title>Authorship Verification with the Ruzicka Metric</title><meta name="author" content="Mike Kestemont , Justin Stover , Moshe Koppel , Folgert Karsdorp , and Walter Daelemans" /><meta name="generator" content="Text Encoding Initiative Consortium XSLT stylesheets" /><meta name="DC.Title" content="Authorship Verification with the Ruzicka Metric" /><meta name="DC.Type" content="Text" /><meta name="DC.Format" content="text/html" /><link href="http://www.tei-c.org/release/xml/tei/stylesheet/tei.css" rel="stylesheet" type="text/css" /><link rel="stylesheet" media="print" type="text/css" href="http://www.tei-c.org/release/xml/tei/stylesheet/tei-print.css" /></head><body class="simple" id="TOP"><div class="stdheader autogenerated"><h1 class="maintitle">Authorship Verification with the Ruzicka Metric</h1></div><!--TEI front--><!--TEI body--><div class="DH-Heading1" id="index.xml-body.1_div.1"><h2 class="DH-Heading1"><span class="headingNumber">1. </span><span class="head">Introduction</span></h2><p>Authorship studies have long played a central role in stylometry, the popular subfield of DH in which the writing style of a text is studied as a function of its author’s identity. While authorship studies come in many flavors, a remarkable aspect is that the field continues to be dominated by so-called ‘lazy’ approaches, where the authorship of an anonymous document is determined by extrapolating the authorship of a document’s nearest neighbor. For this, researchers use metrics to calculate the distances between vector representations of documents in a higher-dimensional space, such as the well-known Manhattan city block distance. In this paper, we apply the minmax metric – originally proposed in the field of geobotanics – to the problem of authorship attribution and verification. Comparative evaluations across a variety of benchmark corpora show that this metric yields better, as well as more consistent results than previously used metrics. While intuitively simply, this metric generally displays a regularising effect across different hyperparametrizations, and allows the more effective use of larger vocabularies and sparser document vectors. In particular the metric seems much less sensitive than its main competitors to (the dimensionality of) the vector space model under which the metric is applied.</p><p>Most authorship studies in computer science are restricted to present-day document collections. In this paper, we illustrate the broader applicability of the minmax metric by applying it to a high-profile case study from Classical Antiquity. The ‘War Commentaries’ by Julius Caesar ( <span style="font-style:italic">Corpus Caesarianum</span>) refers to a group of Latin prose commentaries, describing the military campaigns of the world-renowned Roman statesman Julius Caesar (100-44 BC). While Caesar must have authored a significant portion of these commentaries himself, the exact delineation of his contribution to this important corpus remains a controversial matter. Most notably, Aulus Hirtius – one of Caesar’s most trusted generals – is sometimes believed to have contributed significantly to the corpus. Thus, the authenticity and authorship of the Caesarian corpus is a philological puzzle that has persisted for nineteen centuries. In our paper, we shed new light on this matter.</p></div><div class="DH-Heading1" id="index.xml-body.1_div.2"><h2 class="DH-Heading1"><span class="headingNumber">2. </span><span class="head">Benchmarking</span></h2><p>To properly evaluate the performance of the novel Ruzicka minmax metric, we turn to a publicly available benchmark corpora: the multilingual datasets (Dutch, English, Greek, and Spanish) used by the 2014 track on authorship verification in the PAN competition on uncovering plagiarism, authorship, and social software misuse. This track focused on the “open” task of authorship verification (as opposed to the closed set-up of authorship verification). Each dataset holds a number of “problems”, where given (a) at least one training text by a particular target author, (b) a set of similar mini-oeuvres by other authors, and (c) a new anonymous text, the task is to determine whether or not the anonymous text was written by the target author. A system must output for each of the problems a real-valued confidence score between 0.0 (“definitely not the same author”) and 1.0 (“definitely the same author”). By outputting the value of 0.5, a system can specify that it was not able to solve a problem. For each dataset, a fully independent training and test corpus are available (i.e. the problems, nor authors and texts in both sets do not overlap). Systems are eventually evaluated using two scoring metrics which were also used at the PAN: the established AUC-score, as well as the so-called c@1, a variation of the traditional accuracy-score, which gives more credit to systems that decide to leave some difficult verification problems unanswered. In the full paper, we offer a complete evaluation of all datasets: for the sake of brevity, this paper is restricted to a representative selection of results.</p><p>As common in text classification research, we vectorize the datasets into a tabular model, under a ‘bag-of-words’ assumption, which is largely ignorant of the original word order in document. Unless reported otherwise, we use character tetragrams below (Koppel et al., 2014), which yield generally acceptable results across corpora. We experiment with a number of different vector space models, the results of which can be summarized as follows:</p><ul><li class="item">plain <span style="font-style:italic">tf</span> (where simple relative frequencies are used);</li><li class="item"><span style="font-style:italic">tf-std</span>, where the <span style="font-style:italic">tf</span>-model is scaled using a feature’s standard deviation in the corpus (cf. Burrows’s Delta: Burrows, 2002);</li><li class="item"><span style="font-style:italic">tf-idf</span>, where the <span style="font-style:italic">tf</span>-model is scaled using a feature’s inverse document-frequency (to increase the weight of rare terms).</li><li class="item">…</li></ul><p>In our experiments, we focus on the Ruzicka ‘minmax’ distance metric, a still fairly novel algorithm in the field of stylometry. Just as the Euclidean or Manhattan distance, this metric will calculate a real-valued distance score between two document vector A and B as follows:</p><div class="panel panel-default panel-figure"><img class="img-responsive" src="/static/data/515/image1.png" alt="" class="inline" /></div><p>While the formula below uses the tf-model, the Ruzicka distance can of course be easily applied to other vector space models too. In our paper, we will offer a intuitive assessment of the desirable properties of this metric (e.g. in comparison to Burrows’s Delta).</p></div><div class="DH-Heading1" id="index.xml-body.1_div.3"><h2 class="DH-Heading1"><span class="headingNumber">3. </span><span class="head">General Imposters Framework (GI)</span></h2><p>In our experiments, we make amongst others use of the General Imposters Method, a bootstrapped approach to authorship verification which has recently yielded excellent results. Fitting the verifier on the train data involves two steps. First, we calculate a distance score for the anonymous document in each problem, using Algorithm 1, in order to determine whether the anonymous text was written by the target author specified in the problem:</p><div class="panel panel-default panel-figure"><img class="img-responsive" src="/static/data/515/image2.png" alt="" class="inline" /></div><p>Thus, during <span style="font-style:italic">k</span> iterations (default 100), we randomly select a sample (e.g. 50%) of all the available features in the data set. Likewise, we randomly select <span style="font-style:italic">m</span> ‘imposter’ documents (default 30), which were not written by the target author. Next, we use a <span style="font-style:italic">dist()</span> function to assess whether the anonymous text is closer to any text by the target author than to any text written by the imposters. Here, <span style="font-style:italic">dist()</span> represents a regular, geometric distance metric, such as the Manhattan or Ruzicka metric. The score returned by Algorithm 1 has been characterized as a ‘second-order’ metric, because it does not rely on the rather comparison of document vectors. The general intuition here, is that we do not just calculate how different two documents are; rather we test whether the stylistic differences between them are consistent (a) across many different feature sets, and (b) in comparison to other randomly, sampled documents.</p><p>In the second stage, we attempt to optimize the distance scores returned by Algorithm 1, in the light of the specific evaluation measures used. We apply a score shifter (Algorithm 2), which attempts to define a ‘grey zone’ where the results seem too unreliable to output a score (cf. c@1):</p><div class="panel panel-default panel-figure"><img class="img-responsive" src="/static/data/515/image3.png" alt="" class="inline" /></div><p>Through a grid search of different values between 0 and 1 for p1 and p2, we determine the settings which yield the optimal AUC x c@1 on the train data. In Fig. 1, we plot the optimal results which could be obtained on the train problems in the data set of Dutch Essays, for a specific combination of a metric and a vector space model. We ran the experiment 20 times, with increasing vocabulary truncations (e.g. the 1000 most frequent tetragrams). The results demonstrate how the Ruzicka minmax metric returns the most stable results across the experiments and clearly has a regularizing effect across different hyperparametrizations. In the full paper, we will present a complete evaluation of this system on all the PAN datasets, which in most cases yields surprisingly competitive scores on the test data, even without much corpus-specific parameter tuning. In the table below, we show the test results for Dutch essays corpus in terms of the AUC x c@1. The best combination reaches a AUC x c@1 of 0.886 on the test data (combination of <span style="font-style:italic">minmax</span> and <span style="font-style:italic">std</span>), whereas the best individual system submitted to PAN 2014 only reached 0.823 on that test dataset. Using randomized significance tests, we will additionally demonstrate the regularizing effect of the Ruzicka distance across vector spaces; its strong performance is also evident from Table 1.</p><div class="panel panel-default panel-figure"><img class="img-responsive" src="/static/data/515/image4.png" alt="Figure 1: Optimal results on train corpus" class="inline" /><div class="caption">Figure 1: Optimal results on train corpus</div></div><div class="table"><table class="rules" style="border-collapse:collapse;border-spacing:0;"><tr><td class="DH-Default"></td></tr><tr><td style="border: 1px solid black; padding: 2px;"><div class="table"><table class="rules" style="border-collapse:collapse;border-spacing:0;"><tr><td class="DH-Default">Vector Space / Metric</td><td class="DH-Default">Euclidean</td><td class="DH-Default">Manhattan</td><td class="DH-Default">Minmax</td></tr><tr><td class="DH-Default">Tf</td><td class="DH-Default">0.676</td><td class="DH-Default">0.698</td><td class="DH-Default">0.837</td></tr><tr><td class="DH-Default">Tf-Idf</td><td class="DH-Default">0.720</td><td class="DH-Default">0.750</td><td class="DH-Default">0.854</td></tr><tr><td class="DH-Default">Tf-Std</td><td class="DH-Default">0.614</td><td class="DH-Default">0.701</td><td class="DH-Default">0.886</td></tr></table></div></td></tr></table></div><p>Table 1: Final test results (AUC x C@1)</p></div><div class="DH-Heading1" id="index.xml-body.1_div.4"><h2 class="DH-Heading1"><span class="headingNumber">4. </span><span class="head">Corpus Caesarianum</span></h2><p>To further illustrate the applicability of the Ruzicka metric for authorship problems in traditional philology, we also report a stylometric case study concerning the <span style="font-style:italic">Corpus Caesarianum</span>. This <span style="font-style:italic">Corpus</span> is a group of five commentaries Caesar’s military campaigns:</p><ul><li class="item"><span style="font-style:italic">Bellum Gallicum</span>, the conquest of Gaul, 58 to 50 BC;</li><li class="item"><span style="font-style:italic">Bellum civile</span>, the civil war with Pompey, 49 to 48 BC;</li><li class="item"><span style="font-style:italic">Bellum Alexandrinum</span>, the campaigns in Egypt etc., 48 to 47 BC;</li><li class="item"><span style="font-style:italic">Bellum Africum</span>, the war in North Africa, 47 to 46 BC</li><li class="item"><span style="font-style:italic">Bellum Hispaniense</span>, a rebellion in Spain, 46 to 45 BC.</li></ul><p>The first two commentaries are mainly by Caesar himself, the only exception being the final part of the <span style="font-style:italic">Gallic War</span> (Book 8), which is by Caesar’s general Aulus Hirtius. Suetonius, writing a century and a half later, suggests that either Hirtius or another general, named Oppius, authored the remaining works. We will report experiments which broadly supports the Hirtius’s own claim that he himself compiled and edited the corpus of the non-Caesarian commentaries. Figure 2, for instance, shows a heatmap-like visualisation, in which Hirtius’s Book 8 of the <span style="font-style:italic">Gallic War</span> clearly clusters with the bulk of the <span style="font-style:italic">Alexandrian War</span> (labeled <span style="font-style:italic">x</span>).</p><div class="panel panel-default panel-figure"><img class="img-responsive" src="/static/data/515/image5.png" alt="Figure 2: Minmax-based clustermap of 1000-word samples of the &#xA;                        .&#xA;                    " class="inline" /><div class="caption">Figure 2: Minmax-based clustermap of 1000-word samples of the <span style="font-style:italic">Corpus Caesarianum</span>.</div></div></div><!--TEI back--><div class="bibliogr" id="index.xml-back.1_div.1"><h2><span class="headingNumber"> </span></h2><div class="listhead">Bibliography</div><ol class="listBibl"><li id="index.xml-bibl-d30e507"><div class="biblfree"><span style="font-weight:bold">Argamon, S.</span> (2008). Interpreting Burrows’s Delta: Geometric and probabilistic foundations. <span style="font-style:italic">Literary and Linguistic Computing</span>,<span style="font-weight:bold">23</span>: 131-47.</div></li><li id="index.xml-bibl-d30e519"><div class="biblfree"><span style="font-weight:bold">Burrows. J. F.</span> (2002). ‘Delta’: A measure of stylistic difference and a guide to likely authorship. <span style="font-style:italic">Literary and Linguistic Computing</span>,<span style="font-weight:bold">17</span>: 267-87.</div></li><li id="index.xml-bibl-d30e531"><div class="biblfree"><span style="font-weight:bold">Gaertner, J. and Hausburg, B.</span> (2013). <span style="font-style:italic">Caesar and the Bellum Alexandrinum: An Analysis of Style, Narrative Technique, and the Reception of Greek Historiography</span>. Vandenhoeck &amp; Ruprecht, Göttingen.</div></li><li id="index.xml-bibl-d30e540"><div class="biblfree"><span style="font-weight:bold">Koppel, M. and Winter, Y.</span> (2014). Determining if two documents are written by the same author. <span style="font-style:italic">Journal of the Association for Information Science and Technology</span>, <span style="font-weight:bold">65</span>: 178–87.</div></li><li id="index.xml-bibl-d30e553"><div class="biblfree"><span style="font-weight:bold">Mayer, M. </span>(2011). Caesar and the corpus caesarianum. In Marasco, G. (ed), <span style="font-style:italic">Political auto-biographies and memoirs in antiquity: A Brill companion</span>. Brill, Leiden, pp. 189-232.</div></li><li id="index.xml-bibl-d30e562"><div class="biblfree"><span style="font-weight:bold">Stamatatos, E. et al.</span> (2014). Overview of the author identification task at PAN 2014. In <span style="font-style:italic">Working Notes for CLEF 2014 Conference</span>, pp. 877-97.</div></li><li id="index.xml-bibl-d30e571"><div class="biblfree"><span style="font-weight:bold">Stover, J., Winter, Y., Koppel, M. and Kestemont, M.</span> (2016). Computational authorship verification method attributes a new work to a major 2nd century African author. <span style="font-style:italic">Journal of the American Society for Information Science and Technology</span>,<span style="font-weight:bold">66</span>: 239-42.</div></li></ol></div></body></html>
		</div>
		<div class="col-lg-2">
		</div>
	</div>


		</div>
		<script>
		$(document).ready(function(){
			$('[data-toggle="tooltip"]').tooltip();
		});
		</script>			
	</body>
</html>