<!DOCTYPE html>



<html lang="en">
	<head>
		<meta charset="utf-8">	
		<meta name="viewport" content="width=device-width, initial_scale=1">
		<title>DH 2016 Abstracts</title>
		<link rel="stylesheet" href="/static/bootstrap/css/bootstrap.min.css">
		<link rel="stylesheet" href="/static/bootstrap/css/bootstrap-theme.min.css">
		<link rel="stylesheet" href="/static/css/abstracts.css">
		<script src="/static/jquery/jquery-2.2.4.min.js"></script>
		<script src="/static/bootstrap/js/bootstrap.min.js"></script>
	</head>
	<body>
		<div class="container">
			<div class="row">
				<a href="http://dh2016.adho.org"><img src="/static/images/logo_4.png" class="img-responsive"></a>
			</div>
			<div class="row">
				<ol class="breadcrumb">
					
						<li><a href="http://www.dh2016.adho.org">DH Home</a></li>
					
						<li><a href="/abstracts/">Abstracts</a></li>
					
						<li><a href="/abstracts/144">144</a></li>
					
				</ol>
			</div>
					
			
	<div class="row">
		<div class="col-lg-2">
		</div>
		<div class="col-lg-8 col-xs-12">
			<button class="btn btn-default" data-toggle="collapse" data-target="#head" style="margin-bottom: 5px;">Show info</button>
			<button class="btn btn-default" data-toggle="collapse" data-target="#cite" style="margin-bottom: 5px;">How to cite</button>
			<a href="/static/data/67.xml" class="btn btn-default" role="button" style="margin-bottom: 5px;" download="144.xml">XML Version</a>
			<div class="panel panel-success collapse" style="padding: 10px; border=none;" id="head">
				<div>
					<b>Title: </b>Measuring the Dynamics of Lexico-Semantic Change Since the German Romantic Period
					<br>
					<b>Authors: </b>
					Johannes Hellrich, Udo Hahn
					<br>
					<b>Category: </b>Paper:Short Paper
					<br>
					<b>Keywords: </b>language change, German, romantic period, artificial neural network, word2vec
				</div>
			</div>
			<div class="collapse" id="cite">
				<b>Hellrich, J., Hahn, U.</b> (2016). Measuring the Dynamics of Lexico-Semantic Change Since the German Romantic Period. In <i>Digital Humanities 2016: Conference Abstracts</i>. Jagiellonian University & Pedagogical University, Kraków, 
				
					pp. 545-547.
				
			</div>
		</div>
		<div class="col-lg-2">
		</div>
	</div>
	<div class="row">
		<div class="col-lg-2">
		</div>
		<div class="col-lg-8">	
			<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8" /><!--THIS FILE IS GENERATED FROM AN XML MASTER. DO NOT EDIT (5)--><title>Measuring the Dynamics of Lexico-Semantic Change Since the German Romantic Period</title><meta name="author" content="Johannes Hellrich and Udo Hahn" /><meta name="generator" content="Text Encoding Initiative Consortium XSLT stylesheets" /><meta name="DC.Title" content="Measuring the Dynamics of Lexico-Semantic Change Since the German Romantic Period" /><meta name="DC.Type" content="Text" /><meta name="DC.Format" content="text/html" /><link href="http://www.tei-c.org/release/xml/tei/stylesheet/tei.css" rel="stylesheet" type="text/css" /><link rel="stylesheet" media="print" type="text/css" href="http://www.tei-c.org/release/xml/tei/stylesheet/tei-print.css" /></head><body class="simple" id="TOP"><div class="stdheader autogenerated"><h1 class="maintitle">Measuring the Dynamics of Lexico-Semantic Change Since the German Romantic Period</h1></div><!--TEI front--><!--TEI body--><div class="DH-Heading1" id="index.xml-body.1_div.1"><h2 class="DH-Heading1"><span class="headingNumber">1. </span><span class="head">Introduction</span></h2><p>The dynamics of language change over time are most evident in the lexicon component of natural languages. In particular, the gradual semantic changes words may undergo have a strong effect on the comprehension of historical texts by modern readers. Yet, efforts to automatically detect and trace this lexical evolution are scarce. Our study follows the work of Kim et al. (2014) who detected lexico-semantic changes in English texts over the 20 <sup>th</sup> century via a series of neural network language models. Our models were trained on the German part of the <span style="font-style:italic">Google Books Ngram</span> <span id="ftn1_return"><a class="notelink" title="An n-gram is a sequence of n words plus information on their frequency/probability of occurrence for a given corpus. The available version of the corp…" href="#ftn1"><sup>1</sup></a></span> corpus (Michel, et al., 2011; Lin et al., 2012), which covers over 657k German books. Such models have the particular advantage that they can be queried for the semantic similarity of arbitrary words. We tested this query option by sampling nouns from <span style="font-style:italic">Des Knaben Wunderhorn</span> (Arnim and Brentano, 1806-1808), a collection of German folk poems and songs from the German Romantic period. The choice of this volume is merely motivated by our interest in the literary period it belongs to. We detected interesting semantic changes between 1798 (often taken as the starting point for the German Romantic period) and 2009 (last year in the Google corpus).</p></div><div class="DH-Heading1" id="index.xml-body.1_div.2"><h2 class="DH-Heading1"><span class="headingNumber">2. </span><span class="head">Methods</span></h2><p>Using the specific contexts in which words appear in order to determine the (distributional) meaning of words is an old idea from linguistic structuralism (Firth, 1957). For a long time, this appealing approach could not have been seriously investigated due to the lack of suitably large corpora and adequate computational power to deal with distributional patterns of words on a larger scale. Thus, only few studies on automatically detecting semantic change have been conducted up until now, with a clear focus on the high-volume data provided by Google Books. This collection is widely popular due to its immediate availability and enormous coverage despite well-known problems stemming from both the quality of optical character recognition (OCR) and the sampling strategies used to compile it (Pechenick et al., 2015). <span id="ftn2_return"><a class="notelink" title="The Deutsches Textarchiv (DTA) can be considered as a counter example, at least, as far as the quality of OCR is concerned. Yet, DTA suffers from trem…" href="#ftn2"><sup>2</sup></a></span></p><p>Early approaches towards modeling lexico-semantic change patterns used frequency and bi-gram co-occurrence data (Gulordava and Baroni, 2011), as well as (context-based) classifiers (Mihalcea and Nastase, 2012). Riedl et al. (2014) built distributional thesauri to cluster similar word senses. All of these approaches detected lexico-semantic changes between multiple pre-determined periods. In contrast, neural network language models can be used to detect changes between arbitrary points in time, thus offering a longitudinal perspective (Kim et al., 2014; Kulkarni et al., 2015). In our experiments, we use a skip-gram model, a simplified neural network that is trained to predict plausible contexts for a given word, thereby generating (computationally less expensive) low-dimensional vector space representations of a lexicon (Mikolov et al., 2013). Despite their simplicity, neural network language models are a state-of-the-art approach, with details concerning ideal implementation solutions and training scenarios still being under dispute (Baroni et al., 2014; Schnabel et al., 2015). </p></div><div class="DH-Heading1" id="index.xml-body.1_div.3"><h2 class="DH-Heading1"><span class="headingNumber">3. </span><span class="head">Experiment</span></h2><p>We trained our models on 5-grams spanning the years 1748 to 2009, using a uniform sampling size of 1M 5-grams per year; the first 50 years were used for initialization only. Test words for high-lighting semantic change patterns were selected from <span style="font-style:italic">Des Knaben Wunderhorn</span> by identifying the ten most frequent nouns, i.e. <span style="font-style:italic">Gott </span>[‘god’], <span style="font-style:italic">Herr</span> [‘lord, mister’], <span style="font-style:italic">Liebe</span> [‘love’], <span style="font-style:italic">Tag</span> [‘day’], <span style="font-style:italic">Frau</span> [‘woman, miss’], <span style="font-style:italic">Mutter</span> [‘mother’], <span style="font-style:italic">Herz </span>[‘heart’], <span style="font-style:italic">Wein</span> [‘wine’], <span style="font-style:italic">Nacht</span> [‘night’] and <span style="font-style:italic">Mann </span>[‘man’]. For each of these ten nouns we selected the three words most similar to them (according to the cosine of their respective vector representations) during 1799 and 1808 and between 2000 and 2009, tracking how the similarity of these words developed between 1798 and 2009. The programs used for our experiments and resulting data are publically available via GitHub. <span id="ftn3_return"><a class="notelink" title="https://github.com/hellrich/dh2016" href="#ftn3"><sup>3</sup></a></span></p></div><div class="DH-Heading1" id="index.xml-body.1_div.4"><h2 class="DH-Heading1"><span class="headingNumber">4. </span><span class="head">Results</span></h2><p>The cosine similarity between the 1798 and the 2009 vector representation of the ten test words is rather high, ranging from 0.72 for <span style="font-style:italic">Mann</span> to 0.84 for <span style="font-style:italic">Wein</span>, thus showing only minor semantic changes. Manual interpretation of their most similar words revealed an interesting change for <span style="font-style:italic">Herz</span> (see Fig. 1) that is nowadays more similar to other anatomical terms (such as <span style="font-style:italic">Gehirn</span> [‘brain’], <span style="font-style:italic">Lunge</span> [‘lung’], or <span style="font-style:italic">Ohr</span> [‘ear’]) and less likely to be used metaphorically (such as indicated by <span style="font-style:italic">erschrecke</span> [‘frighten’], or <span style="font-style:italic">Gemüth</span> [archaic for ‘mind’]). As this change predates Google Books’ tendency to overrepresent scientific texts (at least for English, cf. Pechenick et al., 2015) this finding can be assumed to be an example of true lexico-semantic change. The example also demonstrates a need for a metric incorporating frequency information and normalization of input, since <span style="font-style:italic">Gemüth</span> is an archaic form for <span style="font-style:italic">Gemüt</span> non-conformant with modern German spelling conventions, although it is rated as currently similar to <span style="font-style:italic">Herz</span>.</p><p>Fig. 1 Lexical semantics of <span style="font-style:italic">Herz</span> [‘heart’] as expressed by its similarity with six other words; similarity-axis not depicting whole range of possible values (0–1)</p><div class="panel panel-default panel-figure"><img class="img-responsive" src="/static/data/67/image1.png" alt="" class="inline" /></div></div><div class="DH-Heading1" id="index.xml-body.1_div.5"><h2 class="DH-Heading1"><span class="headingNumber">5. </span><span class="head">Conclusion</span></h2><p>This research note has gathered preliminary evidence for the feasibility of corpus-driven studies into German diachronic semantics. We advocate a computational, neural network-based approach where the evolution of lexico-semantic changes is traced by similarities of distributional patterns in the context of words over time.</p><p>Looking backwards for semantic changes is, however, constrained by the quality and quantity of linguistic data available. While the primary corpus we use for determining semantic evolution patterns, the Google Books Ngram corpus, is remarkably large, it suffers from a idiosyncratic sampling policy, as well as OCR shortcomings and even more advanced issues, such as the absent normalization of historic orthographic variants. Other historic corpora dealing with the latter quality issues (such as the <span style="font-style:italic">Deutsches Textarchiv</span>) are plagued by their comparatively minuscule size.</p><p>Future research in Digital Humanities, besides dealing with these issues, will exploit the similarity data in order to make proper use of them under a humanities’ perspective and, thus, hopefully determine the added value of such computational results. This can be achieved by incorporating complementary types of data (e.g. historical, economic ones) to render additional evidences to change patterns. Since this is a huge and complex task, we plan to make our similarity data publically available on a website, together with an easy-to-use interface, as a humanities tool for comparative, diachronic lexico-semantic studies, with several user-adjustable parameters (e.g. different grain sizes of time intervals, alternative ranking metrics, <span style="font-style:italic">etc.</span>). From a methodological perspective, we plan to focus our research on protocols for training models covering long timespans, a metric to measure the quality of historic language models (probably including the need for a manual evaluation) and a way to include frequency information–a word which is no longer used cannot be said to be unchanged in its semantics. Such a system would ideally be tested by an in-depth study of the semantics of carefully selected words, including a comparison with prior, hermeneutically guided work in the humanities as a rich, yet completely informal background theory.</p></div><div class="DH-Heading1" id="index.xml-body.1_div.6"><h2 class="DH-Heading1"><span class="headingNumber">6. </span><span class="head">Funding</span></h2><p>This work was supported by the DFG-founded Research Training Group "The Romantic Model. Variation - Scope - Relevance" [grant GRK 2041/1].</p></div><!--TEI back--><div class="bibliogr" id="index.xml-back.1_div.1"><h2><span class="headingNumber"> </span></h2><div class="listhead">Bibliography</div><ol class="listBibl"><li id="index.xml-bibl-d30e372"><div class="biblfree"><span style="font-weight:bold">Arnim, A. von and Brentano, C. </span>(1806-1808). <span style="font-style:italic">Des Knaben Wunderhorn</span> <span style="font-weight:bold">1</span>(3), (Annotated TCF version provided by the Deutsches Textarchiv).</div></li><li id="index.xml-bibl-d30e384"><div class="biblfree"><span style="font-weight:bold">Baroni, M., Dinu, G. and Kruszewski, G. </span>(2015). Don’t count, predict! A systematic comparison of context-counting vs. context-predicting semantic vectors. <span style="font-style:italic">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</span>,<span style="font-weight:bold">1</span>: 238–47.</div></li><li id="index.xml-bibl-d30e396"><div class="biblfree"><span style="font-weight:bold">Firth, J. R.</span> (1957). A synopsis of linguistic theory, 1930-1955. <span style="font-style:italic">Studies in Linguistic Analysis</span>, pp. 1–32.</div></li><li id="index.xml-bibl-d30e405"><div class="biblfree"><span style="font-weight:bold">Gulordava, K. and Baroni, M. </span>(2011). A distributional similarity approach to the detection of semantic change in the Google Books Ngram corpus <span style="font-style:italic"><span style="font-style:italic">.</span></span> <span style="font-style:italic">Proceedings of the GEMS 2011 Workshop on Geometrical Models of Natural Language Semantics @EMNLP 2011</span>, pp. 67–71.</div></li><li id="index.xml-bibl-d30e421"><div class="biblfree"><span style="font-weight:bold">Kim, Y., et al.</span> (2014). Temporal analysis of language through neural language models <span style="font-style:italic">. </span> <span style="font-style:italic">Proceedings of the ACL 2014 Workshop on Language Technologies and Computational Social Science</span>, pp. 61–65.</div></li><li id="index.xml-bibl-d30e433"><div class="biblfree"><span style="font-weight:bold">Kulkarni, V., et al.</span> (2015). Statistically significant detection of linguistic change. <span style="font-style:italic">Proceedings of the 24th International Conference on World Wide Web</span>, pp. 625–35.</div></li><li id="index.xml-bibl-d30e442"><div class="biblfree"><span style="font-weight:bold">Lin, Y., et al. </span>(2012). Syntactic annotations for the Google Books Ngram Corpus <span style="font-style:italic">. </span> <span style="font-style:italic">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations</span>, pp. 169–74.</div></li><li id="index.xml-bibl-d30e454"><div class="biblfree"><span style="font-weight:bold">Michel, J.B., et al.</span> (2011). Quantitative analysis of culture using millions of digitized books <span style="font-style:italic">. </span> <span style="font-style:italic">Science</span>, <span style="font-weight:bold">331</span>(6014): 176–82.</div></li><li id="index.xml-bibl-d30e469"><div class="biblfree"><span style="font-weight:bold">Mihalcea, R. and Nastase, V.</span> (2012). Word epoch disambiguation: Finding how words change over time <span style="font-style:italic">. </span> <span style="font-style:italic">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics</span>, <span style="font-weight:bold">2</span>: 259–63.</div></li><li id="index.xml-bibl-d30e484"><div class="biblfree"><span style="font-weight:bold">Mikolov, T., et al. </span>(2013). Distributed representations of words and phrases and their compositionality. <span style="font-style:italic">Advances in Neural Information Processing Systems 26 (NIPS2013),</span> pp. 3111–119.</div></li><li id="index.xml-bibl-d30e494"><div class="biblfree"><span style="font-weight:bold">Pechenick, E. A., Danforth, C. M. and Dodds, P. S.</span> (2015). Characterizing the Google Books Corpus: Strong limits to inferences of socio-cultural and linguistic evolution. <span style="font-style:italic">PLoS ONE</span> <span style="font-weight:bold">10</span>(10): e0137041.</div></li><li id="index.xml-bibl-d30e506"><div class="biblfree"><span style="font-weight:bold">Riedl, M., Steuer, R. and Biemann, C.</span> (2014). Distributed distributional similarities of Google Books over the centuries <span style="font-style:italic">. </span> <span style="font-style:italic">Proceedings of the 9th International Conference on Language Resources and Evaluation (LREC’14)</span>, pp. 1401–405.</div></li><li id="index.xml-bibl-d30e518"><div class="biblfree"><span style="font-weight:bold">Schnabel, T., et al.</span> (2015). Evaluation methods for unsupervised word embeddings. <span style="font-style:italic">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP ’15)</span>, pp. 298–307.</div></li></ol></div><!--Notes in [TEI]--><div class="notes"><div class="noteHeading">Notes</div><div class="note" id="ftn1"><span class="noteLabel">1. </span><div class="noteBody"><p class="footnote text">An <span style="font-style:italic">n</span>-gram is a sequence of <span style="font-style:italic">n</span> words plus information on their frequency/probability of occurrence for a given corpus. The available version of the corpus does not consist of running text, but of <span style="font-style:italic">n</span>-grams instead.</p></div></div><div class="note" id="ftn2"><span class="noteLabel">2. </span><div class="noteBody"><p class="footnote text">The <span style="font-style:italic">Deutsches Textarchiv</span> (DTA) can be considered as a counter example, at least, as far as the quality of OCR is concerned. Yet, DTA suffers from tremendous size limitations in comparison with the (German portion of the) Google corpus, since this corpus for historic German texts contains only about 2.4k texts ( <a class="link_ref" href="http://www.deutschestextarchiv.de/list">http://www.deutschestextarchiv.de/list</a>).</p></div></div><div class="note" id="ftn3"><span class="noteLabel">3. </span><div class="noteBody"><p class="footnote text"><a class="link_ref" href="https://github.com/hellrich/dh2016">https://github.com/hellrich/dh2016</a></p></div></div></div></body></html>
		</div>
		<div class="col-lg-2">
		</div>
	</div>


		</div>
		<script>
		$(document).ready(function(){
			$('[data-toggle="tooltip"]').tooltip();
		});
		</script>			
	</body>
</html>