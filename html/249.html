<!DOCTYPE html>



<html lang="en">
	<head>
		<meta charset="utf-8">	
		<meta name="viewport" content="width=device-width, initial_scale=1">
		<title>DH 2016 Abstracts</title>
		<link rel="stylesheet" href="/static/bootstrap/css/bootstrap.min.css">
		<link rel="stylesheet" href="/static/bootstrap/css/bootstrap-theme.min.css">
		<link rel="stylesheet" href="/static/css/abstracts.css">
		<script src="/static/jquery/jquery-2.2.4.min.js"></script>
		<script src="/static/bootstrap/js/bootstrap.min.js"></script>
	</head>
	<body>
		<div class="container">
			<div class="row">
				<a href="http://dh2016.adho.org"><img src="/static/images/logo_4.png" class="img-responsive"></a>
			</div>
			<div class="row">
				<ol class="breadcrumb">
					
						<li><a href="http://www.dh2016.adho.org">DH Home</a></li>
					
						<li><a href="/abstracts/">Abstracts</a></li>
					
						<li><a href="/abstracts/249">249</a></li>
					
				</ol>
			</div>
					
			
	<div class="row">
		<div class="col-lg-2">
		</div>
		<div class="col-lg-8 col-xs-12">
			<button class="btn btn-default" data-toggle="collapse" data-target="#head" style="margin-bottom: 5px;">Show info</button>
			<button class="btn btn-default" data-toggle="collapse" data-target="#cite" style="margin-bottom: 5px;">How to cite</button>
			<a href="/static/data/256.xml" class="btn btn-default" role="button" style="margin-bottom: 5px;" download="249.xml">XML Version</a>
			<div class="panel panel-success collapse" style="padding: 10px; border=none;" id="head">
				<div>
					<b>Title: </b>Making Sense of Illustrated Handwritten Archives
					<br>
					<b>Authors: </b>
					Lambert Schomaker, Andreas Weber, Michiel Thijssen, Maarten Heerlien, Aske Plaat, Siegfried Nijssen, Fons Verbeek, Michael Lew, Eulalia Gasso Miracle, Katy Wolstencroft, Ernest Suyver, Bart Verheij, Marco Wiering, Rene Dekker, Joost Kok, Lissa Roberts, Jaap Van den Herik
					<br>
					<b>Category: </b>Paper:Short Paper
					<br>
					<b>Keywords: </b>Artificial intelligence; handwriting and image recognition; history of science; machine learning; networked heritage
				</div>
			</div>
			<div class="collapse" id="cite">
				<b>Schomaker, L., Weber, A., Thijssen, M., Heerlien, M., Plaat, A., Nijssen, S., Verbeek, F., Lew, M., Gasso Miracle, E., Wolstencroft, K., Suyver, E., Verheij, B., Wiering, M., Dekker, R., Kok, J., Roberts, L., Van den Herik, J.</b> (2016). Making Sense of Illustrated Handwritten Archives. In <i>Digital Humanities 2016: Conference Abstracts</i>. Jagiellonian University & Pedagogical University, Kraków, 
				
					pp. 674-676.
				
			</div>
		</div>
		<div class="col-lg-2">
		</div>
	</div>
	<div class="row">
		<div class="col-lg-2">
		</div>
		<div class="col-lg-8">	
			<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8" /><!--THIS FILE IS GENERATED FROM AN XML MASTER. DO NOT EDIT (5)--><title>Making Sense of Illustrated Handwritten Archives</title><meta name="author" content="Lambert Schomaker , Andreas Weber , Michiel Thijssen , Maarten Heerlien , Aske Plaat , Siegfried Nijssen , Fons Verbeek , Michael Lew , Eulalia Gasso Miracle , Katy Wolstencroft , Ernest Suyver , Bart Verheij , Marco Wiering , Rene Dekker , Joost Kok , Lissa Roberts , and Jaap Van den Herik" /><meta name="generator" content="Text Encoding Initiative Consortium XSLT stylesheets" /><meta name="DC.Title" content="Making Sense of Illustrated Handwritten Archives" /><meta name="DC.Type" content="Text" /><meta name="DC.Format" content="text/html" /><link href="http://www.tei-c.org/release/xml/tei/stylesheet/tei.css" rel="stylesheet" type="text/css" /><link rel="stylesheet" media="print" type="text/css" href="http://www.tei-c.org/release/xml/tei/stylesheet/tei-print.css" /></head><body class="simple" id="TOP"><div class="stdheader autogenerated"><h1 class="maintitle">Making Sense of Illustrated Handwritten Archives</h1></div><!--TEI front--><!--TEI body--><div class="panel panel-default panel-figure"><img class="img-responsive" src="/static/data/256/image1.png" alt="Figure 1. Page from a bundle of field notes, describing and depicting a mouse species. Source: Naturalis Biodiversity Center, Archief van de Natuurkundige Commissie voor Nederlands-Indië. Copyright: Public Domain Mark 1.0" class="inline" /><div class="caption">Figure 1. Page from a bundle of field notes, describing and depicting a mouse species. Source: Naturalis Biodiversity Center, Archief van de Natuurkundige Commissie voor Nederlands-Indië. Copyright: Public Domain Mark 1.0</div></div><p>This paper presents initial findings of the <a class="link_ref" href="http://brill.com/makingsense">research project</a> <span style="font-style:italic">Making Sense of Illustrated Handwritten Archives</span> and demonstrates the recognition capabilities of the MONK artificial intelligence system developed since the early 2000s at the institute of Artificial Intelligence and Cognitive Engineering (ALICE) at Groningen University (Van der Zant et al., 2008; Van Oosten and Schomaker, 2014a, Van Oosten and Schomaker, 2014b). In a period of four years (Q1 2016 – Q1 2020), our research project aims to produce an innovative and user-friendly online environment that combines both image and textual recognition, and allows an integrated study of fragmented historical heritage collections. <span style="font-weight:bold">Next to a short demonstration of MONK, we use this paper to outline how handwriting and image recognition helps to increase the value of illustrated handwritten collections by enriching and linking information that is now inaccessible and disconnected. </span>By doing so it advances the state of the art in automated extraction, classification, and networking of knowledge from heterogeneous manuscript collections.</p><p>The MONK system uses shape-based feature vector methods that have very few assumptions concerning the content or style of the material. It avoids the traditional OCR approach (optical character recognition) which assumes that individual characters are essentially legible. That assumption only holds for a tiny fraction of handwritten material and a limited number of scripts. The only assumptions MONK makes are that pictorial and textual segments are separated by white spaces; and that the layout, of underlining, etc. in a specific document, is consistent throughout the document. In MONK, classification methods are used that allow for a fast bootstrap from single example instances (nearest-neighbor search) (Gast et al., 2013). With larger numbers of labeled examples, models can be computed, varying from nearest-centroids to support-vector machines and neural networks in a continuous learning process (Krizhevsky et al., 2012; Liu et al, 2015; Guo, in press). A challenging topic from the technical point of view is the relation between existing semantic knowledge (ontologies) and the statistically inferred semantics using Google’s <span style="font-style:italic">word2vec</span> and current deep-learning neural networks. Can the underlying structure and style in a collection of a common and realistic size be detected by such algorithms? Can the proposed enrichment system profit from generally available text corpora? The processing power required by the proposed architecture is substantial. For this project, algorithmic optimization of the image processing and recognition system is necessary in order to create the necessary speed and flexibility of the system for use by non-technical end users. In order to tackle this challenge the consortium will make use of the combined knowledge and expertise of ALICE in Groningen, and the Leiden Institute of Advanced Computer Science (LIACS), where multiple supercomputers and high performance computing experts are present.</p><p>Because of its visual approach, MONK can handle the diversity of material that we encounter in our use case and in historical collections in general: text, drawings, and images. MONK also does not require a language model nor fully transcribed samples to quickly assess the contents of an archive page. The human-in-the-loop approach of MONK is currently ‘label’ oriented, but will be enhanced by providing the user and the system with ontologies for bootstrapping the learning process. The system will understand handwritten corpora to such an extent that the visual and textual content on individual pages is categorized, determined and networked to other pages in the archive and external sources. To construct training examples for MONK, biologists and historians of science will manually label documents to the machine learning software by means of a human in the loop approach. In addition, a crowdsourcing approach will be used to further expand this corpus of examples. Our consortium will here build on the expertise of ALICE and Naturalis Biodiversity Center, the Leiden-based National Museum of Natural History. Eventually, the computer-assisted recognition of words and visual information on a page will thus allow users to search, filter and group arbitrary archive items and enables connections with external databases. Last but not least, MONK lays the groundwork for full transcription of any handwritten-illustrated archival collection. </p><div class="panel panel-default panel-figure"><img class="img-responsive" src="/static/data/256/image2.png" alt="Figure 2. Drawing of Burro multicolor created in Buitenzorg, Java in 1827 by Pieter van Oort. Source: Naturalis Biodiversity Center, Archief van de Natuurkundige Commissie voor Nederlands-Indië. Copyright: Public Domain Mark 1.0" class="inline" /><div class="caption">Figure 2. Drawing of Burro multicolor created in Buitenzorg, Java in 1827 by Pieter van Oort. Source: Naturalis Biodiversity Center, Archief van de Natuurkundige Commissie voor Nederlands-Indië. Copyright: Public Domain Mark 1.0</div></div><p>The central use case of our research project is the collection of the <span style="font-style:italic">Natuurkundige Commissie voor Nederlandsch-Indië </span>(hereinafter NC). It is one of the top-collections of Naturalis. From 1820 to 1850, the NC charted the natural and economic state of the Dutch East Indies and returned a wealth of scientific data and specimens which are now stored in archives in the Netherlands and Indonesia. The collection comprises thousands of handwritten notes and drawings and tens of thousands biological and geological specimens. While these archival items have all been digitized, the individual pages in the notebooks, diaries and reports are not catalogued nor labeled separately. Many of the field notes combine different textual and visual elements on one page. Our short paper presentation is based on the processing of an initial set of understudied handwritten field notes which we carried out in early 2016. By doing so, we will demonstrate the efficiency of the MONK system and our approach.</p><p>Owing to the different ‘hands’ and languages used in the documents, links across handwritten field records and notes, drawings and specimens cannot be made in an efficient way. Our corpus contains material from at least seventeen different writers and the used languages range from German <span style="font-style:italic">(Kurrentschrift)</span> to Latin, French, and Dutch. The labels of related historic specimens only provide very general information on collection localities and collectors. Hence, the typical use case of a scholar wishing to retrieve information on a certain species, person, drawing, or collecting locality is limited. Owing to its sheer dimension and its weak structure, it is impractical to disclose and network this archive manually. Its current inaccessibility hampers research into Southeast Asian natural history and the history of (scientific) knowledge production. Knowledge extracted from the documents will be structured and served as Linked Open Data. This will allow interlinking of content and also enable interoperability with other cultural heritage resources, for example, the physical specimens obtained during expeditions, or other historically significant data collections from the same area.</p><p>The multi-layered character of the material makes it a perfect use case for developing a technologically advanced and usability engineered digital environment for interpreting and connecting illustrated-handwritten collections. In our consortium data scientists from the Universities in Leiden and Groningen work closely together historians of science from the University of Twente and taxonomy experts from Naturalis. Fueled by an investment from BRILL publishers in a national funding scheme, this project will not only result in the disclosure of the NC archive, but will also enable the integrated study of underexplored scientific manuscript collections and archives in general. </p><!--TEI back--><div class="bibliogr" id="index.xml-back.1_div.1"><h2><span class="headingNumber"> </span></h2><div class="listhead">Bibliography</div><ol class="listBibl"><li id="index.xml-bibl-d30e510"><div class="biblfree"><span style="font-weight:bold">Zant, T. van der, Schomaker, L. and Haak, K. </span> (2008). Handwritten-Word Spotting Using Biologically Inspired Features. <span style="font-style:italic">IEEE Transactions on Pattern Analysis and Machine Intelligence</span>, <span style="font-weight:bold">30</span>(11): 1945–57.</div></li><li id="index.xml-bibl-d30e522"><div class="biblfree"><span style="font-weight:bold">Oosten, J.-P. van and Schomaker, L. </span>(2014a). Separability versus prototypicality in handwritten word-image retrieval. <span style="font-style:italic">Pattern Recognition</span>, <span style="font-weight:bold">47</span>(3): 1031–38. (Handwriting Recognition and Other PR Applications)</div></li><li id="index.xml-bibl-d30e534"><div class="biblfree"><span style="font-weight:bold">Oosten, J.-P. van and Schomaker, L. </span>(2014b). A Reevaluation and Benchmark of Hidden Markov Models. <span style="font-style:italic">2014 14th International Conference on Frontiers in Handwriting Recognition (ICFHR)</span>. pp. 531–36.</div></li><li id="index.xml-bibl-d30e543"><div class="biblfree"><span style="font-weight:bold">Gast, E., Oerlemans, A. and Lew, M. S. </span>(2013). Very large scale nearest neighbor search: ideas, strategies and challenges. <span style="font-style:italic">International Journal of Multimedia Information Retrieval</span>, <span style="font-weight:bold">2</span>(4): 229–41.</div></li><li id="index.xml-bibl-d30e556"><div class="biblfree"><span style="font-weight:bold">Krizhevsky, A., Sutskever, I. and Hinton, G. E. </span>(2012). Imagenet classification with deep convolutional neural networks. <span style="font-style:italic">Advances in Neural Information Processing Systems</span>. pp. 1097–105.</div></li><li id="index.xml-bibl-d30e565"><div class="biblfree"><span style="font-weight:bold">Liu, Y., Guo, Y., Wu, S. and Lew, M. S. </span>(2015). DeepIndex for Accurate and Efficient Image Retrieval. <span style="font-style:italic">Proceedings of the 5th ACM on International Conference on Multimedia Retrieval</span>. (ICMR ’15). New York, NY, USA: ACM, pp. 43–50.</div></li><li id="index.xml-bibl-d30e574"><div class="biblfree"><span style="font-weight:bold">Guo, Y., Liu, Y., Oerlemans, A., Lao, S., Wu, S. and Lew, M. S.</span> (2015). Deep learning for visual understanding: A review. <span style="font-style:italic">Neurocomputing</span>. (Available online 26 November 2015).</div></li></ol></div></body></html>
		</div>
		<div class="col-lg-2">
		</div>
	</div>


		</div>
		<script>
		$(document).ready(function(){
			$('[data-toggle="tooltip"]').tooltip();
		});
		</script>			
	</body>
</html>