<!DOCTYPE html>



<html lang="en">
	<head>
		<meta charset="utf-8">	
		<meta name="viewport" content="width=device-width, initial_scale=1">
		<title>DH 2016 Abstracts</title>
		<link rel="stylesheet" href="/static/bootstrap/css/bootstrap.min.css">
		<link rel="stylesheet" href="/static/bootstrap/css/bootstrap-theme.min.css">
		<link rel="stylesheet" href="/static/css/abstracts.css">
		<script src="/static/jquery/jquery-2.2.4.min.js"></script>
		<script src="/static/bootstrap/js/bootstrap.min.js"></script>
	</head>
	<body>
		<div class="container">
			<div class="row">
				<a href="http://dh2016.adho.org"><img src="/static/images/logo_4.png" class="img-responsive"></a>
			</div>
			<div class="row">
				<ol class="breadcrumb">
					
						<li><a href="http://www.dh2016.adho.org">DH Home</a></li>
					
						<li><a href="/abstracts/">Abstracts</a></li>
					
						<li><a href="/abstracts/21">21</a></li>
					
				</ol>
			</div>
					
			
	<div class="row">
		<div class="col-lg-2">
		</div>
		<div class="col-lg-8 col-xs-12">
			<button class="btn btn-default" data-toggle="collapse" data-target="#head" style="margin-bottom: 5px;">Show info</button>
			<button class="btn btn-default" data-toggle="collapse" data-target="#cite" style="margin-bottom: 5px;">How to cite</button>
			<a href="/static/data/93.xml" class="btn btn-default" role="button" style="margin-bottom: 5px;" download="21.xml">XML Version</a>
			<div class="panel panel-success collapse" style="padding: 10px; border=none;" id="head">
				<div>
					<b>Title: </b>Toccata : Text-Oriented Computational Classifier Applicable To Authorship
					<br>
					<b>Authors: </b>
					Richard Sandes Forsyth
					<br>
					<b>Category: </b>Paper:Short Paper
					<br>
					<b>Keywords: </b>authorship, classification, cross-validation, stylometry.
				</div>
			</div>
			<div class="collapse" id="cite">
				<b>Forsyth, R.</b> (2016). Toccata : Text-Oriented Computational Classifier Applicable To Authorship. In <i>Digital Humanities 2016: Conference Abstracts</i>. Jagiellonian University & Pedagogical University, Kraków, 
				
					pp. 510-513.
				
			</div>
		</div>
		<div class="col-lg-2">
		</div>
	</div>
	<div class="row">
		<div class="col-lg-2">
		</div>
		<div class="col-lg-8">	
			<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8" /><!--THIS FILE IS GENERATED FROM AN XML MASTER. DO NOT EDIT (5)--><title>Toccata : Text-Oriented Computational Classifier Applicable To Authorship</title><meta name="author" content="Richard Sandes Forsyth" /><meta name="generator" content="Text Encoding Initiative Consortium XSLT stylesheets" /><meta name="DC.Title" content="Toccata : Text-Oriented Computational Classifier Applicable To Authorship" /><meta name="DC.Type" content="Text" /><meta name="DC.Format" content="text/html" /><link href="http://www.tei-c.org/release/xml/tei/stylesheet/tei.css" rel="stylesheet" type="text/css" /><link rel="stylesheet" media="print" type="text/css" href="http://www.tei-c.org/release/xml/tei/stylesheet/tei-print.css" /></head><body class="simple" id="TOP"><div class="stdheader autogenerated"><h1 class="maintitle">Toccata : Text-Oriented Computational Classifier Applicable To Authorship</h1></div><!--TEI front--><!--TEI body--><div class="DH-Heading1" id="index.xml-body.1_div.1"><h2 class="DH-Heading1"><span class="headingNumber">1. </span><span class="head">Introduction</span></h2><p>Many text-classification techniques have been proposed and used for authorship attribution (Holmes, 1994; Grieve, 2007; Juola, 2008; Koppel et al., 2011), genre categorization (Biber, 1988; Argamon et al., 2003), stylochronometry (Forsyth, 1999) and other tasks within computational stylistics. However, until quite recently, it has been extremely difficult to assess novel and existing techniques on comparable benchmark problems within a common framework using statistically robust methods.</p><p>Toccata is a resource for computational stylometry which aims to address that lack, freely available at</p><p><a class="link_ref" href="http://www.richardsandesforsyth.net/software.html">http://www.richardsandesforsyth.net/software.html</a></p><p>under the GNU public licence.</p><p>The main program is a test harness in which a variety of text-classification algorithms can be evaluated on unproblematic cases and, if required, applied to disputed cases. The package supplies four pre-existing classification methods as modules (including Delta (Burrows, 2002), widely regarded as a standard in this area) as well as five sample corpora (including the famous <span style="font-style:italic">Federalist Papers</span>) so that users who don't wish to write Python code can use it simply as an off-the-shelf classifier and those who do can familiarize themselves with the system before implementing their own algorithms.</p><p>Noteworthy features of the system include:</p><ol><li class="item">sample corpora provided for familiarization;</li><li class="item">test phase using random subsampling to give robust error-rate estimation;</li><li class="item">ability to plug in new techniques or to employ existing standards;</li><li class="item">option of post-hoc phase applying trained model(s) to unseen holdout data;</li><li class="item">empirically grounded computation of post-hoc confidence weights to deal with 'open' problems where the unseen cases may not belong to any of the training-set categories;</li><li class="item">accompanying export file readable by R or similar statistical packages for optional further processing.</li></ol></div><div class="DH-Heading1" id="index.xml-body.1_div.2"><h2 class="DH-Heading1"><span class="headingNumber">2. </span><span class="head">Sketch of the System's Operation</span></h2><p>Toccata performs three main functions, in sequence:</p><p>(a) testmode: leave-n-out random resampling test of the classifier on the training corpus to provide statistics by which the classifier can be evaluated;</p><p>(b) holdout: application of the classifier to an unseen holdout sample of texts, if given;</p><p>(c) posthoc: re-application to the holdout sample of texts (if given) using the results from phase (a) to estimate empirical probabilities.</p><p>Steps (b) and (c) are optional.</p></div><div class="DH-Heading1" id="index.xml-body.1_div.3"><h2 class="DH-Heading1"><span class="headingNumber">3. </span><span class="head">Sample corpora</span></h2><p>Toccata is a document-oriented system. Thus a training corpus consists of a number of text files, in UTF8 encoding, without markup such as HTML tags. Each file is treated as an individual document, belonging to a particular category. Example corpora are supplied to enable users to start using the system, prior to collecting or reformatting their own corpora.</p><p><span style="font-weight:bold">ajps</span>: ninety poems by 2 eminent 19th-century Hungarian poets, Arany József and Petőfi Sándor. Arany was godfather to Petőfi's child, so we might expect their writing styles to be relatively similar.</p><p><span style="font-weight:bold">cics</span>: Latin texts relevant to the authorship of the <span style="font-style:italic">Consolatio</span> which Cicero wrote in 45 BC. This was thought to have been lost until in 1583 AD when Sigonio claimed to have rediscovered it. Background information can be found in Forsyth et al. (1999).</p><p><span style="font-weight:bold">feds</span>: writings by Alexander Hamilton and James Madison, as well as some contemporaries of theirs. This corpus is related to another notable authorship dispute, concerning the <span style="font-style:italic">Federalist Papers</span>, which were published in New York in 1788. See Holmes and Forsyth (1995).</p><p><span style="font-weight:bold">mags</span>: 144 texts from 2 different learned journals, namely <span style="font-style:italic">Literary and Linguistic Computing</span> and <span style="font-style:italic">Machine Learning</span>. Each text is an excerpt consisting of the Abstract plus initial paragraph of an article in one of those journals, written during the period 1987-1995.</p><p><span style="font-weight:bold">sonnets</span>: 196 English sonnets, 14 each by 14 different authors, with an additional holdout sample of 24 texts, half of which are by authors absent from the main sample.</p></div><div class="DH-Heading1" id="index.xml-body.1_div.4"><h2 class="DH-Heading1"><span class="headingNumber">4. </span><span class="head">Validation by Random Subsampling</span></h2><p>A major objective of the system is to assess the effectiveness of text-classification methods by a form of cross validation. For this purpose the training corpus of undisputed texts is repeatedly divided into two portions, one used to form a classification model and the other used to test the accuracy of this model. After this cycle a number of quality statistics are computed and printed, along with a confusion matrix. This helps to establish a relatively honest estimate of the likely future error rate of the classifier. After subsampling, the program will construct a model on the full training set. This may then be applied to a genuine holdout sample, if provided.</p></div><div class="DH-Heading1" id="index.xml-body.1_div.5"><h2 class="DH-Heading1"><span class="headingNumber">5. </span><span class="head">Classifier Modules</span></h2><p>A classifier module is expected to develop trained models of each text category and deliver matching scores of a text to each model, with more positive scores indicating stronger matching. The category with the highest match-score relative to the average of all scores for the text, is the assigned class. Four library modules are supplied "off the shelf".</p><p>Module <span style="font-weight:bold">docalib_deltoid.py</span> is an implementation of Burrows's delta (Burrows, 2002) which has become a standard technique in authorship attribution studies. Module <span style="font-weight:bold">docalib_keytoks.py</span> works by first finding the 1024 most common word tokens in the corpus, then keeping from these the most distinctive. For classification, relative word frequencies in the text being classified are correlated with relative frequencies in each class. Module <span style="font-weight:bold">docalib_maws.py</span> is a version of what Mosteller and Wallace in their classic work (1964/1984) on the <span style="font-style:italic">Federalist Papers</span> call their "robust Bayesian analysis", as implemented by Forsyth (1995). Module <span style="font-weight:bold">docalib_topvocs.py</span> implements another classifier inspired by the approach of Burrows (1992), which uses the most frequent tokens in the training corpus as features.</p></div><div class="DH-Heading1" id="index.xml-body.1_div.6"><h2 class="DH-Heading1"><span class="headingNumber">6. </span><span class="head">The Holdout and Posthoc Phases</span></h2><p>The subsampling test phase (above) is primarily concerned with assessing the quality of a classification method. The holdout and posthoc phases are when that method is applied in earnest.</p><p>If a holdout sample is given, the model developed on the training set is applied to that sample. The holdout texts may belong to categories that were not present in the training set, so each decision is categorized as correct (+), incorrect (-) or undetermined (?) and the success rate statistics computed accordingly.</p><p>This is illustrated in Table 1, below, from an application of the MAWS (Mosteller and Wallace) method to a collection of sonnets. Here the training set consists of 196 short English poems -- 14 sonnets by 14 different authors. This is a challenging problem firstly because the median length of each text in the training corpus is 116 words, secondly because 14 is a relatively large number of candidates.</p><p>Table 1 shows the ranking produced on a holdout sample of 24 texts, absent from the training set. Note that 12 of these 24 items are 'distractors', i.e. texts by authors not present in the training set. The program assigns these a question mark (?) in assessing its own decision.</p><p>The listing ranks the program's decisions from most to least credible. The upper third include 6 correct assignments, 1 clear mistake and a distractor. The middle third contains 1 correct classification, 3 mistakes and 4 distractors. The last third contains no correct answers, 1 mistake and 7 distractors. (Incidentally, the distractor poem by the Earl of Oxford, ranked twentieth, is more congruent with Wordsworth than any other author, including Shakespeare, and not confidently assigned to any of the training categories.)</p><p>This output addresses the very real problem of documents from outside the known training categories. The listing is ordered by a quantity labelled 'credit'. This is the geometric mean of the last two numbers in each line, labelled 'confidence' and 'congruity'. Confidence is derived from the preceding subsampling phase. It is computed from the differential matching score of the text under consideration as W / (W+L), where W is the number of correct answers which received a lower differential score during the subsampling phase and L is the number of wrong answers with a higher score. Congruity is simply the proportion of matching scores of the chosen category that were lower, in the subsampling phase, than the score for the case in question. It is an empirically based index of compatibility between the assigned category of the text and the training examples of that category.</p><p>In all kinds of classification, the problem of never-before-seen categories can loom large. (See, for instance, Eder, 2013.) Like most trainable classifiers, Toccata always picks the most likely category from those it has encountered in training, but the most likely may not be very likely. The confidence and congruity scores give useful information in this regard. For example, if we only consider the classifications which obtain a score of at least 0.5 on both confidence and congruity, we find 6 correct decisions, 1 incorrect and 1 distractor. Treating the distractor (assigning a sonnet by Dylan Thomas to Edna Millay) as incorrect still represents a 75% success rate in an "open" authorship problem on texts only slightly more than a hundred word tokens in length, where the training sample for each known category consists of approximately 1600 words, with a chance expectation of 7% success. In other words, three crucial parameters -- training corpus size, text length and number of categories -- are all well "outside the envelope" of most previously reported authorship studies.</p><p>Table 1 -- Posthoc ranking of 24 decisions on unseen texts, including 12 'distractors'</p><div class="table"><table class="rules" style="border-collapse:collapse;border-spacing:0;"><tr><td class="Plain_Text">rank</td><td class="Plain_Text">credit</td><td class="Plain_Text">filename</td><td class="Plain_Text">pred:true</td><td class="Plain_Text">conf.</td><td class="Plain_Text">congruity</td></tr><tr><td class="Plain_Text">1</td><td class="Plain_Text">0.9163</td><td class="Plain_Text">ChrRoss_WinterSecret.t</td><td class="Plain_Text">ChrRoss + ChrRoss</td><td class="Plain_Text">0.9530</td><td class="Plain_Text">0.8810</td></tr><tr><td class="Plain_Text">2</td><td class="Plain_Text">0.8768</td><td class="Plain_Text">WilShak_6.txt </td><td class="Plain_Text">WilShak + WilShak</td><td class="Plain_Text">0.9425</td><td class="Plain_Text">0.8158</td></tr><tr><td class="Plain_Text">3</td><td class="Plain_Text">0.8142</td><td class="Plain_Text">DylThom_Altar09.txt </td><td class="Plain_Text">EdnMill ? DylThom</td><td class="Plain_Text">0.8838</td><td class="Plain_Text">0.7500</td></tr><tr><td class="Plain_Text">4</td><td class="Plain_Text">0.7664</td><td class="Plain_Text">MicDray_Idea000.txt </td><td class="Plain_Text">MicDray + MicDray</td><td class="Plain_Text">0.6378</td><td class="Plain_Text">0.9211</td></tr><tr><td class="Plain_Text">5</td><td class="Plain_Text">0.7595</td><td class="Plain_Text">WilShak_137.txt </td><td class="Plain_Text">WilShak + WilShak</td><td class="Plain_Text">0.8118</td><td class="Plain_Text">0.7105</td></tr><tr><td class="Plain_Text">6</td><td class="Plain_Text">0.6950</td><td class="Plain_Text">JohDonn_Nativity.txt </td><td class="Plain_Text">JohDonn + JohDonn</td><td class="Plain_Text">0.6720</td><td class="Plain_Text">0.7188</td></tr><tr><td class="Plain_Text">7</td><td class="Plain_Text">0.6247</td><td class="Plain_Text">MicDray_Idea048.txt </td><td class="Plain_Text">JohDonn - MicDray</td><td class="Plain_Text">0.5430</td><td class="Plain_Text">0.7188</td></tr><tr><td class="Plain_Text">8</td><td class="Plain_Text">0.5356</td><td class="Plain_Text">WilShak_109.txt </td><td class="Plain_Text">WilShak + WilShak</td><td class="Plain_Text">0.5737</td><td class="Plain_Text">0.5000</td></tr><tr><td class="Plain_Text">9</td><td class="Plain_Text">0.5225</td><td class="Plain_Text">DylThom_Altar05.txt </td><td class="Plain_Text">RupBroo ? DylThom</td><td class="Plain_Text">0.4150</td><td class="Plain_Text">0.6579</td></tr><tr><td class="Plain_Text">10</td><td class="Plain_Text">0.4684</td><td class="Plain_Text">TomWyat_THEY_FLEE_FROM</td><td class="Plain_Text">EdmSpen ? ThoWyat</td><td class="Plain_Text">0.4596</td><td class="Plain_Text">0.4773</td></tr><tr><td class="Plain_Text">11</td><td class="Plain_Text">0.4226</td><td class="Plain_Text">PerShel_Ozymandias.txt</td><td class="Plain_Text">EliBrow ? PerShel</td><td class="Plain_Text">0.2217</td><td class="Plain_Text">0.8056</td></tr><tr><td class="Plain_Text">12</td><td class="Plain_Text">0.4027</td><td class="Plain_Text">EliBrow_SP23.txt </td><td class="Plain_Text">DanRoss - EliBrow</td><td class="Plain_Text">0.2237</td><td class="Plain_Text">0.7250</td></tr><tr><td class="Plain_Text">13</td><td class="Plain_Text">0.3061</td><td class="Plain_Text">WilShak_RomeoJuliet.tx</td><td class="Plain_Text">WilShak + WilShak</td><td class="Plain_Text">0.2094</td><td class="Plain_Text">0.4474</td></tr><tr><td class="Plain_Text">14</td><td class="Plain_Text">0.2739</td><td class="Plain_Text">PhiSidn_astel108.txt </td><td class="Plain_Text">EliBrow - PhiSidn</td><td class="Plain_Text">0.1080</td><td class="Plain_Text">0.6944</td></tr><tr><td class="Plain_Text">15</td><td class="Plain_Text">0.2625</td><td class="Plain_Text">DylThom_Altar06.txt </td><td class="Plain_Text">EliBrow ? DylThom</td><td class="Plain_Text">0.0992</td><td class="Plain_Text">0.6944</td></tr><tr><td class="Plain_Text">16</td><td class="Plain_Text">0.2283</td><td class="Plain_Text">JohDonn_Temple.txt </td><td class="Plain_Text">EdnMill - JohDonn</td><td class="Plain_Text">0.1179</td><td class="Plain_Text">0.4423</td></tr><tr><td class="Plain_Text">17</td><td class="Plain_Text">0.2014</td><td class="Plain_Text">Lincoln1863Gettysburg.</td><td class="Plain_Text">SamDani ? AbeLinc</td><td class="Plain_Text">0.0649</td><td class="Plain_Text">0.6250</td></tr><tr><td class="Plain_Text">18</td><td class="Plain_Text">0.1894</td><td class="Plain_Text">RicFors_LaBocca.txt </td><td class="Plain_Text">RupBroo ? RicFors</td><td class="Plain_Text">0.0649</td><td class="Plain_Text">0.5526</td></tr><tr><td class="Plain_Text">19</td><td class="Plain_Text">0.1352</td><td class="Plain_Text">HelFors_1958.txt </td><td class="Plain_Text">EliBrow ? HelFors</td><td class="Plain_Text">0.0263</td><td class="Plain_Text">0.6944</td></tr><tr><td class="Plain_Text">20</td><td class="Plain_Text">0.1089</td><td class="Plain_Text">oxford_13.txt </td><td class="Plain_Text">WilWord ? Oxford </td><td class="Plain_Text">0.0265</td><td class="Plain_Text">0.4474</td></tr><tr><td class="Plain_Text">21</td><td class="Plain_Text">0.0977</td><td class="Plain_Text">RicFors_Underworld.txt</td><td class="Plain_Text">EdnMill ? RicFors</td><td class="Plain_Text">0.0261</td><td class="Plain_Text">0.3654</td></tr><tr><td class="Plain_Text">22</td><td class="Plain_Text">0.0755</td><td class="Plain_Text">HelFors_1982.txt </td><td class="Plain_Text">DanRoss ? HelFors</td><td class="Plain_Text">0.0109</td><td class="Plain_Text">0.5250</td></tr><tr><td class="Plain_Text">23</td><td class="Plain_Text">0.0690</td><td class="Plain_Text">DylThom_Altar03.txt </td><td class="Plain_Text">RupBroo ? DylThom</td><td class="Plain_Text">0.0106</td><td class="Plain_Text">0.4474</td></tr><tr><td class="Plain_Text">24</td><td class="Plain_Text">0.0411</td><td class="Plain_Text">PhiSidn_astel030.txt </td><td class="Plain_Text">EdmSpen - PhiSidn</td><td class="Plain_Text">0.0106</td><td class="Plain_Text">0.1591</td></tr></table></div><p>++?+++-+???-+-?-???????-</p></div><!--TEI back--><div class="bibliogr" id="index.xml-back.1_div.1"><h2><span class="headingNumber"> </span></h2><div class="listhead">Bibliography</div><ol class="listBibl"><li id="index.xml-bibl-d30e911"><div class="biblfree"><span style="font-weight:bold">Argamon, S., et al.</span> (2003). Gender, genre, and writing style in formal written texts. <span style="font-style:italic">Text</span>, <span style="font-weight:bold">23</span>(3): 321-46.</div></li><li id="index.xml-bibl-d30e923"><div class="biblfree"><span style="font-weight:bold">Biber, D.</span> (1988). <span style="font-style:italic">Variation across speech and writing</span>. Cambridge: Cambridge University Press.</div></li><li id="index.xml-bibl-d30e932"><div class="biblfree"><span style="font-weight:bold">Burrows, J.F.</span> (1992). Not unless you ask nicely: the interpretive nexus between analysis and information. <span style="font-style:italic">Literary and Linguistic Computing</span>, <span style="font-weight:bold">7</span>(2): 91-109.</div></li><li id="index.xml-bibl-d30e944"><div class="biblfree"><span style="font-weight:bold">Burrows, J.F.</span> (2002). 'Delta': a measure of stylistic difference and a guide to likely authorship. <span style="font-style:italic">Literary and Linguistic Computing</span>, <span style="font-weight:bold">17</span>(3): 267-87.</div></li><li id="index.xml-bibl-d30e957"><div class="biblfree"><span style="font-weight:bold">Eder, M.</span> (2013). Bootstrapping Delta: a safety net in open-set authorship attribution. <a class="link_ref" href="http://dh2013.unl.edu/abstracts/"><span style="font-style:italic">Digital Humanities 2013: Conference Abstracts</span></a>. Lincoln: University of Nebraska-Lincoln, pp. 169-72.</div></li><li id="index.xml-bibl-d30e969"><div class="biblfree"><span style="font-weight:bold">Forsyth, R.S.</span> (1995). <span style="font-style:italic">Stylistic Structures: a Computational Approach to Text Classification</span>. Unpublished Doctoral Thesis, Faculty of Science, University of Nottingham. <a class="link_ref" href="http://www.richardsandesforsyth.net/doctoral.html">http://www.richardsandesforsyth.net/doctoral.html</a></div></li><li id="index.xml-bibl-d30e981"><div class="biblfree"><span style="font-weight:bold">Forsyth, R.S.</span> (1999). Stylochronometry with substrings, or: a poet young and old. <span style="font-style:italic">Literary and Linguistic Computing</span>, <span style="font-weight:bold">14</span>(4): 467-77.</div></li><li id="index.xml-bibl-d30e993"><div class="biblfree"><span style="font-weight:bold">Forsyth, R.S., Holmes, D.I. and Tse, E.K</span>. (1999). Cicero, Sigonio, and Burrows: investigating the authenticity of the 'Consolatio'. <span style="font-style:italic">Literary and Linguistic Computing, </span><span style="font-weight:bold">14</span>(3): 1-26.</div></li><li id="index.xml-bibl-d30e1004"><div class="biblfree"><span style="font-weight:bold">Grieve, J.</span> (2007). Quantitative authorship attribution: an evaluation of techniques. <span style="font-style:italic">Literary and Linguistic Computing</span>, <span style="font-weight:bold">22</span>(3): 251-70.</div></li><li id="index.xml-bibl-d30e1016"><div class="biblfree"><span style="font-weight:bold">Holmes, D.</span> (1994). Authorship attribution. <span style="font-style:italic">Computers and the Humanities</span>, <span style="font-weight:bold">28</span>: 1-20.</div></li><li id="index.xml-bibl-d30e1029"><div class="biblfree"><span style="font-weight:bold">Holmes, D.I. and Forsyth, R.S.</span> (1995). The 'Federalist' revisited: new directions in authorship attribution. <span style="font-style:italic">Literary and Linguistic Computing</span>, <span style="font-weight:bold">10</span>(2): 111-27.</div></li><li id="index.xml-bibl-d30e1041"><div class="biblfree"><span style="font-weight:bold">Juola, P.</span> (2006). Authorship attribution. <span style="font-style:italic">Foundations and Trends in Information Retrieval</span>, <span style="font-weight:bold">1</span>(3): 233-334.</div></li><li id="index.xml-bibl-d30e1053"><div class="biblfree"><span style="font-weight:bold">Koppel, M., Schler, J. and Argamon, S.</span> (2011). Authorship attribution in the wild. <span style="font-style:italic">Language Resources and Evaluation</span>, <span style="font-weight:bold">45</span>, pp. 83-94. DOI 10.1007/s10579-009-9111-2.</div></li><li id="index.xml-bibl-d30e1065"><div class="biblfree"><span style="font-weight:bold">Mosteller, F. and Wallace, D.L.</span> (1984). <span style="font-style:italic">Applied Bayesian and Classical Inference: the Case of the Federalist Papers</span>. New York: Springer. [First edition, 1964.]</div></li></ol></div></body></html>
		</div>
		<div class="col-lg-2">
		</div>
	</div>


		</div>
		<script>
		$(document).ready(function(){
			$('[data-toggle="tooltip"]').tooltip();
		});
		</script>			
	</body>
</html>