<!DOCTYPE html>



<html lang="en">
	<head>
		<meta charset="utf-8">	
		<meta name="viewport" content="width=device-width, initial_scale=1">
		<title>DH 2016 Abstracts</title>
		<link rel="stylesheet" href="/static/bootstrap/css/bootstrap.min.css">
		<link rel="stylesheet" href="/static/bootstrap/css/bootstrap-theme.min.css">
		<link rel="stylesheet" href="/static/css/abstracts.css">
		<script src="/static/jquery/jquery-2.2.4.min.js"></script>
		<script src="/static/bootstrap/js/bootstrap.min.js"></script>
	</head>
	<body>
		<div class="container">
			<div class="row">
				<a href="http://dh2016.adho.org"><img src="/static/images/logo_4.png" class="img-responsive"></a>
			</div>
			<div class="row">
				<ol class="breadcrumb">
					
						<li><a href="http://www.dh2016.adho.org">DH Home</a></li>
					
						<li><a href="/abstracts/">Abstracts</a></li>
					
						<li><a href="/abstracts/385">385</a></li>
					
				</ol>
			</div>
					
			
	<div class="row">
		<div class="col-lg-2">
		</div>
		<div class="col-lg-8 col-xs-12">
			<button class="btn btn-default" data-toggle="collapse" data-target="#head" style="margin-bottom: 5px;">Show info</button>
			<button class="btn btn-default" data-toggle="collapse" data-target="#cite" style="margin-bottom: 5px;">How to cite</button>
			<a href="/static/data/188.xml" class="btn btn-default" role="button" style="margin-bottom: 5px;" download="385.xml">XML Version</a>
			<div class="panel panel-success collapse" style="padding: 10px; border=none;" id="head">
				<div>
					<b>Title: </b>Ancient Maya Writings as High-Dimensional Data: a Visualization Approach
					<br>
					<b>Authors: </b>
					Gulcan Can, Jean-Marc Odobez, Carlos Pallan Gayol, Daniel Gatica-Perez
					<br>
					<b>Category: </b>Paper:Long Paper
					<br>
					<b>Keywords: </b>Maya glyphs, t-SNE
				</div>
			</div>
			<div class="collapse" id="cite">
				<b>Can, G., Odobez, J., Pallan Gayol, C., Gatica-Perez, D.</b> (2016). Ancient Maya Writings as High-Dimensional Data: a Visualization Approach. In <i>Digital Humanities 2016: Conference Abstracts</i>. Jagiellonian University & Pedagogical University, Kraków, 
				
					pp. 139-143.
				
			</div>
		</div>
		<div class="col-lg-2">
		</div>
	</div>
	<div class="row">
		<div class="col-lg-2">
		</div>
		<div class="col-lg-8">	
			<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8" /><!--THIS FILE IS GENERATED FROM AN XML MASTER. DO NOT EDIT (5)--><title>Ancient Maya Writings as High-Dimensional Data: a Visualization Approach </title><meta name="author" content="Gulcan Can , Jean-Marc Odobez , Carlos Pallan Gayol , and Daniel Gatica-Perez" /><meta name="generator" content="Text Encoding Initiative Consortium XSLT stylesheets" /><meta name="DC.Title" content="Ancient Maya Writings as High-Dimensional Data: a Visualization Approach" /><meta name="DC.Type" content="Text" /><meta name="DC.Format" content="text/html" /><link href="http://www.tei-c.org/release/xml/tei/stylesheet/tei.css" rel="stylesheet" type="text/css" /><link rel="stylesheet" media="print" type="text/css" href="http://www.tei-c.org/release/xml/tei/stylesheet/tei-print.css" /></head><body class="simple" id="TOP"><div class="stdheader autogenerated"><h1 class="maintitle"><span class="titlem">Ancient Maya Writings as High-Dimensional Data: a Visualization Approach</span> <span class="titlem"></span></h1></div><!--TEI front--><!--TEI body--><div class="DH-Heading1" id="index.xml-body.1_div.1"><h2 class="DH-Heading1"><span class="headingNumber">1. </span><span class="head">Introduction</span></h2><p>The ancient Maya civilization flourished from around 2000 BC to 1600 AD and left a great amount of cultural heritage materials, in the shape of stone monument inscriptions, folded codex pages, or personal ceramic items. All these materials contain hieroglyphs (in short glyphs) written on them. The Maya writing system is visually complex (Fig. 1) and new glyphs are still being discovered. This brings the necessity of better digital preservation systems. Interpretation of a small amount of glyphs is still open to discussion due to both visual differences and semantic analysis. Some glyphs are damaged, or have many variations due to artistic reasons and the evolving nature of language.</p><div class="panel panel-default panel-figure"><img class="img-responsive" src="/static/data/188/10000201000005E1000004659135E837.png" alt="Figure 1. A stone inscription found in Pomona, Tabasco (Mexico), Panel 1 from 771 AD (Photograph by Carlos Pallán Gayol for AJIMAYA/INAH Project© 2006, Instituto Nacional de Antropología de Historia, Mexico)" class="graphic" /><div class="caption">Figure 1. A stone inscription found in Pomona, Tabasco (Mexico), Panel 1 from 771 AD (Photograph by Carlos Pallán Gayol for AJIMAYA/INAH Project© 2006, Instituto Nacional de Antropología de Historia, Mexico)</div></div><p>Signs following ancient Mesoamerican representational conventions end up being classified according to their appearance, which leads to potential confusions as the iconic origin of many signs and their transformations through time are not well-understood. For instance, a sign thought to fall within the category of 'body-part' can later be proven to actually correspond to a vegetable element (a different semantic domain). Similarly, several signs classified as 'abstract', 'square' or 'round' could actually be pars-pro-toto representations of a larger whole.</p><div class="panel panel-default panel-figure"><img class="img-responsive" src="/static/data/188/1000020100000781000003211C532234.png" alt="Figure 2. Maya glyph samples from several categories (according to Thompson's catalog) that illustrate the within-class variety and between-class similarity" class="graphic" /><div class="caption">Figure 2. Maya glyph samples from several categories (according to Thompson's catalog) that illustrate the within-class variety and between-class similarity</div></div><p>Fig. 2 illustrates the challenges to analyse Maya glyphs visually. Adding functionalities that take context (i.e., co-occurrence statistics, characteristics of the data) and part-whole relations (i.e., highlighting diagnostic parts) into account would bring guidance during decipherment tasks. The tools we envision are different from existing almanac-by-almanac visualization systems (Vail and Hernandez, 2013). They are also more engaging for users (i.e. visitors in museums), and offer promising perspectives for scholars.</p><p>This motivates the study of data visualization. In this paper, we built a prototype for visualization of glyphs based on visual features. We introduce (1) an approach to analyse Maya glyphs combining a state-of-the-art visual shape descriptor, and (2) a non-linear method to visualize high-dimensional data. For the first component, we use the histogram of orientation shape context (HOOSC) (Roman-Rangel et. al., 2011a; Roman-Rangel et. al., 2011b; Roman-Rangel et. al., 2013) which has similarities to other descriptors of the recognition literature (Belongie et. al., 2002; Dalal and Triggs, 2005; Lowe, 2004), but is adapted to shape analysis (Franken and van Gemert, 2013). </p><p>For the second component, we use the t-distributed Stochastic Neighbourhood Embedding (t-SNE) (Van der Maaten and Hinton, 2008), which is a dimensionality reduction method from the machine learning literature that has value for Digital Humanities (DH), as it can highlight the structure of high-dimensional data, i.e., multiple viewpoints among samples.</p><p>As analysis of DH data is often based on attributes like authorship, produced time, and place, observing these variations as smooth transitions with t-SNE becomes a relevant feature. </p><p>We show that the proposed methodology is useful to analyse the extent of spatial support used in the shape descriptor and to reveal new connections in the corpus through inspection of glyphs from stone monuments and glyph variants from catalogue sources. In particular, we hope that the presentation of our use of t-SNE can motivate further work in DH for other related problems.</p></div><div class="DH-Heading1" id="index.xml-body.1_div.2"><h2 class="DH-Heading1"><span class="headingNumber">2. </span><span class="head">Methodology</span></h2><div class="panel panel-default panel-figure"><img class="img-responsive" src="/static/data/188/10000201000006D2000001D278FA1261.png" alt="Figure 3. Overall flow for visualization with t-SNE" class="graphic" /><div class="caption">Figure 3. Overall flow for visualization with t-SNE</div></div><p>The analysis process is illustrated in Fig. 3. First, for each glyph, a standard visual bag-of-words representation (BoW) is computed from the HOOSC descriptors. Second, dimensionality reduction is performed on the BoW representation of a glyph collection to generate the visualization. The main steps are described below. </p><div class="DH-Heading2" id="index.xml-body.1_div.2_div.1"><h3 class="DH-Heading2"><span class="headingNumber">2.1. </span><span class="head">Datasets</span></h3><p>We analyse our visualization pipeline on two individual Maya glyph datasets.</p><div class="DH-Heading3" id="index.xml-body.1_div.2_div.1_div.1"><h4 class="DH-Heading3"><span class="headingNumber">2.1.1. </span><span class="head">Monument data</span></h4><div class="panel panel-default panel-figure"><img class="img-responsive" src="/static/data/188/10000201000004A300000208C03F34E8.png" alt="Figure 4. Sample glyph images, corresponding Thompson annotations, and syllabic values (sounds) of selected 10 classes from the syllabic monument glyph dataset" class="graphic" /><div class="caption">Figure 4. Sample glyph images, corresponding Thompson annotations, and syllabic values (sounds) of selected 10 classes from the syllabic monument glyph dataset</div></div><p>We use a subset (630 samples from 10 classes, Fig. 4) of hand-drawings (Roman-Rangel et. al., 2011), corresponding to syllabic glyphs inscribed in monuments. These samples are collected by archaeologists (as part of Mexico’s AJIMAYA project) from stone inscriptions spread over four regions (Peten, Usumacinta, Motagua, and Yucatan). As an additional source, around 300 glyph samples are taken from existing catalogues (Thompson and Eric, 1962; Macri and Looper, 2003). </p></div><div class="DH-Heading3" id="index.xml-body.1_div.2_div.1_div.2"><h4 class="DH-Heading3"><span class="headingNumber">2.1.2. </span><span class="head">Thompson catalogue </span></h4><p>Secondly, we use 1487 glyph variants cropped from the Thompson's catalogue. These variants belong to 814 categories and divided as main sign and prefix/suffix groups in the catalogue.</p></div></div><div class="DH-Heading2" id="index.xml-body.1_div.2_div.2"><h3 class="DH-Heading2"><span class="headingNumber">2.2. </span><span class="head">Visual feature representation</span></h3><div class="panel panel-default panel-figure"><img class="img-responsive" src="/static/data/188/10000201000003570000011DEDB4B719.png" alt="Figure 5. HOOSC computation at a sample position of the shape" class="graphic" /><div class="caption">Figure 5. HOOSC computation at a sample position of the shape</div></div><p>The HOOSC is a shape descriptor proposed in our research group for Maya glyphs (Roman-Rangel, 2011b). It is computed in two main steps (Fig. 5). First, the orientations of a set of sampled points are computed. Secondly, for a given sampled position, the histogram of local orientations are computed using a small number <span style="font-style:italic">Na</span> of angle bins forming a circular grid partition centred at each point. The HOOSC descriptor is obtained by concatenating all histograms, and applying per-ring normalization. Basic parameters are the spatial context <span style="font-style:italic">sc</span> defining the extent of the spatial partition; the number of rings <span style="font-style:italic">N</span> <span style="font-style:italic">r</span>; and the number <span style="font-style:italic">N</span> <span style="font-style:italic">s </span>of slices in a ring. With <span style="font-style:italic">N</span> <span style="font-style:italic">a</span> =8, <span style="font-style:italic">N</span> <span style="font-style:italic">r</span> =2, <span style="font-style:italic">N</span> <span style="font-style:italic">s</span>=8, HOOSC has 128 dimensions. We have used HOOSC for usual retrieval and categorization tasks (Hu et. al., 2015).</p></div><div class="DH-Heading2" id="index.xml-body.1_div.2_div.3"><h3 class="DH-Heading2"><span class="headingNumber">2.3. </span><span class="head">Dimensionality reduction: t-SNE</span></h3><p>Proposed in (Hinton and Roweis, 2002), SNE is a non-linear dimensionality reduction method. It relates the Euclidean distances of samples in high-dimensional space to the conditional probability for each point selecting one of the neighbours. In t-SNE (Van der Maaten and Hinton, 2008), these distributions are modelled as heavy-tailed t-distributions. t-SNE aims to find for each data point, a lower-dimensional projection such that the conditional probabilities in the projected space are as close as possible to those of the original space (measured with KL divergence (Kullback and Leibler, 1951)).</p><p>In our application, first, we project the BoW representation to a 30-dimensional space using PCA, then applied t-SNE to these projections to get 2-dimension mapping. t-SNE keeps track of the local structure of the data as it optimizes the clusters globally.</p></div></div><div class="DH-Heading1" id="index.xml-body.1_div.3"><h2 class="DH-Heading1"><span class="headingNumber">3. </span><span class="head">Results and discussion</span></h2><p>The full-scale visualization of the glyphs are available at <a class="link_ptr" href="https://www.idiap.ch/project/maaya/demos/t-sne"><span>https://www.idiap.ch/project/maaya/demos/t-sne</span></a>.</p><div class="DH-Heading2" id="index.xml-body.1_div.3_div.1"><h3 class="DH-Heading2"><span class="headingNumber">3.1. </span><span class="head">Glyph monument corpus structure</span></h3><div class="panel panel-default panel-figure"><img class="img-responsive" src="/static/data/188/100002010000044C0000046002AD45BC.png" alt="Figure 6. Monument data: t-SNE plots with visual representations obtained at four different spatial context levels" class="graphic" /><div class="caption">Figure 6. Monument data: t-SNE plots with visual representations obtained at four different spatial context levels</div></div><p>Fig. 6 shows the monument corpus. The region encoded in the visual descriptor varies from almost whole glyph (sc=1/1) to small local parts (sc=1/8). One question is how spatial context influences visualization of the representation. Regarding the visual clusters, with the most global representation (sc=1/1), our method extracts more distinct clusters, e.g. T229 and T126 in Fig. 7 (navy and magenta in Fig. 6 and 9). Please see Fig. 9 for roughly-coloured clusters of the glyphs. As the descriptor gets more local, the categories with common patterns mix up (Fig. 6). Yet, our method is able to capture meaningful common local parts and maps the samples based on these elements, i.e. parallel lines, hatches, and circles. </p><div class="panel panel-default panel-figure"><img class="img-responsive" src="/static/data/188/10000000000004E2000002EE99F1601A.png" alt="Figure 7. Monument data: Close-up of two clusters (T229 on the left and T126 on the right), corresponding to navy and magenta clusters in Fig. 6 with the most global HOOSC descriptor (sc=1/1)" class="graphic" /><div class="caption">Figure 7. Monument data: Close-up of two clusters (T229 on the left and T126 on the right), corresponding to navy and magenta clusters in Fig. 6 with the most global HOOSC descriptor (sc=1/1)</div></div><p>For Maya epigraphers in our team, a more neatly differentiated grouping of signs, e.g. obtained by HOOSC with sc=1/1 is preferable. However, work on the effects of parameter choice is required to obtain groupings that make more epigraphic sense. Clearer 'borderlines', less 'outliers,' and less 'intrusive' signs (e.g. T25 and T1) within each cluster would be desirable. Our results in this regard are preliminary, but they open promising research questions.</p><div class="panel panel-default panel-figure"><img class="img-responsive" src="/static/data/188/1000020100000618000002F87971B233.png" alt="Figure 8. Monument data: Close-up of two clusters (T59 on the left and T116 on the right), which exhibit smooth transition between samples corresponding to place or temporal variations" class="graphic" /><div class="caption">Figure 8. Monument data: Close-up of two clusters (T59 on the left and T116 on the right), which exhibit smooth transition between samples corresponding to place or temporal variations</div></div><p>Another important epigraphic point is that we observe interesting visual transitions between samples of the categories. Fig. 8 shows examples from category T59 and T116, which illustrate a smooth dilation of samples in one direction. These kind of observations are interesting for archaeologists, since they might correspond to modification of the glyph signs over time or place.</p><div class="panel panel-default panel-figure"><img class="img-responsive" src="/static/data/188/10000000000003EB0000050054BDC39D.png" alt="Figure 9. Monument data: Visualization of all class samples with the most global HOOSC descriptor (sc=1/1)" class="graphic" /><div class="caption">Figure 9. Monument data: Visualization of all class samples with the most global HOOSC descriptor (sc=1/1)</div></div></div><div class="DH-Heading2" id="index.xml-body.1_div.3_div.2"><h3 class="DH-Heading2"><span class="headingNumber">3.2. </span><span class="head"><span style="color:#000000">Glyph variants from Thompson catalogue</span></span></h3><div class="panel panel-default panel-figure"><img class="img-responsive" src="/static/data/188/10000201000006940000042C50C35A02.png" alt="Figure 10. Catalogue data: A visual cluster of main signs from the Thompson's catalogue, with the most global HOOSC descriptor (sc=1/1). Many of them are impersonated main signs that corresponds to gods or animals. In this part of the visualization, the upper left part has more visually complex variants than the rightmost samples" class="graphic" /><div class="caption">Figure 10. Catalogue data: A visual cluster of main signs from the Thompson's catalogue, with the most global HOOSC descriptor (sc=1/1). Many of them are impersonated main signs that corresponds to gods or animals. In this part of the visualization, the upper left part has more visually complex variants than the rightmost samples</div></div><p>From the visualization of glyph variants in Thompson's catalogue with the largest spatial context level (sc=1/1), we observe that visually similar categories are grouped together, while exhibiting smooth transitions. These transitions may correspond to some characteristics of the data. Fig. 10 shows a cluster of personified main signs in which degree of visual internal detail decreases in the indicated direction. We also observe separate visual clusters for hatched, horizontal and vertical glyphs. </p></div></div><div class="DH-Heading1" id="index.xml-body.1_div.4"><h2 class="DH-Heading1"><span class="headingNumber">4. </span><span class="head">Conclusion</span></h2><p>Our goal in this study is to help DH scholars to visualize data collections not as isolated elements, but in context (visually and semantically). Even though early catalogues are built based on visual similarities, i.e., (Thompson and Eric, 1962) or (Zimmermann, 1956) relied on graphic cards to study similar patterns, the categorization methods were poorly understood and were not easy to reconfigure.</p><p>Furthermore, due to the limited knowledge at the time about semantics and sign variants, these catalogues turned out to be inaccurate or outdated. Similarly, Gardiner’s list (Gardiner, 1957) is insufficient to elucidate sign variability in the 'Book of The Dead' (Budge, 1901).</p><p>With the proposed tool, however, considering details at different scales as semantic/diagnostic regions in the visualization can help archaeologists to discover semantic relations. In this way, overlapping notions such as 'colours', 'cardinal directions' and specific toponyms from earthly, heavenly or underworld realms can be studied in greater detail.</p><p>Finally, illustrating all variations with different visual focus in a fast and quantitative manner brings out the characteristics of signs. This also helps experts match samples from various sources (i.e. monuments, codices, and ceramic surfaces) to corpus data more efficiently; and trigger the decipherment of less frequent and damaged signs. Hence, our work is a step towards producing a more accurate and state-of-the-art sign catalogue.</p></div><div class="DH-Heading1" id="index.xml-body.1_div.5"><h2 class="DH-Heading1"><span class="headingNumber">5. </span><span class="head">Acknowledgements</span></h2><p>This work was funded by Swiss National Science Foundation as part of the MAAYA project. </p></div><!--TEI back--><div class="bibliogr" id="index.xml-back.1_div.1"><h2><span class="headingNumber"> </span></h2><div class="listhead">Bibliography</div><ol class="listBibl"><li id="index.xml-bibl-d30e505"><div class="biblfree"><span style="font-weight:bold">Belongie, S., Malik, J. and Puzicha, J.</span> (2002). Shape matching and object recognition using shape contexts. <span style="font-style:italic">IEEE Transactions on Pattern Analysis and Machine Intelligence</span>, <span style="font-weight:bold">24</span>(4): 509–22.</div></li><li id="index.xml-bibl-d30e517"><div class="biblfree"><span style="font-weight:bold">Budge, E. A. W.</span> (1901). <span style="font-style:italic">The Book of the Dead: An English Translation of the Chapters, Hymns, Etc. of the Theban Recension, with Introduction, Notes, Etc.</span> (Books on Egypt and Chaldaea). Open Court Pub.</div></li><li id="index.xml-bibl-d30e526"><div class="biblfree"><span style="font-weight:bold">Dalal, N. and Triggs, B.</span> (2005). <span style="font-style:italic">Histograms of Oriented Gradients for Human Detection. vol. 1. IEEE</span>, pp. 886–93.</div></li><li id="index.xml-bibl-d30e535"><div class="biblfree"><span style="font-weight:bold">Franken, M. and Gemert, J. C. van</span> (2013). <span style="font-style:italic">Automatic Egyptian hieroglyph recognition by retrieving images as texts</span>, ACM Press, pp. 765–68.</div></li><li id="index.xml-bibl-d30e545"><div class="biblfree"><span style="font-weight:bold">Gardiner, A. H.</span> (1957). <span style="font-style:italic">Egyptian Grammar: Being an Introduction to the Study of Hieroglyphs. 3d ed., rev</span>. Oxford: Griffith Institute, Ashmolean Museum.</div></li><li id="index.xml-bibl-d30e554"><div class="biblfree"><span style="font-weight:bold">Hinton, G. E. and Roweis, S. T.</span> (2002). <span style="font-style:italic">Stochastic neighbor embedding.</span> pp. 833–40.</div></li><li id="index.xml-bibl-d30e563"><div class="biblfree"><span style="font-weight:bold">Hu, R., Can, G., Pallan Gayol, C., Krempel, G., Spotak, J., Vail, G., Marchand-Maillet, S., Odobez, J.-M. and Gatica-Perez, D.</span> (2015). Multimedia Analysis and Access of Ancient Maya Epigraphy: Tools to support scholars on Maya hieroglyphics. <span style="font-style:italic">Signal Processing Magazine, IEEE</span>, <span style="font-weight:bold">32</span>(4): 75–84.</div></li><li id="index.xml-bibl-d30e575"><div class="biblfree"><span style="font-weight:bold">Kullback, S. and Leibler, R. A.</span> (1951). On information and sufficiency. <span style="font-style:italic">The Annals of Mathematical Statistics</span>, <span style="font-weight:bold">22</span>(1): 79–86.</div></li><li id="index.xml-bibl-d30e587"><div class="biblfree"><span style="font-weight:bold">Lowe, D. G.</span> (2004). Distinctive image features from scale-invariant keypoints. <span style="font-style:italic">International Journal of Computer Vision</span>, <span style="font-weight:bold">60</span>(2): 91–110.</div></li><li id="index.xml-bibl-d30e599"><div class="biblfree"><span style="font-weight:bold">Maaten, L. Van der and Hinton, G.</span> (2008). Visualizing data using t-SNE. <span style="font-style:italic">Journal of Machine Learning Research</span>, <span style="font-weight:bold">9</span>(2579-2605): 85.</div></li><li id="index.xml-bibl-d30e612"><div class="biblfree"><span style="font-weight:bold">Macri, M. J. and Looper, M. G.</span> (2003). <span style="font-style:italic">The New Catalog of Maya Hieroglyphs: The Classic Period Inscriptions</span>. University of Oklahoma Press. Vol. <span style="font-weight:bold">1</span>.</div></li><li id="index.xml-bibl-d30e624"><div class="biblfree"><span style="font-weight:bold">Roman-Rangel, E., Odobez, J.-M. and Gatica-Perez, D.</span> (2013). Evaluating shape descriptors for detection of maya hieroglyphs. <span style="font-style:italic">Pattern Recognition</span>. Springer, pp. 145–54.</div></li><li id="index.xml-bibl-d30e633"><div class="biblfree"><span style="font-weight:bold">Roman-Rangel, E., Pallan, C., Odobez, J.-M. and Gatica-Perez, D.</span> (2011a). Analyzing ancient maya glyph collections with contextual shape descriptors. <span style="font-style:italic">International Journal of Computer Vision</span>, <span style="font-weight:bold">94</span>(1): 101–17.</div></li><li id="index.xml-bibl-d30e645"><div class="biblfree"><span style="font-weight:bold">Roman-Rangel, E., Pallan Gayol, C., Odobez, J.-M. and Gatica-Perez, D.</span> (2011b). <span style="font-style:italic">Searching the past: an improved shape descriptor to retrieve Maya hieroglyphs. ACM</span>, pp. 163–72.</div></li><li id="index.xml-bibl-d30e654"><div class="biblfree"><span style="font-weight:bold">Thompson, J. E. S. and Eric, S.</span> (1962). <span style="font-style:italic">A Catalog of Maya Hieroglyphs</span>. University of Oklahoma Press Norman.</div></li><li id="index.xml-bibl-d30e663"><div class="biblfree"><span style="font-weight:bold">Vail, G. and Hernández, C.</span> (2013). The Maya Codices Database, Version 4.1. <span style="font-style:italic">A Website and Database Available at: http://www.mayacodices.org/</span>.</div></li><li id="index.xml-bibl-d30e673"><div class="biblfree"><span style="font-weight:bold">Zimmermann, G.</span> (1956). <span style="font-style:italic">Die Hieroglyphen Der Maya-Handschriften</span>. (Abhandlungen Aus Dem Gebiet Der Auslandskunde / Reihe B: Völkerkunde, Kulturgeschichte Und Sprachen). De Gruyter.</div></li></ol></div></body></html>
		</div>
		<div class="col-lg-2">
		</div>
	</div>


		</div>
		<script>
		$(document).ready(function(){
			$('[data-toggle="tooltip"]').tooltip();
		});
		</script>			
	</body>
</html>