<!DOCTYPE html>



<html lang="en">
	<head>
		<meta charset="utf-8">	
		<meta name="viewport" content="width=device-width, initial_scale=1">
		<title>DH 2016 Abstracts</title>
		<link rel="stylesheet" href="/static/bootstrap/css/bootstrap.min.css">
		<link rel="stylesheet" href="/static/bootstrap/css/bootstrap-theme.min.css">
		<link rel="stylesheet" href="/static/css/abstracts.css">
		<script src="/static/jquery/jquery-2.2.4.min.js"></script>
		<script src="/static/bootstrap/js/bootstrap.min.js"></script>
	</head>
	<body>
		<div class="container">
			<div class="row">
				<a href="http://dh2016.adho.org"><img src="/static/images/logo_4.png" class="img-responsive"></a>
			</div>
			<div class="row">
				<ol class="breadcrumb">
					
						<li><a href="http://www.dh2016.adho.org">DH Home</a></li>
					
						<li><a href="/abstracts/">Abstracts</a></li>
					
						<li><a href="/abstracts/10">10</a></li>
					
				</ol>
			</div>
					
			
	<div class="row">
		<div class="col-lg-2">
		</div>
		<div class="col-lg-8 col-xs-12">
			<button class="btn btn-default" data-toggle="collapse" data-target="#head" style="margin-bottom: 5px;">Show info</button>
			<button class="btn btn-default" data-toggle="collapse" data-target="#cite" style="margin-bottom: 5px;">How to cite</button>
			<a href="/static/data/705.xml" class="btn btn-default" role="button" style="margin-bottom: 5px;" download="10.xml">XML Version</a>
			<div class="panel panel-success collapse" style="padding: 10px; border=none;" id="head">
				<div>
					<b>Title: </b>Music Information Retrieval Algorithms for Oral History Collections
					<br>
					<b>Authors: </b>
					Sharon Webb, Chris Kiefer, Ben Jackson, Alice Eldridge, James Baker
					<br>
					<b>Category: </b>Paper:Pre-Conference Workshop and Tutorial
					<br>
					<b>Keywords: </b>music information retrieval
				</div>
			</div>
			<div class="collapse" id="cite">
				<b>Webb, S., Kiefer, C., Jackson, B., Eldridge, A., Baker, J.</b> (2016). Music Information Retrieval Algorithms for Oral History Collections. In <i>Digital Humanities 2016: Conference Abstracts</i>. Jagiellonian University & Pedagogical University, Kraków, 
				
					pp. 948-949.
				
			</div>
		</div>
		<div class="col-lg-2">
		</div>
	</div>
	<div class="row">
		<div class="col-lg-2">
		</div>
		<div class="col-lg-8">	
			<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8" /><!--THIS FILE IS GENERATED FROM AN XML MASTER. DO NOT EDIT (5)--><title>Music Information Retrieval Algorithms for Oral History Collections</title><meta name="author" content="Sharon Webb , Chris Kiefer , Ben Jackson , Alice Eldridge , and James Baker" /><meta name="generator" content="Text Encoding Initiative Consortium XSLT stylesheets" /><meta name="DC.Title" content="Music Information Retrieval Algorithms for Oral History Collections" /><meta name="DC.Type" content="Text" /><meta name="DC.Format" content="text/html" /><link href="http://www.tei-c.org/release/xml/tei/stylesheet/tei.css" rel="stylesheet" type="text/css" /><link rel="stylesheet" media="print" type="text/css" href="http://www.tei-c.org/release/xml/tei/stylesheet/tei-print.css" /></head><body class="simple" id="TOP"><div class="stdheader autogenerated"><h1 class="maintitle">Music Information Retrieval Algorithms for Oral History Collections</h1></div><!--TEI front--><!--TEI body--><p>Digital humanities, as a largely text based domain, often treats audio files as texts, retrieving semantic information in order to categorise, sort, and discover audio. This workshop will treat audio as audio. Taking oral history collections from the University of Sussex Archive of Resistance Testimony as a test case, participants will be lead through the use of Music Information Retrieval (MIR) approaches to categorise, sort, and support their discovery of an audio collection. Participants will also be supported in planning the extension of these approaches to explore audio collections that they know or work with.</p><p>All instructors for this workshop are from the new inter-disciplinary Sussex Humanities Lab at the University of Sussex. The workshop combines the diverse interests of the instructors to focus on the application of music technology to history and stems from this inherently collaborative environment.</p><p>Oral history best practice publications and resources often focus on the application and use of digital methods and tools to create, store and manage audio, audio-visual, and subsequent text files. They recommend, for example, standards for file formats, metadata and text encoding, software for audio to text conversion, and database and content management systems. However, while a number of projects provide innovative and useful tools that challenge the privilege of the text (i.e. Oral History Metadata Synchroniser), the majority of projects rely on the ability to encode an oral history interview to carry out further analysis using digital tools and methods. The analysis, therefore, is based on the text surrogate rather than the original audio source, but as Alessandro Portellii states this focus denies the ‘orality of the oral source’.</p><p>Text encodings or transcripts of oral history interviews have their obvious advantages - they are easier to anonymise, distribute and store, and we have established techniques for text analysis. However, there are indications within the community that the privilege of this text based approach should be questioned given the ever increasing possibility for computational analysis of audio. This is evident in the Oral History Society’s recent call for papers which remarks that the ‘auditory dimension of oral history was for decades notoriously underused’.</p><p>In light of this loss of context and information this workshop will explore the original sources for the richer datasets which they afford. The field of MIR provides this opportunity. MIR draws from digital audio signal processing, pattern recognition, psychology of perception, software system design, and machine learning to develop algorithms that enable computers to ‘listen’ to and abstract high-level musical information from low-level audio data. Just as human listeners can recognize pitch, tempo, chords, genre, song structure etc, MIR algorithms are capable of recognizing and extracting this information, enabling systems to perform extensive sorting, searching, music recommendation, metadata generation, transcription on large data sets. Deployed initially in musicology research and more recently for automatic recommender systems, the research potential for MIR tools in non-musical audio data mining is being recognised (e.g. analysing bio-acoustic data for ecological purposes) but yet to be fully explored in the humanities.</p><p>The aim of this workshop is to help the digital humanities community explore the possibilities of MIR in a practical and methodological fashion within context of oral history collections. Our participatory design approach enables development for a broader scope of problems and support participants to challenge current methodologies for oral history analysis. We seek to apply an objective analysis based on the content of the source material in its entirety and complement or challenge human and text based analysis with computational methods. By applying MIR algorithms to a field that traditionally privileges text we hope to add new understandings and interpretations to rich audio resources.</p><!--TEI back--><div class="bibliogr" id="index.xml-back.1_div.1"><h2><span class="headingNumber"> </span></h2><div class="listhead">Bibliography</div><ol class="listBibl"><li id="index.xml-bibl-d30e239"><div class="biblfree"><span style="font-weight:bold">Grele, R</span>. (2007). Oral History as Evidence. In Thomas L. Carlton, T.L., Lois E. Myers, L.E., &amp; Sharpless, R. (eds) <span style="font-style:italic">History of Oral History: Foundations and Methodology</span>. Plymouth:The Rowman &amp; Littlefield Publishing Group, p. 33-94</div></li></ol></div></body></html>
		</div>
		<div class="col-lg-2">
		</div>
	</div>


		</div>
		<script>
		$(document).ready(function(){
			$('[data-toggle="tooltip"]').tooltip();
		});
		</script>			
	</body>
</html>