<!DOCTYPE html>



<html lang="en">
	<head>
		<meta charset="utf-8">	
		<meta name="viewport" content="width=device-width, initial_scale=1">
		<title>DH 2016 Abstracts</title>
		<link rel="stylesheet" href="/static/bootstrap/css/bootstrap.min.css">
		<link rel="stylesheet" href="/static/bootstrap/css/bootstrap-theme.min.css">
		<link rel="stylesheet" href="/static/css/abstracts.css">
		<script src="/static/jquery/jquery-2.2.4.min.js"></script>
		<script src="/static/bootstrap/js/bootstrap.min.js"></script>
	</head>
	<body>
		<div class="container">
			<div class="row">
				<a href="http://dh2016.adho.org"><img src="/static/images/logo_4.png" class="img-responsive"></a>
			</div>
			<div class="row">
				<ol class="breadcrumb">
					
						<li><a href="http://www.dh2016.adho.org">DH Home</a></li>
					
						<li><a href="/abstracts/">Abstracts</a></li>
					
						<li><a href="/abstracts/63">63</a></li>
					
				</ol>
			</div>
					
			
	<div class="row">
		<div class="col-lg-2">
		</div>
		<div class="col-lg-8 col-xs-12">
			<button class="btn btn-default" data-toggle="collapse" data-target="#head" style="margin-bottom: 5px;">Show info</button>
			<button class="btn btn-default" data-toggle="collapse" data-target="#cite" style="margin-bottom: 5px;">How to cite</button>
			<a href="/static/data/486.xml" class="btn btn-default" role="button" style="margin-bottom: 5px;" download="63.xml">XML Version</a>
			<div class="panel panel-success collapse" style="padding: 10px; border=none;" id="head">
				<div>
					<b>Title: </b>Adding Semantics To Comics Using A Crowdsourcing Approach
					<br>
					<b>Authors: </b>
					Mihnea Tufis
					<br>
					<b>Category: </b>Paper:Short Paper
					<br>
					<b>Keywords: </b>crowdsourcing, comics, annotation, data quality
				</div>
			</div>
			<div class="collapse" id="cite">
				<b>Tufis, M.</b> (2016). Adding Semantics To Comics Using A Crowdsourcing Approach. In <i>Digital Humanities 2016: Conference Abstracts</i>. Jagiellonian University & Pedagogical University, Kraków, 
				
					pp. 694-697.
				
			</div>
		</div>
		<div class="col-lg-2">
		</div>
	</div>
	<div class="row">
		<div class="col-lg-2">
		</div>
		<div class="col-lg-8">	
			<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8" /><!--THIS FILE IS GENERATED FROM AN XML MASTER. DO NOT EDIT (5)--><title>Adding Semantics To Comics Using A Crowdsourcing Approach</title><meta name="author" content="Mihnea Tufis" /><meta name="generator" content="Text Encoding Initiative Consortium XSLT stylesheets" /><meta name="DC.Title" content="Adding Semantics To Comics Using A Crowdsourcing Approach" /><meta name="DC.Type" content="Text" /><meta name="DC.Format" content="text/html" /><link href="http://www.tei-c.org/release/xml/tei/stylesheet/tei.css" rel="stylesheet" type="text/css" /><link rel="stylesheet" media="print" type="text/css" href="http://www.tei-c.org/release/xml/tei/stylesheet/tei-print.css" /></head><body class="simple" id="TOP"><div class="stdheader autogenerated"><h1 class="maintitle">Adding Semantics To Comics Using A Crowdsourcing Approach</h1></div><!--TEI front--><!--TEI body--><div class="DH-Heading1" id="index.xml-body.1_div.1"><h2 class="DH-Heading1"><span class="headingNumber">1. </span><span class="head">Introduction</span></h2><p>With over 85 million print units sold in 2014 for the top 300 comic book titles only, the comics industry is reaching a new high for the first time since 2007 (before the economical crisis). And this doesn’t include the increasingly popular graphic novels or the increasingly more accessible digital comics. The resurgence of comics and the establishment of the graphic novel as a literary genre prompted Humanities scholars to turn their attention on comics as a medium. In this paper, we address the difficulty of creating a digitized corpus by using a crowdsourced approach for annotating comic books. The resulting XML-based encodings could assist not only researchers, but publishers and collection curators equally.</p></div><div class="DH-Heading1" id="index.xml-body.1_div.2"><h2 class="DH-Heading1"><span class="headingNumber">2. </span><span class="head">Motivation</span></h2><p>Our approach should provide Digital Humanities (DH) scholars with a (currently missing) structured, annotated corpus; this should enable or speed up research related to the comics and sequential art theory: identifying the rhythm of the narration based on the shape, size or number of panels and its relation to the depicted action, investigations about the style of comics authors, historical periods, cultural movements etc.</p><p>Curators and collectors (professional or amateur) of physical or online comics collections would be provided with a structured content which could be more easily integrated within their collections or databases. This may assist them into enlarging public or private databases of characters or comics series and enable the creation of artefacts such as comic books dictionaries, search indices and dictionaries of onomatopoeia. A certain number of projects are already in place and could greatly benefit from the creation of comic books annotations. We mention here the Grand Comics Database <span id="ftn1_return"><a class="notelink" title="http://www.comics.org/" href="#ftn1"><sup>1</sup></a></span> (an online database of printed comics), Comic Book Database <span id="ftn2_return"><a class="notelink" title="http://comicbookdb.com/" href="#ftn2"><sup>2</sup></a></span>, Digital Comics Museum <span id="ftn3_return"><a class="notelink" title="http://digitalcomicmuseum.com/" href="#ftn3"><sup>3</sup></a></span> (a collection of scanned public domain comics from the Golden Age) or the Catalogue of the <span style="font-style:italic">Cité Internationale de la Bande Dessinée et de l’Image</span> <span id="ftn4_return"><a class="notelink" title="http://www.citebd.org/" href="#ftn4"><sup>4</sup></a></span> from Angoulême.</p><p>From a publishing perspective, current standard specifications related to digital comics, such as EPUB’s Region Based Navigation (Conboy et al., 2014) and Metadata Structural Vocabulary for Comics (Ichikawa et al., 2014) are taking care exclusively of the presentation layer (i.e. rendering a publication on a screen device). But the artistic nature of comics and the great potential digital comics have already showcased allow us to go beyond simple content presentation. We believe that the data we are collecting will allow publishers and digital comics authors to create better, enhanced content and in the end a superior reading experience.</p></div><div class="DH-Heading1" id="index.xml-body.1_div.3"><h2 class="DH-Heading1"><span class="headingNumber">3. </span><span class="head">Crowdsourcing Annotations for Comics</span></h2><p>Participants to our crowdsourcing experiment (Azavea, 2014; Sharma, 2010) are digital comics readers. Previous research has identified expertise sharing, belonging to a community and helping with a research project as strong motivating factors for crowdsourcing participants (Dunn et al., 2012). In addition, our industrial partner will incentivize participants with product vouchers for their platform <span id="ftn5_return"><a class="notelink" title="Actialuna – Sequencity: https://www.sequencity.com" href="#ftn5"><sup>5</sup></a></span>.</p><p>The tasks we propose are organized around a set of questions regarding a series of comics-related topics (Eisner, 1985; Ichikawa et al., 2014) on which computer algorithms are not performing well enough: complex page layouts, identification of narration elements (characters, places, events, objects), stylistic elements (balloon shapes, onomatopoeia, movement lines).</p><div class="panel panel-default panel-figure"><img class="img-responsive" src="/static/data/486/image1.png" alt="Figure 1. The 4 key annotation themes" class="inline" /><div class="caption">Figure 1. The 4 key annotation themes</div></div><p>We aggregate the answers (Feng et al., 2014; Snow et al., 2008) taking into account the reliability of an annotator in a given context (task difficulty, user experience with the task, type of question) and the agreement between the annotators (Nowak et al., 2010). A quality score is thus generated for each annotation, with the best of them being selected as solutions.</p><p>We subsequently are able to generate the ComicsML encodings (Walsh, 2012). This XML derived format is particularly useful since it’s based on the already widespread Text Encoding Initiative (TEI), allowing for declarations of page structure and composition, panels, characters, text (in all the varieties hosted by the comics medium: different types of balloons, diegetic text, onomatopoeia), events and even panel-to-panel transitions.</p><div class="DH-Heading2" id="index.xml-body.1_div.3_div.1"><h3 class="DH-Heading2"><span class="headingNumber">3.1. </span><span class="head">Page structure</span></h3><p>The annotators are presented with a simple interface (Fig. 2) in which they will have to make a choice between a set of suggested grid layouts. These layouts are the output of applying the automatic frame extraction algorithm developed by (Rigaud et al., 2011). Alternatively, for complex page layouts, they will be asked to draw the page layout themselves.</p></div><div class="DH-Heading2" id="index.xml-body.1_div.3_div.2"><h3 class="DH-Heading2"><span class="headingNumber">3.2. </span><span class="head">Character identification</span></h3><p>At this step, we ask the “crowd” to simply enumerate all the characters they can identify in the current page. Characters are identified by reading their names in the text, recognising them from experience or simply giving a general statement about the character (e.g., “ <span style="font-style:italic">masked man</span>” may be referring to <span style="font-style:italic">Batman</span>). Using state of the art symbolic learning algorithms we fusion generic and specific information (e.g. if <span style="font-style:italic">Batman</span> and “<span style="font-style:italic">masked man</span>” both have high quality scores in the same context, they will both denote the same concept and will be considered as valid annotations).</p></div><div class="DH-Heading2" id="index.xml-body.1_div.3_div.3"><h3 class="DH-Heading2"><span class="headingNumber">3.3. </span><span class="head">Places identification</span></h3><p>We ask the annotators to simply enumerate all the places they can recognise on the current page. We are particularly looking for named places (e.g., <span style="font-style:italic">Gotham City, NY, planet Mars</span>), but will also ask the annotator to mark any generic place that he might consider important for the scenes in the page (e.g., “ <span style="font-style:italic">the interior of a bank</span>“ [in case of a robbery], “<span style="font-style:italic">inside a space ship</span>” [in case of a battle in space]). These are exactly the kind of very specific annotation tasks for which state of the art image recognition algorithms are expected to fail.</p></div><div class="DH-Heading2" id="index.xml-body.1_div.3_div.4"><h3 class="DH-Heading2"><span class="headingNumber">3.4. </span><span class="head">Events identification</span></h3><p>This is yet another highly specific recognition task. Annotators are asked to describe the most important events occurring in the page. The solutions generated at this step, together with the annotations obtained in the previous steps will be used to further build the ComicsML encoding of the page.</p><p>Comics scholar Scott McCloud stresses the role of ellipsis (“the blood in the gutters“ – the space between two panels) as an artistic mean for authors to engage their readers, and describes a typology of these transition spaces (McCloud, 1993). ComicsML allows us to declare such transitions through the #ana attribute of the cbml:panel element, giving us the possibility to investigate their use and their distribution across different cultural spaces (France/Belgium, Japan/Korea, USA).</p><div class="panel panel-default panel-figure"><img class="img-responsive" src="/static/data/486/image2.png" alt="Figure 2. Annotation interface (drawing page structure-left, narration elements-right)" class="inline" /><img class="img-responsive" src="/static/data/486/image3.png" alt="Figure 2. Annotation interface (drawing page structure-left, narration elements-right)" class="inline" /><div class="caption">Figure 2. Annotation interface (drawing page structure-left, narration elements-right)</div></div></div><div class="DH-Heading2" id="index.xml-body.1_div.3_div.5"><h3 class="DH-Heading2"><span class="headingNumber">3.5. </span><span class="head">Non-visual cues</span></h3><p>Comics are a special medium, making use of the visual to depict all other non-visual senses, with the help of different drawing “tricks”, such as:</p><ul><li class="item">Smoke coming out of a cigarette may engage the reader’s smelling sense</li><li class="item">Onomatopoeia form a particular language of their own; comics and especially manga authors have proven great creativity when it comes to expressing different sounds via stylised text (e.g., “ <span style="font-style:italic">POW!</span>” – punch, “ <span style="font-style:italic">BAM!</span>” – gunshot)</li><li class="item">Horizontal lines around a car suggest the car is moving at high speed, while around a ball, they express the ball’s movement</li></ul><p>Researchers could study, for instance, the drawing style of an author and his use of non-visual cues, and go as far as creating onomatopoeia dictionaries for comics (to our knowledge, such dictionaries already exist for manga, but not for American nor European comics).</p><p>At the end of this stage, we should be able to generate a reasonably complete ComicsML encoding of the current page (see Fig. 3).</p><div class="panel panel-default panel-figure"><img class="img-responsive" src="/static/data/486/image4.png" alt="Figure 3. A fragment of the ComicsML encoding for the page presented above" class="inline" /><div class="caption">Figure 3. A fragment of the ComicsML encoding for the page presented above</div></div></div></div><div class="DH-Heading1" id="index.xml-body.1_div.4"><h2 class="DH-Heading1"><span class="headingNumber">4. </span><span class="head">Conclusions</span></h2><p>We have presented the outline of our crowdsourced annotation system for comics, as well as details of how we have designed our tasks, having in mind three main aspects: the limits of current digital comic book formats, the specifications behind the ComicsML metadata schema and theoretical principles of comics as a medium (Eisner, 1985). Last, we have presented the way in which the collected results are merged into the final ComicsML encoding and have briefly discussed some potential applications.</p></div><!--TEI back--><div class="bibliogr" id="index.xml-back.1_div.1"><h2><span class="headingNumber"> </span></h2><div class="listhead">Bibliography</div><ol class="listBibl"><li id="index.xml-bibl-d30e370"><div class="biblfree"><span style="font-weight:bold">Azavea, SciStarter.</span> (2014). <span style="font-style:italic">Citizen Science Data Factory, Part 1: Data Collection Platform Evaluation</span>.</div></li><li id="index.xml-bibl-d30e379"><div class="biblfree"><span style="font-weight:bold">Dunn, S. and Hedges, M.</span> (2012). Engaging the Crowd with Humanities Research. <span style="font-style:italic">Crowd-Sourcing Scoping Study</span>. Centre for e-Research, Dept. of Digital Humanities – King’s College, London.</div></li><li id="index.xml-bibl-d30e388"><div class="biblfree"><span style="font-weight:bold">Conboy, G., Duga, B., Gardeur, H., Kanai, T., Kopp, M., Kroupa, B., Lester, J., Garrish, M., Murata, M. and O’Connor E.</span> (2014). <span style="font-style:italic">EPUB Region Based Navigation 1.0</span>. <a class="link_ref" href="http://www.idpf.org/epub/renditions/region-nav/">http://www.idpf.org/epub/renditions/region-nav/</a> (accessed 5 March 2016).</div></li><li id="index.xml-bibl-d30e400"><div class="biblfree"><span style="font-weight:bold">Eisner, W. (1985).</span> <span style="font-style:italic">Comics and Sequential Art: Principles and Practices From the Legendary Cartoonist</span>. Norton&amp;Company, USA&amp;U.K.</div></li><li id="index.xml-bibl-d30e410"><div class="biblfree"><span style="font-weight:bold">Feng, D., Sveva, B. and Zajac, R. (2009).</span> Acquiring High Quality Non-Expert Knowledge from On-demand Workforce. <span style="font-style:italic">People’s Web Meets NLP-2009</span>, ACL (2009), 51-56.</div></li><li id="index.xml-bibl-d30e419"><div class="biblfree"><span style="font-weight:bold">Ichikawa, D., Kasdorf, B, Kopp, M. and Kroupa, B.</span> (2014). <span style="font-style:italic">EPUB Region Based Navigation Markup Guide 1.0</span>. <a class="link_ref" href="http://www.idpf.org/epub/guides/region-nav-markup/">http://www.idpf.org/epub/guides/region-nav-markup/</a> (accessed 5 March 2016).</div></li><li id="index.xml-bibl-d30e431"><div class="biblfree"><span style="font-weight:bold">McCloud, S.</span> (1993). <span style="font-style:italic">Understanding Comics – The Invisible Art</span>, Harper Collins, USA.</div></li><li id="index.xml-bibl-d30e440"><div class="biblfree"><span style="font-weight:bold">Nowak, S. and Ruger, S.</span> (2010) How reliable are annotations via crowdsourcing? A study about inter-annotator agreement for multi-label image annotation. In <span style="font-style:italic">Proc. MIR-2010</span>, ACM, 557-566.</div></li><li id="index.xml-bibl-d30e449"><div class="biblfree"><span style="font-weight:bold">Rigaud, C., Tsopze, N., Burie, J.-C. and Ogier, J.-M.</span> (2011). Robust text and frame extraction from comic books. <span style="font-style:italic">GREC-2011</span>, Springer, 129-138.</div></li><li id="index.xml-bibl-d30e458"><div class="biblfree"><span style="font-weight:bold">Sharma, A.</span> (2010). Crowdsourcing Critical Success Factor Model: Strategies to harness the collective intelligence of the crowd. Working paper.</div></li><li id="index.xml-bibl-d30e465"><div class="biblfree"><span style="font-weight:bold">Snow, R., O’Connor, B., Jurafsky, D. and Ng, A.Y.</span> (2008). Cheap and Fast – But is it Good? Evaluating Non-Expert Annotations for Natural Language Tasks. <span style="font-style:italic">EMNLP-2008</span>, ACM, 254-263.</div></li><li id="index.xml-bibl-d30e474"><div class="biblfree"><span style="font-weight:bold">Walsh, J.A.</span> (2012). Comic Book Markup Language: an Introduction and Rationale. <span style="font-style:italic">DHQ-6</span>, 1. <a class="link_ref" href="http://www.digitalhumanities.org/dhq/vol/6/1/000117/000117.html">http://www.digitalhumanities.org/dhq/vol/6/1/000117/000117.html</a> (accessed 5 March 2016).</div></li></ol></div><!--Notes in [TEI]--><div class="notes"><div class="noteHeading">Notes</div><div class="note" id="ftn1"><span class="noteLabel">1. </span><div class="noteBody"><p class="footnote text">http://www.comics.org/</p></div></div><div class="note" id="ftn2"><span class="noteLabel">2. </span><div class="noteBody"><p class="footnote text">http://comicbookdb.com/</p></div></div><div class="note" id="ftn3"><span class="noteLabel">3. </span><div class="noteBody"><p class="footnote text">http://digitalcomicmuseum.com/</p></div></div><div class="note" id="ftn4"><span class="noteLabel">4. </span><div class="noteBody"><p class="footnote text">http://www.citebd.org/</p></div></div><div class="note" id="ftn5"><span class="noteLabel">5. </span><div class="noteBody"><p class="footnote text">Actialuna – Sequencity: https://www.sequencity.com</p></div></div></div></body></html>
		</div>
		<div class="col-lg-2">
		</div>
	</div>


		</div>
		<script>
		$(document).ready(function(){
			$('[data-toggle="tooltip"]').tooltip();
		});
		</script>			
	</body>
</html>