<!DOCTYPE html>



<html lang="en">
	<head>
		<meta charset="utf-8">	
		<meta name="viewport" content="width=device-width, initial_scale=1">
		<title>DH 2016 Abstracts</title>
		<link rel="stylesheet" href="/static/bootstrap/css/bootstrap.min.css">
		<link rel="stylesheet" href="/static/bootstrap/css/bootstrap-theme.min.css">
		<link rel="stylesheet" href="/static/css/abstracts.css">
		<script src="/static/jquery/jquery-2.2.4.min.js"></script>
		<script src="/static/bootstrap/js/bootstrap.min.js"></script>
	</head>
	<body>
		<div class="container">
			<div class="row">
				<a href="http://dh2016.adho.org"><img src="/static/images/logo_4.png" class="img-responsive"></a>
			</div>
			<div class="row">
				<ol class="breadcrumb">
					
						<li><a href="http://www.dh2016.adho.org">DH Home</a></li>
					
						<li><a href="/abstracts/">Abstracts</a></li>
					
						<li><a href="/abstracts/12">12</a></li>
					
				</ol>
			</div>
					
			
	<div class="row">
		<div class="col-lg-2">
		</div>
		<div class="col-lg-8 col-xs-12">
			<button class="btn btn-default" data-toggle="collapse" data-target="#head" style="margin-bottom: 5px;">Show info</button>
			<button class="btn btn-default" data-toggle="collapse" data-target="#cite" style="margin-bottom: 5px;">How to cite</button>
			<a href="/static/data/458.xml" class="btn btn-default" role="button" style="margin-bottom: 5px;" download="12.xml">XML Version</a>
			<div class="panel panel-success collapse" style="padding: 10px; border=none;" id="head">
				<div>
					<b>Title: </b>Tool-based Identification of Melodic Patterns in MusicXML Documents
					<br>
					<b>Authors: </b>
					Manuel Burghardt, Lukas Lamm, David Lechler, Matthias Schneider, Tobias Semmelmann
					<br>
					<b>Category: </b>Paper:Short Paper
					<br>
					<b>Keywords: </b>music information retrieval, melodic similarity, melodic patterns
				</div>
			</div>
			<div class="collapse" id="cite">
				<b>Burghardt, M., Lamm, L., Lechler, D., Schneider, M., Semmelmann, T.</b> (2016). Tool-based Identification of Melodic Patterns in MusicXML Documents. In <i>Digital Humanities 2016: Conference Abstracts</i>. Jagiellonian University & Pedagogical University, Kraków, 
				
					pp. 440-442.
				
			</div>
		</div>
		<div class="col-lg-2">
		</div>
	</div>
	<div class="row">
		<div class="col-lg-2">
		</div>
		<div class="col-lg-8">	
			<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8" /><!--THIS FILE IS GENERATED FROM AN XML MASTER. DO NOT EDIT (5)--><title>Tool-based Identification of Melodic Patterns in MusicXML Documents</title><meta name="author" content="Manuel Burghardt , Lukas Lamm , David Lechler , Matthias Schneider , and Tobias Semmelmann" /><meta name="generator" content="Text Encoding Initiative Consortium XSLT stylesheets" /><meta name="DC.Title" content="Tool-based Identification of Melodic Patterns in MusicXML Documents" /><meta name="DC.Type" content="Text" /><meta name="DC.Format" content="text/html" /><link href="http://www.tei-c.org/release/xml/tei/stylesheet/tei.css" rel="stylesheet" type="text/css" /><link rel="stylesheet" media="print" type="text/css" href="http://www.tei-c.org/release/xml/tei/stylesheet/tei-print.css" /></head><body class="simple" id="TOP"><div class="stdheader autogenerated"><h1 class="maintitle">Tool-based Identification of Melodic Patterns in MusicXML Documents</h1></div><!--TEI front--><!--TEI body--><div class="DH-Heading1" id="index.xml-body.1_div.1"><h2 class="DH-Heading1"><span class="headingNumber">1. </span><span class="head">Introduction: Digital musicology</span></h2><p>Computer-based methods in musicology have been around at least since the 1980s <span id="ftn1_return"><a class="notelink" title="The popular series „Computing in Musicology“ started around 1985. For an overview of all volumes of the series cf. http://www.ccarh.org/publications/b…" href="#ftn1"><sup>1</sup></a></span>. Besides the creation of digital editions (cf. Kepper et al., 2014; Veit, 2015), scholars in this area of study have also been interested in quantitative approaches for musicological analyses (cf. Müllensiefen and Frieler, 2004; Vigilanti, 2007). Such quantitative analyses rely on music information retrieval (MIR) systems, which can be used to search collections of songs according to different musicological parameters. There are many examples for existing MIR systems, all with specific strengths and weaknesses. Among the main downsides of such systems are:</p><ul><li class="item"><span style="font-weight:bold">Usability problems</span>, i.e. tools are cumbersome to use, as they oftentimes only provide a command-line interface and also require some basic programming skills to utilize them; example: Humdrum <span id="ftn2_return"><a class="notelink" title="http://www.humdrum.org/" href="#ftn2"><sup>2</sup></a></span></li><li class="item"><span style="font-weight:bold">Restricted scope of querying</span>, i.e. tools can only be used to search for musical incipits; examples: RISM <span id="ftn3_return"><a class="notelink" title="https://opac.rism.info/" href="#ftn3"><sup>3</sup></a></span>, HymnQuest <span id="ftn4_return"><a class="notelink" title="http://hymnquest.com/" href="#ftn4"><sup>4</sup></a></span></li><li class="item"><span style="font-weight:bold">Restricted song collection</span>, i.e. tools can only be used for specific collections of music files; various examples of MIR tools for specific collections are described in Typke et al. (2005)</li></ul><p>A particularly promising MIR tool can be found in Peachnote <span id="ftn5_return"><a class="notelink" title="http://www.peachnote.com/" href="#ftn5"><sup>5</sup></a></span> (Viro, 2011), which uses optical music recognition (OMR) software to index more than one million sheets from the Petrucci Music Library <span id="ftn6_return"><a class="notelink" title="http://imslp.org/" href="#ftn6"><sup>6</sup></a></span>, aiming to provide a search interface for musicology which can be seen as an analog of the Google Books Ngram Viewer <span id="ftn7_return"><a class="notelink" title="https://books.google.com/ngrams" href="#ftn7"><sup>7</sup></a></span>. Despite many existing software solutions, we believe that accurate OMR is still a major challenge in digital musicology. At the same time, there are numerous databases <span id="ftn8_return"><a class="notelink" title="http://www.musicxml.com/music-in-musicxml/" href="#ftn8"><sup>8</sup></a></span> at hand, that provide machine-readable music documents, fully annotated with MusicXML (Good, 2001) markup.</p><p>On this account, we designed MusicXML Analyzer, a generic MIR system that is trying to overcome the weaknesses of existing MIR tools, and that allows for the analysis of arbitrary documents encoded in MusicXML format. </p></div><div class="DH-Heading1" id="index.xml-body.1_div.2"><h2 class="DH-Heading1"><span class="headingNumber">2. </span><span class="head">MusicXML Analyzer: Basic functionality and implementation details</span></h2><p>MusicXML Analyzer can be used to analyze songs in a quantitative manner, and to search for specific melodic patterns in a collection of songs. The results of the analyses are rendered as virtual scores and can be viewed in any recent web browser. In addition, the queries and the results can be played as a synthesized audio file; all analyses can also be exported as PDF or CSV files.</p><p>The tool comprises three main components: (1) the upload function, (2) the analysis function, and (3) the search function. After one or more files in MusicXML format have been uploaded via an intuitive drag-and-drop dialog, the analysis component parses the data and calculates basic frequencies; the results are stored in an SQL database and can be displayed in a dashboard view (cf. Fig. 1). </p><div class="panel panel-default panel-figure"><img class="img-responsive" src="/static/data/458/image1.png" alt="Figure 1: Snippet from the dashboard view, showing basic frequencies for a corpus of MusicXML documents." class="inline" /><div class="caption">Figure 1: Snippet from the dashboard view, showing basic frequencies for a corpus of MusicXML documents.</div></div><p>The dashboard displays the following information, either for an individual song, or for a corpus of multiple songs:</p><ul><li class="item">Overall statistics for single notes, rests and measures </li><li class="item">Types of instruments used in the song (if described in the MusicXML data)</li><li class="item">Frequency distribution for single notes, intervals, keys, note durations and meters </li></ul><p>Via a dedicated search function, a corpus of MusicXML documents can be queried for melodic patterns on different levels of information:</p><ul><li class="item">Search for a sound sequence; example: c’, c’, g’, g’</li><li class="item">Search for a rhythmic pattern; example: eighth note, eighth note, quarter note, quarter note</li><li class="item">Search for melodic patterns, i.e. a combination of sound sequence and rhythm; example: c’ / eighth note, c’ / eighth note, g’ / quarter note, g’ / quarter note</li></ul><p>Search queries can be entered via a virtual staff that was realized with the VexFlow library <span id="ftn9_return"><a class="notelink" title="http://www.vexflow.com/" href="#ftn9"><sup>9</sup></a></span> (cf. Fig. 2). Once a search pattern has been entered, it can also be played as a synthesized Midi sequence, which was realized with the Midi.js library <span id="ftn10_return"><a class="notelink" title="http://mudcu.be/midi-js" href="#ftn10"><sup>10</sup></a></span>.</p><div class="panel panel-default panel-figure"><img class="img-responsive" src="/static/data/458/image2.png" alt="Figure 2: Interface for entering queries to identify tonal, rhythmic, or melodic patterns in a corpus of MusicXML documents." class="inline" /><div class="caption">Figure 2: Interface for entering queries to identify tonal, rhythmic, or melodic patterns in a corpus of MusicXML documents.</div></div><p>After a query has been submitted, all results – i.e. the songs that contain the search pattern – are displayed in a list view. The list contains the name of the song and also the number of total occurrences of the search pattern in that song. By clicking on one of the song items in the list, a virtual score is rendered for the whole song; the search pattern is highlighted whenever it occurs in that virtual score (cf. Fig. 3). The whole song can be played directly in the web browser, or downloaded for further analyses as a PDF (realized with the jsPDF library <span id="ftn11_return"><a class="notelink" title="https://parall.ax/products/jspdf" href="#ftn11"><sup>11</sup></a></span>).</p><div class="panel panel-default panel-figure"><img class="img-responsive" src="/static/data/458/image3.png" alt="Figure 3: Virtual score rendering of a document from the results list; the search pattern is highlighted in red color." class="inline" /><div class="caption">Figure 3: Virtual score rendering of a document from the results list; the search pattern is highlighted in red color.</div></div><p>MusicXML Analyzer was implemented by means of standard web technologies (HTML, CSS, JavaScript, PHP), in particular by utilizing the following libraries and frameworks: Laravel <span id="ftn12_return"><a class="notelink" title="http://laravel.com/" href="#ftn12"><sup>12</sup></a></span>, jQuery <span id="ftn13_return"><a class="notelink" title="https://jquery.com/" href="#ftn13"><sup>13</sup></a></span>, D3.js <span id="ftn14_return"><a class="notelink" title="http://d3js.org/" href="#ftn14"><sup>14</sup></a></span>, Bootstrap <span id="ftn15_return"><a class="notelink" title="http://getbootstrap.com/" href="#ftn15"><sup>15</sup></a></span>, Typed.js <span id="ftn16_return"><a class="notelink" title="http://www.mattboldt.com/demos/typed-js/" href="#ftn16"><sup>16</sup></a></span>, Dropzone.js <span id="ftn17_return"><a class="notelink" title="http://www.dropzonejs.com/" href="#ftn17"><sup>17</sup></a></span>.</p><p>A short demo video that showcases the main functionality of the tool is available at</p><ul><li class="item"><a class="link_ref" href="https://dl.dropboxusercontent.com/u/4194636/MusicXML-Analyzer.mp4">https://dl.dropboxusercontent.com/u/4194636/MusicXML-Analyzer.mp4</a></li></ul><p>A fully functional online demo <span id="ftn18_return"><a class="notelink" title="Due to some technical limitations of our server environment, the initial access to the online demo may take a few seconds to wake up the server from i…" href="#ftn18"><sup>18</sup></a></span> of MusicXML Analyzer is available at</p><ul><li class="item"><a class="link_ref" href="http://music-xml-analyzer.herokuapp.com/">http://music-xml-analyzer.herokuapp.com/</a></li></ul><p>MusicXML Analyzer can also be downloaded and modified (according to the MIT open source license) from GitHub:</p><ul><li class="item"><a class="link_ref" href="https://github.com/freakimkaefig/Music-XML-Analyzer"><span class="Bullets">https://github.com/freakimkaefig/Music-XML-Analyzer</span></a></li></ul></div><div class="DH-Heading1" id="index.xml-body.1_div.3"><h2 class="DH-Heading1"><span class="headingNumber">3. </span><span class="head">Future directions</span></h2><p>In its current implementation, MusicXML Analyzer performs an exact match search, i.e. only documents which have the exact same value in their MusicXML markup will be found by the search function. We are planning to implement a more sophisticated melodic similarity algorithm (cf. Grachten et al., 2002; Miura and Shioya, 2003) that allows for the configuration of different similarity thresholds. </p><p>At the same time, we are adapting MusicXML Analyzer for a recent project on a large corpus of German folksongs. Besides monophonic melodies, this collection of folksongs also contains machine-readable metadata (region, date, etc.) and lyrics. Accordingly, we are trying to enhance the search features of MusicXML Analyzer in a way it can not only search songs for melodic patterns, but also for metadata parameters and keywords from the lyrics. Such an enhanced MIR system could be used to analyze the following research questions:</p><ul><li class="item">Are there characteristic melodic and linguistic patterns for German folksongs, from a diachronic perspective as well as from a regional perspective?</li><li class="item">Are there melodic-linguistic collocations, i.e. do certain melodic patterns co-occur with certain keywords or phrases?</li></ul></div><!--TEI back--><div class="bibliogr" id="index.xml-back.1_div.1"><h2><span class="headingNumber"> </span></h2><div class="listhead">Bibliography</div><ol class="listBibl"><li id="index.xml-bibl-d30e508"><div class="biblfree"><span style="font-weight:bold">Good, M.</span> (2001). MusicXML for Notation and Analysis. In Hewlett, W. B. and Selfridge-Field, E. (eds.), <span style="font-style:italic">The Virtual Score: Representation, Retrieval, Restoration</span>. Cambridge (MA) and London (UK): MIT Press, pp. 113–24.</div></li><li id="index.xml-bibl-d30e517"><div class="biblfree"><span style="font-weight:bold">Grachten, M. A., Josep, L. and Mántaras R. L.</span> (2002). A comparison of different approaches to melodic similarity. <span style="font-style:italic">Proceedings of the 2nd International Conference in Music and Artificial Intelligence (ICMAI) 2002</span>.</div></li><li id="index.xml-bibl-d30e526"><div class="biblfree"><span style="font-weight:bold">Kepper, J., Schreiter, S. and Veit, J.</span> (2014). ‚Freischütz‘ analog oder digital – Editionsformen im Spannungsfeld von Wissenschaft und Praxis. <span style="font-style:italic">Editio</span>, <span style="font-weight:bold">28</span>: 127–50.</div></li><li id="index.xml-bibl-d30e538"><div class="biblfree"><span style="font-weight:bold">Miura, T. and Shioya, I.</span> (2003). Similarity among melodies for music information retrieval. <span style="font-style:italic">Proceedings of the 12th International Conference on Information and Knowledge Management (CIKM) 2003</span>.</div></li><li id="index.xml-bibl-d30e548"><div class="biblfree"><span style="font-weight:bold">Müllensiefen, D. and Frieler, K.</span> (2004). Optimizing Measures Of Melodic Similarity For The Exploration Of A Large Folk Song Database. <span style="font-style:italic">Proceedings of the 5th International Conference on Music Information Retrieval (ISMIR) 2004</span>, pp. 274–80.</div></li><li id="index.xml-bibl-d30e557"><div class="biblfree"><span style="font-weight:bold">Typke, R., Wiering, F. and Veltkamp, R. C.</span> (2005). A survey of music information retrieval systems. <span style="font-style:italic">Proceedings of the 6th International Conference on Music Information Retrieval (ISMIR) 2005</span>, pp. 153–60.</div></li><li id="index.xml-bibl-d30e566"><div class="biblfree"><span style="font-weight:bold">Veit, J.</span> (2015). Music notation beyond paper. On developing digital humanities tools for music editing. <span style="font-style:italic">Forschungsforum Paderborn</span>, <span style="font-weight:bold">18</span>: 40-48.</div></li><li id="index.xml-bibl-d30e578"><div class="biblfree"><span style="font-weight:bold">Viglianti, R.</span> (2007). MusicXML: An XML Based Approach to Musicological Analysis. <span style="font-style:italic">Digital Humanities 2007: Conference Abstracts</span>, pp. 235–37.</div></li><li id="index.xml-bibl-d30e587"><div class="biblfree"><span style="font-weight:bold">Viro, V.</span> (2011). Peachnote: Music Score Search and Analysis Platform. <span style="font-style:italic">Proceedings of the 12th International Conference on Music Information Retrieval (ISMIR) 2011</span>, pp. 359-62.</div></li></ol></div><!--Notes in [TEI]--><div class="notes"><div class="noteHeading">Notes</div><div class="note" id="ftn1"><span class="noteLabel">1. </span><div class="noteBody"><p>The popular series „Computing in Musicology“ started around 1985. For an overview of all volumes of the series cf. http://www.ccarh.org/publications/books/cm/; Note: All URLs mentioned in this text were last checked on March 3, 2016.</p></div></div><div class="note" id="ftn2"><span class="noteLabel">2. </span><div class="noteBody"><p class="footnote text">http://www.humdrum.org/</p></div></div><div class="note" id="ftn3"><span class="noteLabel">3. </span><div class="noteBody"><p class="footnote text">https://opac.rism.info/</p></div></div><div class="note" id="ftn4"><span class="noteLabel">4. </span><div class="noteBody"><p class="footnote text">http://hymnquest.com/</p></div></div><div class="note" id="ftn5"><span class="noteLabel">5. </span><div class="noteBody"><p class="footnote text">http://www.peachnote.com/</p></div></div><div class="note" id="ftn6"><span class="noteLabel">6. </span><div class="noteBody"><p class="footnote text">http://imslp.org/</p></div></div><div class="note" id="ftn7"><span class="noteLabel">7. </span><div class="noteBody"><p class="footnote text">https://books.google.com/ngrams</p></div></div><div class="note" id="ftn8"><span class="noteLabel">8. </span><div class="noteBody"><p class="footnote text">http://www.musicxml.com/music-in-musicxml/</p></div></div><div class="note" id="ftn9"><span class="noteLabel">9. </span><div class="noteBody"><p class="footnote text">http://www.vexflow.com/</p></div></div><div class="note" id="ftn10"><span class="noteLabel">10. </span><div class="noteBody"><p class="footnote text">http://mudcu.be/midi-js</p></div></div><div class="note" id="ftn11"><span class="noteLabel">11. </span><div class="noteBody"><p class="footnote text">https://parall.ax/products/jspdf</p></div></div><div class="note" id="ftn12"><span class="noteLabel">12. </span><div class="noteBody"><p class="footnote text">http://laravel.com/</p></div></div><div class="note" id="ftn13"><span class="noteLabel">13. </span><div class="noteBody"><p class="footnote text">https://jquery.com/</p></div></div><div class="note" id="ftn14"><span class="noteLabel">14. </span><div class="noteBody"><p class="footnote text">http://d3js.org/</p></div></div><div class="note" id="ftn15"><span class="noteLabel">15. </span><div class="noteBody"><p class="footnote text">http://getbootstrap.com/</p></div></div><div class="note" id="ftn16"><span class="noteLabel">16. </span><div class="noteBody"><p class="footnote text">http://www.mattboldt.com/demos/typed-js/</p></div></div><div class="note" id="ftn17"><span class="noteLabel">17. </span><div class="noteBody"><p class="footnote text">http://www.dropzonejs.com/</p></div></div><div class="note" id="ftn18"><span class="noteLabel">18. </span><div class="noteBody"><p>Due to some technical limitations of our server environment, the initial access to the online demo may take a few seconds to wake up the server from <span style="font-style:italic">idle mode</span>.</p></div></div></div></body></html>
		</div>
		<div class="col-lg-2">
		</div>
	</div>


		</div>
		<script>
		$(document).ready(function(){
			$('[data-toggle="tooltip"]').tooltip();
		});
		</script>			
	</body>
</html>