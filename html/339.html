<!DOCTYPE html>



<html lang="en">
	<head>
		<meta charset="utf-8">	
		<meta name="viewport" content="width=device-width, initial_scale=1">
		<title>DH 2016 Abstracts</title>
		<link rel="stylesheet" href="/static/bootstrap/css/bootstrap.min.css">
		<link rel="stylesheet" href="/static/bootstrap/css/bootstrap-theme.min.css">
		<link rel="stylesheet" href="/static/css/abstracts.css">
		<script src="/static/jquery/jquery-2.2.4.min.js"></script>
		<script src="/static/bootstrap/js/bootstrap.min.js"></script>
	</head>
	<body>
		<div class="container">
			<div class="row">
				<a href="http://dh2016.adho.org"><img src="/static/images/logo_4.png" class="img-responsive"></a>
			</div>
			<div class="row">
				<ol class="breadcrumb">
					
						<li><a href="http://www.dh2016.adho.org">DH Home</a></li>
					
						<li><a href="/abstracts/">Abstracts</a></li>
					
						<li><a href="/abstracts/339">339</a></li>
					
				</ol>
			</div>
					
			
	<div class="row">
		<div class="col-lg-2">
		</div>
		<div class="col-lg-8 col-xs-12">
			<button class="btn btn-default" data-toggle="collapse" data-target="#head" style="margin-bottom: 5px;">Show info</button>
			<button class="btn btn-default" data-toggle="collapse" data-target="#cite" style="margin-bottom: 5px;">How to cite</button>
			<a href="/static/data/262.xml" class="btn btn-default" role="button" style="margin-bottom: 5px;" download="339.xml">XML Version</a>
			<div class="panel panel-success collapse" style="padding: 10px; border=none;" id="head">
				<div>
					<b>Title: </b>Enhancing Close Reading
					<br>
					<b>Authors: </b>
					Muhammad Faisal Cheema, Stefan Jänicke, Gerik Scheuermann
					<br>
					<b>Category: </b>Paper:Poster
					<br>
					<b>Keywords: </b>Annotations, Distant Reading, Close Reading
				</div>
			</div>
			<div class="collapse" id="cite">
				<b>Cheema, M., Jänicke, S., Scheuermann, G.</b> (2016). Enhancing Close Reading. In <i>Digital Humanities 2016: Conference Abstracts</i>. Jagiellonian University & Pedagogical University, Kraków, 
				
					pp. 758-761.
				
			</div>
		</div>
		<div class="col-lg-2">
		</div>
	</div>
	<div class="row">
		<div class="col-lg-2">
		</div>
		<div class="col-lg-8">	
			<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8" /><!--THIS FILE IS GENERATED FROM AN XML MASTER. DO NOT EDIT (5)--><title>Enhancing Close Reading </title><meta name="author" content="Muhammad Faisal Cheema , Stefan Jänicke and Gerik Scheuermann" /><meta name="generator" content="Text Encoding Initiative Consortium XSLT stylesheets" /><meta name="DC.Title" content="Enhancing Close Reading" /><meta name="DC.Type" content="Text" /><meta name="DC.Format" content="text/html" /><link href="http://www.tei-c.org/release/xml/tei/stylesheet/tei.css" rel="stylesheet" type="text/css" /><link rel="stylesheet" media="print" type="text/css" href="http://www.tei-c.org/release/xml/tei/stylesheet/tei-print.css" /></head><body class="simple" id="TOP"><div class="stdheader autogenerated"><h1 class="maintitle"><span class="titlem">Enhancing Close Reading</span> <span class="titlem"></span></h1></div><!--TEI front--><!--TEI body--><div class="DH-Heading1" id="index.xml-body.1_div.1"><h2 class="DH-Heading1"><span class="headingNumber">1. </span><span class="head">Motivation</span></h2><p>In last years, the advancements in computer science brought a global change in the way information is stored, retrieved and analyzed. The digital humanities also benefit from these developments, and now, a vast amount of texts is available in digital form. This information explosion generates interesting research questions for humanities scholars who are capable of deriving new insights from this knowledge bank. In order to support humanities scholars, many visualization techniques – summarized in a survey (Jänicke et al., 2015b) – were developed to aid exploring large texts collections. Most of these techniques are interactive and belong to the category of distant reading (Moretti, 2005). The authors of the mentioned survey observe that less work has been done to improve the close reading capabilities of humanities scholars even though they are often focused on close reading text passages.</p><p>Close reading is the careful interpretation of the text, where the scholar iteratively reads the text in order to explore its meaning, inherent topics and occurring relationships (Boyles, 2013). Traditionally, close reading is done on paper. Several ideas and thoughts are made persistent by annotations written at the margins alongside the text (see Figure 1). But as the margin space is limited, not all observations can be put around the text. So, annotations may become cluttered and confusing for the reader, especially, when obsolete ideas are struck through. Despite its disadvantages, annotating on paper is still quite popular as it benefits the scholars to record observations about the hypothesis and all these changes reappear in front of the scholar’s eyes as soon as he re-reads the text passage. We observed that the way of annotating in close reading resembles the idea of mind maps (Buzan et al., 1993) that are based on a central concept and thoughts are represented around it using lines and text. In the close reading scenario, the text can be considered as the central concept and annotations represent thoughts.</p><p>An important task of computer science is to enhance the original workflows of researchers with computational methods. As most humanities scholars are well trained in close reading and nowadays often work with digital texts, it is necessary to enhance their capabilities for digital close reading. We propose an enhanced close reading design inspired by mind-maps that not only mimics the traditional way of annotating a text on paper, but also helps humanities scholars to perform live visual analyses. Furthermore, we use extendible margins to provide enough space for all thoughts of the scholar.</p><p><a id="id_docs-internal-guid-cfc761b5-411d-b964-effb-76d244703cf0"><!--anchor--></a> <span style="color:#000000"> </span></p><div class="panel panel-default panel-figure"><img class="img-responsive" src="/static/data/262/1000000000000640000004D5F3E06A1C.png" alt="Figure 1: Traditional close reading on paper" class="graphic" /><div class="caption">Figure 1: Traditional close reading on paper</div></div><p><span style="color:#000000"> </span> <span style="color:#000000"> </span><span id="ftn1_return"><a class="notelink" title="Image reproduced with permission from Kehoe (Kehoe et al., 2013)" href="#ftn1"><sup>1</sup></a></span><span style="color:#000000"> </span></p></div><div class="DH-Heading1" id="index.xml-body.1_div.2"><h2 class="DH-Heading1"><span class="headingNumber">2. </span><span class="head">Related Work</span></h2><p>Nancy Boyles (Boyles, 2013) defines close reading, which has become a fundamental method in literary criticism in the 20th century (Hawthorn, 2000), as follows: “Essentially, close reading means reading to uncover layers of meaning that lead to deep comprehension.” Annotating the text in close reading is a strong method for scholars to facilitate the understanding of a text passage. Figure 1 shows the result of a traditional close reading approach. In this example, various annotation methods were used by the scholar to annotate various features of a text passage in Charles Dickens' „David Copperfield“. </p><p>The availability of digital texts has further awaken the interest of humanities scholars in collaboratively close reading the same texts. There are several annotation tools for such a purpose, such as eMargin (Kehoe et al., 2013), Hypothes.is (Bonn et al., 2014) and NB (Zyto et al., 2012). These tools are beneficial for collaborative research and classroom environments as they provide an excellent paradigm to share thoughts, as well as find collective answers. To avoid clutter, these tools work with popup windows that are only shown on demand. In Figure 2, the eMargin system is shown where colors are used to highlight different text features, and a popup window on demand, lists the comments of collaborating scholars.</p><p><a id="id_docs-internal-guid-cfc761b5-412e-0f91-0c44-c948a3dc5484"><!--anchor--></a> <span style="color:#000000"> </span></p><div class="panel panel-default panel-figure"><img class="img-responsive" src="/static/data/262/10000201000003CB000002F649BAF3AA.png" alt="Figure 2: eMargin annotation tool" class="graphic" /><div class="caption">Figure 2: eMargin annotation tool</div></div><p><span style="color:#000000"> </span> <span style="color:#000000"> </span><span id="ftn2_return"><a class="notelink" title="Image reproduced with permission from Kehoe (Kehoe et al., 2013)" href="#ftn2"><sup>2</sup></a></span><span style="color:#000000"> </span></p><p>Digital Ink Annotations systems (Schilit, 1998, Bargeron et al., 2003, Agrawala et al., 2005, Yoon et al., 2013) also support annotating text, but their use is only limited to pen-based computing devices such as tablets. The systems are designed to work well on smaller screens, and the adaption to larger screens is not appropriately implemented. </p><p>Close reading tasks can also be assisted via distant reading tools. For example, parallel coordinates, a heatmap and a dot plot are used to analyze the variance of a selected text passage from different German translations of Shakespeare’s Othello (Geng et al., 2013). Heat maps are appropriate visualizations to illustrate the distribution of specific phrases or annotations in a corpus (Muralidharan, 2011, Alex et al., 2015). Voyant Tools allow the user to perform basic text mining functions with selected word statistics shown in linked views (Sinclair et al., 2012). The Voyant Tools interface in Figure 3 shows statistics about Chapter 2 of Oscar Wilde's “David Copperfield”. Goffin's idea to enhance close reading is the integration of small visualizations (e.g., maps or bar charts) besides the words of a text (Goffin et al., 2014).</p><div class="panel panel-default panel-figure"><img class="img-responsive" src="/static/data/262/100002010000077C000003DA2D6B26FC.png" alt="Figure 3: Screenshot of web-based Voyant Tools (Sinclair et al., 2012)." class="graphic" /><div class="caption">Figure 3: Screenshot of web-based Voyant Tools (Sinclair et al., 2012).</div></div></div><div class="DH-Heading1" id="index.xml-body.1_div.3"><h2 class="DH-Heading1"><span class="headingNumber">3. </span><span class="head">Enhanced Close Reading Design</span></h2><p>In contrast to the tools mentioned above, we combine traditional annotation tasks with distant reading analyses to enhance the close reading capabilities of the scholar. We suggest a design inspired by mind mapping (an example mind map is shown in Figure 4a), a methodology that allows a researcher to work on a central concept, and thoughts and features about that concept are placed around it using figures, lines etc. In a mind map, the associations spread out from a central concept in a free-flowing, yet organized and coherent manner (Budd, 2004) - thus forming a mental map of the central concept. We observe that like in the case of mind maps, fixed annotations around the central text in a traditional close reading process facilitate forming a mental map of the thoughts about the text of interest, and help the scholar to draw conclusions when seeing the whole picture.</p><div class="table" id="Table1"><table class="frame" style="border-collapse:collapse;border-spacing:0;"><tr><td><div class="panel panel-default panel-figure"><img class="img-responsive" src="/static/data/262/10000200000002F4000001B428DDC0DA.png" alt="Figure 4a: An example mind map" class="graphic" /><div class="caption">Figure 4a: An example mind map</div></div> <span id="ftn3_return"><a class="notelink" title="Image reproduced with permission from Kanter (Kanter, 2015) (Figure under CC BY 2.0 license, see for details)." href="#ftn3"><sup>3</sup></a></span></td><td><div class="panel panel-default panel-figure"><img class="img-responsive" src="/static/data/262/10000201000002F4000001B45878ECC5.png" alt="Figure 4b: Mind-map inspired close reading" class="graphic" /><div class="caption">Figure 4b: Mind-map inspired close reading</div></div></td></tr></table></div><p>Figure 4b illustrates the idea of a mind map inspired interface with multiple types of annotations supporting the scholar in the close reading process. Textual annotations known from the traditional close reading are also necessary in the digital process. In addition, images, videos and charts can facilitate text interpretation and the generation of valuable hypotheses about the text. To support dynamic, multifarious views on a certain text passage or a term of interest, we designed our interface the way that the literary scholar can apply a multitude of visual analyses and generate distant reading visualizations that are placed as annotations alongside the text. This combines the traditional close reading paradigm with elaborated text visualization techniques valuable for exploration purposes. An important feature of our proposed interface design is to support the scholar to „stay in the flow“ (Bederson, 2004), so that the central focus remains on the text, which can be analyzed without interrupting the scholar. The major advantage of our design over existing tools that assist close reading tasks is interface versatility. For example, Voyant Tools (see Figure 3) provide a predefined set of visualizations based on text statistics. On the other hand, our design allows the scholar to choose an appropriate text visualization as an annotation alongside the text, which is based on a user-defined query on the text.. Therefore, the scholar can apply different text visualizations for different passages of the text to support a variety of close reading tasks. </p><p>An example of the design discussed above is shown in Figure 5. The example from Figure 1 is annotated using different kinds of annotations. Like in other digital tools, certain topics of the text are annotated using colors. In addition, the character(s) Peggotty is marked and a panel shows thumbnail images based on a Google Images search. Also the relative word frequency chart of the term “Peggotty” in Chapter 2 is shown on the bottom left. Furthermore, on the left area, a TagPie (Jänicke et al., 2015a) showing the co-occurrences of both the terms memory and observation helps to investigate the hypothesis of the literary scholar about the similar meaning of both topics. The example depicts how the scholar can use different annotation tools as well as different distant reading tools to enrich the close reading experience.</p><div class="panel panel-default panel-figure"><img class="img-responsive" src="/static/data/262/100002010000075F00000440C3691AC9.png" alt="Figure 5: Example of our design" class="graphic" /><div class="caption">Figure 5: Example of our design</div></div></div><div class="DH-Heading1" id="index.xml-body.1_div.4"><h2 class="DH-Heading1"><span class="headingNumber">4. </span><span class="head">Future Work and Conclusions</span></h2><p>We held discussion with the collaborating humanities scholars about the design as well as the usability of the proposed interface. The scholars remarked that such an interface will help removing fears of using digital humanities tools and that they intend to use the tool as it mimics their existing workflows. They also mentioned that such a tool could help users getting a better big picture of the text, and that it enhances the close reading capabilities of the scholar. Another important point is the capability in supporting teaching activities. They mentioned that various types of annotations (text, pictures, charts) are also used in teaching material, but it is not easy to share these with students. Such a tool could support this process as it generates persistent annotations to be analyzed and discussed collaboratively in courses. </p><p>We observe that the scholar’s initial reactions after seeing the prototype of the tool, which is still in development, are convincing and encouraging. We think that rigid modeling syntax is inappropriate for annotation. Our final interface will allow the scholar to make annotation styles versatile. At the digital humanities conference, we will demonstrate our prototype and discuss future prospects within the community. An additional user study will compare the viability of our proposed, mind map inspired annotation technique to existing approaches.</p></div><div class="DH-Heading1" id="index.xml-body.1_div.5"><h2 class="DH-Heading1"><span class="headingNumber">5. </span><span class="head">Acknowledgements</span></h2><p>We thank our colleagues from the humanities department, Judith Blumenstein in particular, who provided insights and expertise that greatly assisted this research.</p></div><!--TEI back--><div class="bibliogr" id="index.xml-back.1_div.1"><h2><span class="headingNumber"> </span></h2><div class="listhead">Bibliography</div><ol class="listBibl"><li id="index.xml-bibl-d30e377"><div class="biblfree"><span style="font-weight:bold">Agrawala, M. and Shilman, M.</span> (2005). DIZI: a digital ink zooming interface for document annotation. <span style="font-style:italic">Human-Computer Interaction-INTERACT 2005</span>, Springer Berlin Heidelberg, pp. 69-79.</div></li><li id="index.xml-bibl-d30e386"><div class="biblfree"><span style="font-weight:bold">Alex, B., Grover, C., Zhou, K., Hinrichs and Palimpsest, U.</span> (2015). Improving Assisted Curation of Loco-specific Literature. <span style="font-style:italic">Proceedings of the Digital Humanities 2015</span>, pp. 5-7.</div></li><li id="index.xml-bibl-d30e395"><div class="biblfree"><span style="font-weight:bold">Bargeron, D. and Moscovich, T.</span> (2003). Reflowing digital ink annotations. <span style="font-style:italic">Proceedings of the SIGCHI conference on Human factors in computing systems</span>, ACM, pp. 385-93.</div></li><li id="index.xml-bibl-d30e404"><div class="biblfree"><span style="font-weight:bold">Bederson, B. B.</span> (2004). Interfaces for staying in the flow. <span style="font-style:italic">Ubiquity</span>, 1-1.</div></li><li id="index.xml-bibl-d30e414"><div class="biblfree"><span style="font-weight:bold">Bonn, M. and McGlone, J.</span> (2014). New Feature: Article Annotation with Hypothesis. <span style="font-style:italic">Journal of Electronic Publishing</span>, <span style="font-weight:bold">17</span>(2).</div></li><li id="index.xml-bibl-d30e426"><div class="biblfree"><span style="font-weight:bold">Boyles, N.</span> (2013). Closing in on Close Reading. <span style="font-style:italic">Educational Leadership</span>, <span style="font-weight:bold">70</span>(4): 36–41.</div></li><li id="index.xml-bibl-d30e438"><div class="biblfree"><span style="font-weight:bold">Budd, J. W.</span> (2004). Mind Maps as Classroom Exercises. <span style="font-style:italic">The Journal of Economic Education</span>, <span style="font-weight:bold">35</span>(1): 35–46.</div></li><li id="index.xml-bibl-d30e450"><div class="biblfree"><span style="font-weight:bold">Buzan, T. and Buzan, B.</span> (1993). The Mind Map Book How to Use Radiant Thinking to Maximise Your Brain's Untapped Potential. New York: Plume.</div></li><li id="index.xml-bibl-d30e456"><div class="biblfree"><span style="font-weight:bold">Geng, Z., Cheesman, T., Laramee, R. S., Flanagan, K. and Thiel, S.</span> (2013). ShakerVis: Visual analysis of segment variation of German translations of Shakespeare’s Othello. <span style="font-style:italic">Information Visualization</span>, <span style="font-weight:bold">15</span>: 93-116.</div></li><li id="index.xml-bibl-d30e468"><div class="biblfree"><span style="font-weight:bold">Goffin, P., Willett, W., Fekete, J. D. and Isenberg, P.</span> (2014). Exploring the placement and design of word-scale visualizations. Visualization and Computer Graphics, <span style="font-style:italic">IEEE Transactions</span>, <span style="font-weight:bold">20</span>(12): 2291-300.</div></li><li id="index.xml-bibl-d30e481"><div class="biblfree"><span style="font-weight:bold">Hawthorn, J.</span> (2000). <span style="font-style:italic">A glossary of contemporary literary theory</span>. Oxford University Press.</div></li><li id="index.xml-bibl-d30e490"><div class="biblfree"><span style="font-weight:bold">Jänicke, S., Blumenstein, J., Rücker, M., Zeckzer, D. and Scheuermann, G.</span> (2015a). Visualizing the Results of Search Queries on Ancient Text Corpora with Tag Pies. <span style="font-style:italic">Digital Humanities Quarterly</span>.</div></li><li id="index.xml-bibl-d30e499"><div class="biblfree"><span style="font-weight:bold">Jänicke, S., Franzini, G., Cheema, M. F. and Scheuermann, G.</span> (2015b). On Close and Distant Reading in Digital Humanities: A Survey and Future Challenges. In Borgo, R., Ganovelli, F., and Viola, I. (eds.), <span style="font-style:italic">Eurographics Conference on Visualization (EuroVis) - STARs (2015)</span>, The Eurographics Association.</div></li><li id="index.xml-bibl-d30e508"><div class="biblfree"><span style="font-weight:bold">Kanter, B.</span> (2015). Cambodia4kids.org, https://www.flickr.com/photos/cambodia4kidsorg/6195211411 (Retrieved 2015-11-25).</div></li><li id="index.xml-bibl-d30e514"><div class="biblfree"><span style="font-weight:bold">Kehoe, A. and Gee, M.</span> (2013). eMargin: A Collaborative Textual Annotation Tool. <span style="font-style:italic">Ariadne</span>, <span style="font-weight:bold">71</span>.</div></li><li id="index.xml-bibl-d30e526"><div class="biblfree"><span style="font-weight:bold">McCabe, M. M.</span> (2015). <span style="font-style:italic">Platonic Conversations</span>. Oxford University Press.</div></li><li id="index.xml-bibl-d30e536"><div class="biblfree"><span style="font-weight:bold">Moretti, F.</span> (2005). <span style="font-style:italic">Graphs, Maps, Trees: Abstract Models for a Literary History</span>. New York: Verso.</div></li><li id="index.xml-bibl-d30e545"><div class="biblfree"><span style="font-weight:bold">Muralidharan, A.</span> (2011). A Visual Interface for Exploring Language Use in Slave Narratives. <span style="font-style:italic">Proceedings of the Digital Humanities 2011</span>.</div></li><li id="index.xml-bibl-d30e554"><div class="biblfree"><span style="font-weight:bold">Schilit, B. N., Golovchinsky, G. and Price, M. N.</span> (1998). Beyond paper: supporting active reading with free form digital ink annotations. <span style="font-style:italic">Proceedings of the SIGCHI conference on Human factors in computing systems</span>, ACM Press/Addison-Wesley Publishing Co., pp. 249-56.</div></li><li id="index.xml-bibl-d30e563"><div class="biblfree"><span style="font-weight:bold">Sinclair, S. and Rockwell, G.</span> (2012). Voyant Tools. Online: http://voyant-tools.org (Retrieved 2015-11-25).</div></li><li id="index.xml-bibl-d30e569"><div class="biblfree"><span style="font-weight:bold">Yoon, D., Chen, N. and Guimbretière, F.</span> (2013). TextTearing: Opening white space for digital ink annotation. <span style="font-style:italic">Proceedings of the 26th annual ACM symposium on User interface software and technology</span>, ACM, pp. 107-12.</div></li><li id="index.xml-bibl-d30e578"><div class="biblfree"><span style="font-weight:bold">Zyto, S., Karger, D., Ackerman, M. and Mahajan, S. (2012).</span> Successful classroom deployment of a social document annotation system. <span style="font-style:italic">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</span>, ACM, pp. 1883-92.</div></li></ol></div><!--Notes in [TEI]--><div class="notes"><div class="noteHeading">Notes</div><div class="note" id="ftn1"><span class="noteLabel">1. </span><div class="noteBody"><a id="id_docs-internal-guid-cfc761b5-418b-4abf-34b3-191157a29b72"><!--anchor--></a> <span style="color:#000000">Image reproduced with permission from Kehoe (Kehoe et al., 2013)</span></div></div><div class="note" id="ftn2"><span class="noteLabel">2. </span><div class="noteBody"><a id="id_docs-internal-guid-cfc761b5-418b-4abf-34b3-191157a29b722"><!--anchor--></a> <span style="color:#000000">Image reproduced with permission from Kehoe (Kehoe et al., 2013)</span></div></div><div class="note" id="ftn3"><span class="noteLabel">3. </span><div class="noteBody">Image reproduced with permission from Kanter (Kanter, 2015) (Figure under CC BY 2.0 license, see <a class="link_ptr" href="https://creativecommons.org/licenses/by/2.0/"><span>https://creativecommons.org/licenses/by/2.0/</span></a> for details).</div></div></div></body></html>
		</div>
		<div class="col-lg-2">
		</div>
	</div>


		</div>
		<script>
		$(document).ready(function(){
			$('[data-toggle="tooltip"]').tooltip();
		});
		</script>			
	</body>
</html>