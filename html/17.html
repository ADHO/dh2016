<!DOCTYPE html>



<html lang="en">
	<head>
		<meta charset="utf-8">	
		<meta name="viewport" content="width=device-width, initial_scale=1">
		<title>DH 2016 Abstracts</title>
		<link rel="stylesheet" href="/static/bootstrap/css/bootstrap.min.css">
		<link rel="stylesheet" href="/static/bootstrap/css/bootstrap-theme.min.css">
		<link rel="stylesheet" href="/static/css/abstracts.css">
		<script src="/static/jquery/jquery-2.2.4.min.js"></script>
		<script src="/static/bootstrap/js/bootstrap.min.js"></script>
	</head>
	<body>
		<div class="container">
			<div class="row">
				<a href="http://dh2016.adho.org"><img src="/static/images/logo_4.png" class="img-responsive"></a>
			</div>
			<div class="row">
				<ol class="breadcrumb">
					
						<li><a href="http://www.dh2016.adho.org">DH Home</a></li>
					
						<li><a href="/abstracts/">Abstracts</a></li>
					
						<li><a href="/abstracts/17">17</a></li>
					
				</ol>
			</div>
					
			
	<div class="row">
		<div class="col-lg-2">
		</div>
		<div class="col-lg-8 col-xs-12">
			<button class="btn btn-default" data-toggle="collapse" data-target="#head" style="margin-bottom: 5px;">Show info</button>
			<button class="btn btn-default" data-toggle="collapse" data-target="#cite" style="margin-bottom: 5px;">How to cite</button>
			<a href="/static/data/387.xml" class="btn btn-default" role="button" style="margin-bottom: 5px;" download="17.xml">XML Version</a>
			<div class="panel panel-success collapse" style="padding: 10px; border=none;" id="head">
				<div>
					<b>Title: </b>Corpus Analyses of Multimodal Narrative: The Example of Graphic Novels
					<br>
					<b>Authors: </b>
					Alexander Dunst, Rita Hartel, Sven Hohenstein, Jochen Laubrock
					<br>
					<b>Category: </b>Paper:Long Paper
					<br>
					<b>Keywords: </b>Graphic Novel, Eye-Tracking, Corpus Studies, Annotation Tools, Image Processing
				</div>
			</div>
			<div class="collapse" id="cite">
				<b>Dunst, A., Hartel, R., Hohenstein, S., Laubrock, J.</b> (2016). Corpus Analyses of Multimodal Narrative: The Example of Graphic Novels. In <i>Digital Humanities 2016: Conference Abstracts</i>. Jagiellonian University & Pedagogical University, Kraków, 
				
					pp. 178-180.
				
			</div>
		</div>
		<div class="col-lg-2">
		</div>
	</div>
	<div class="row">
		<div class="col-lg-2">
		</div>
		<div class="col-lg-8">	
			<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8" /><!--THIS FILE IS GENERATED FROM AN XML MASTER. DO NOT EDIT (5)--><title>Corpus Analyses of Multimodal Narrative: The Example of Graphic Novels</title><meta name="author" content="Alexander Dunst , Rita Hartel , Sven Hohenstein , and Jochen Laubrock" /><meta name="generator" content="Text Encoding Initiative Consortium XSLT stylesheets" /><meta name="DC.Title" content="Corpus Analyses of Multimodal Narrative: The Example of Graphic Novels" /><meta name="DC.Type" content="Text" /><meta name="DC.Format" content="text/html" /><link href="http://www.tei-c.org/release/xml/tei/stylesheet/tei.css" rel="stylesheet" type="text/css" /><link rel="stylesheet" media="print" type="text/css" href="http://www.tei-c.org/release/xml/tei/stylesheet/tei-print.css" /></head><body class="simple" id="TOP"><div class="stdheader autogenerated"><h1 class="maintitle">Corpus Analyses of Multimodal Narrative: The Example of Graphic Novels</h1></div><!--TEI front--><!--TEI body--><div class="DH-Heading1" id="index.xml-body.1_div.1"><h2 class="DH-Heading1"><span class="headingNumber">1. </span><span class="head">Introduction</span></h2><p>This paper presents first empirical analyses and visualizations of a large corpus of graphic novels – an increasingly popular form of book-length comics aimed at adults – that is currently in the process of being assembled and digitized. We introduce an XML vocabulary and visual editor that we have developed for the annotation of our corpus, and reflect on the challenges presented by a cultural form that is characterized by the complex interaction of text and images. Analyzing the specific narrativity of this and other multimodal cultural forms (including illustrated books and magazines, theater, film, television and computer games), we argue, calls for a combination of quantitative and qualitative methods drawn from such diverse fields as narratology, digital art history, and cognitive science. In contrast to corpus analyses of literary texts, which have made great strides in recent years, comparable work on visual narrative still remains in its infancy and at the periphery of the digital humanities. While this can be traced, in part, to copyright issues, such scholarship also faces a number of crucial technical and methodological hurdles – from image description, classification, and object recognition to the operationalization of narratological concepts. Given the dominance of visual storytelling in modern and contemporary culture, overcoming these hurdles will represent an important contribution to the further development of DH research.</p><p>The introduction presents our corpus and the wider research questions of our interdisciplinary group. This is followed by a brief overview over the “Graphic Narrative Markup Language” (GNML), which builds on TEI, and the visual editor developed for the annotation of graphic novels, but which is also applicable to other multimodal forms. A version of this editor will be available as open-acess software by the time of the conference. Part two introduces a number of analyses and visualizations combining the study of text and images that make up graphic novels. The final part moves to the quantitative and qualitative analysis of graphic novels with the help of eye-tracking. This approach allows us to study the construction of storyworlds by empirical readers, and thus opens up an aspect of narrative that remains severely underrepresented in DH, and the humanities at large.</p></div><div class="DH-Heading1" id="index.xml-body.1_div.2"><h2 class="DH-Heading1"><span class="headingNumber">2. </span><span class="head">1. GNML-Editor: Tools for (Semi-)Automatic Annotation</span></h2><p>Whereas the automatic analysis of text corpora has become feasible in many instances, such automation currently remains a pipe dream for multimodal narratives. In the case of comics and similarly hand-drawn, or otherwise non-perspectival, images, object identification depends on lengthy training efforts and registers a relatively high error rate. Similarly, standard OCR programs fail at recognizing the (quasi) hand writing that dominates comics. As a consequence, our corpus study presently depends on manual and semi-automatic annotation. For this purpose, we have developed the XML-language GNML, which builds on TEI and previous efforts by John Walsh (2012), to describe all textual and visual properties of graphic novels. To minimize errors during the annotation process, our visual GNML-editor supports annotators with integrated spell checking and auto-completion mechanisms. An automatic recognition of panels is complemented by a function that recognizes the borders of individual captions, speech bubbles, and characters to accelerate annotation. Further automations, such as an in-built OCR for narrative text that conforms to standard fonts, are currently under development. As the conceptual basis of the editor (visual objects with graphic and textual characteristics) is not limited to comics but can be applied to other text-image combinations in visual culture (from illustrated manuscripts to film and TV), the editor will be generalized for the annotation of such formats.</p></div><div class="DH-Heading1" id="index.xml-body.1_div.3"><h2 class="DH-Heading1"><span class="headingNumber">3. </span><span class="head">2. Quantitative Analyses and Visualizations of Graphic Novels</span></h2><p>Part two presents approaches that combine image and text analysis for a number of structural features of graphic novels. Methods developed for digital literary studies, such as topic modeling, are of limited value for the analysis of visual culture given the dominance of images. In contrast, studies of large-scale image sets have so far shown little interest in narrative analysis. To complicate matters further, most narratological concepts are drawn from the study of literary texts, and it remains questionable to what extent they can be successfully applied to visual narrative.</p><p>In a first analysis of the corpus, which is still in the process of being digitized and annotated, we look at the historical development of the visual and textual elements of about 150 book covers of graphic novels. This includes a grammatical and semantic analysis of their titles with the help of a statistical language parser, as well as the stylistic and visual attributes of their design and cover images. In a second step, we move to more detailed studies of a first sub-corpus that consists of the ten most-cited titles within our larger set of graphic novels. Such a small sub-set does not allow for genre comparisons or for studying historical developments within the form. However, we can consider the narrative features of representative texts within our corpus. In order to do so, we compare a network analysis of characters with their visual prominence and respective share of text, and complement this with a stylistic analysis of the latter. </p></div><div class="DH-Heading1" id="index.xml-body.1_div.4"><h2 class="DH-Heading1"><span class="headingNumber">4. </span><span class="head">3. Eyetracking Analysis of Multimodal Narrative</span></h2><p>The experimental observation of eye movements has proven a reliable measure of the human processing of text and images, and allows us to form hypotheses about the construction of storyworlds by empirical readers. The final part of the paper aims to show the value of this method by considering excerpts from a first, explorative corpus of canonical graphic novels. In contrast to theoretical scholarship on comics, which has emphasized the primacy of images (Groensteen, 2009), our experiments demonstrate that readers focus most of their attention on the text. Not only is it usually read first, but many images are either not focused on at all, or analyzed purely in peripheral vision. Whether images are viewed depends, among other variables, on their informational content: if either visual aspects or the storyline continue from one panel to the next, it is much more likely that a panel will be skipped by the reader than if they are distinguished more clearly from its immediate predecessor. We also look at the interaction between visual and textual levels: do reading habits differ if text and images refer to distinct storylines? Finally, we report on experiments that focus on comic reading expertise, for which we propose a new empirical measure. In sharp contrast to the reading of text alone, where experience and reading speed are positively correlated, experienced comics readers focus on the visual aspects of the panels for an extended amount of time. This time appears to be invested wisely, since they are able to better understand the story, as shown by an empirical content test. Taken together, these results suggest that the text and image work together to transmit the narrativity of graphic novels, and that a specific type of expertise is required to understand multimodal narratives. This maps well onto the hypothesis that comics and other forms of sequential art use a particular kind of visual language (McCloud, 1993), which has been analyzed in psycholinguistic terms by Cohn (2013).</p></div><div class="DH-Heading1" id="index.xml-body.1_div.5"><h2 class="DH-Heading1"><span class="headingNumber">5. </span><span class="head">4. Summary and Conclusions</span></h2><p>We present a new DH project aiming at collecting and analyzing a corpus of graphic literature, enriched by human annotations as well as by a corpus of eye-movement recordings to measure the momentary distribution of readers’ attention. First example analyses on both global and local levels demonstrate the potential of this approach. A toolchain for description, annotation, and analysis of these data is being developed, and is of potential use for a wider field of studies in cultural analytics of image-related and multimodal material. In perspective, the corpus will be further enhanced by automated description, using features developed in the field of computer vision (Farabet et al., 2013; Krizhevsky et al., 2012; Rigaud et al., 2015; Serre et al., 2007).</p></div><!--TEI back--><div class="bibliogr" id="index.xml-back.1_div.1"><h2><span class="headingNumber"> </span></h2><div class="listhead">Bibliography</div><ol class="listBibl"><li id="index.xml-bibl-d30e286"><div class="biblfree"><span style="font-weight:bold">Cohn, N.</span> (2013). <span style="font-style:italic">The Visual Language of Comics. Introduction to the Structure and Cognition of Sequential Images.</span> London: Bloomsbury.</div></li><li id="index.xml-bibl-d30e295"><div class="biblfree"><span style="font-weight:bold">Farabet, C., Couprie, C., Najman, L. and LeCun, Y.</span> (2013). Learning Hierarchical Features for Scene Labeling. <span style="font-style:italic">IEEE Transactions on Pattern Analysis and Machine Intelligence</span>,<span style="font-weight:bold">35</span>: 1915–29.</div></li><li id="index.xml-bibl-d30e307"><div class="biblfree"><span style="font-weight:bold">Groensteen, T.</span> (2007). <span style="font-style:italic">The System of Comics</span>. Jackson, MS: University of Mississippi Press.</div></li><li id="index.xml-bibl-d30e316"><div class="biblfree"><span style="font-weight:bold">Krizhevsky, A., Sutskever, I. and Hinton, G. E.</span> (2012). ImageNet Classification with Deep Convolutional Neural Networks. <span style="font-style:italic">Advances in Neural Information Processing Systems</span>,<span style="font-weight:bold">25</span>: 1097–1105.</div></li><li id="index.xml-bibl-d30e329"><div class="biblfree"><span style="font-weight:bold">Lowe, D. G.</span> (2004). Distinctive Image Features from Scale-Invariant Keypoints. <span style="font-style:italic">International Journal of Computer Vision</span>,<span style="font-weight:bold">60</span>: 91–110.</div></li><li id="index.xml-bibl-d30e341"><div class="biblfree"><span style="font-weight:bold">McCloud, S.</span> (1993). <span style="font-style:italic">Understanding Comics: The Invisible Art.</span> New York, NY: Harper Collins.</div></li><li id="index.xml-bibl-d30e350"><div class="biblfree"><span style="font-weight:bold">Rigaud, C., Guérin, C., Karatzas, D., Burie, J.-C. and Ogier, J.-M.</span> (2015). Knowledge-driven understanding of images in comic books. <span style="font-style:italic">International Journal on Document Analysis and Recognition</span>,<span style="font-weight:bold">18</span>: 199–221.</div></li><li id="index.xml-bibl-d30e362"><div class="biblfree"><span style="font-weight:bold">Serre, T., Wolf, L., Bileschi, S., Riesenhuber, M. and Poggio, T.</span> (2007). Robust Object Recognition with Cortex-like Mechanisms. <span style="font-style:italic">IEEE Transactions on Pattern Analysis and Machine Intelligence</span>,<span style="font-weight:bold">29</span>: 411–26.</div></li><li id="index.xml-bibl-d30e374"><div class="biblfree"><span style="font-weight:bold">Walsh, J.</span> (2012). Comic Book Markup Language: An Introduction and Rationale. <span style="font-style:italic">Digital Humanities Quarterly,</span> (6–1).</div></li></ol></div></body></html>
		</div>
		<div class="col-lg-2">
		</div>
	</div>


		</div>
		<script>
		$(document).ready(function(){
			$('[data-toggle="tooltip"]').tooltip();
		});
		</script>			
	</body>
</html>