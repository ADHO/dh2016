<!DOCTYPE html>



<html lang="en">
	<head>
		<meta charset="utf-8">	
		<meta name="viewport" content="width=device-width, initial_scale=1">
		<title>DH 2016 Abstracts</title>
		<link rel="stylesheet" href="/static/bootstrap/css/bootstrap.min.css">
		<link rel="stylesheet" href="/static/bootstrap/css/bootstrap-theme.min.css">
		<link rel="stylesheet" href="/static/css/abstracts.css">
		<script src="/static/jquery/jquery-2.2.4.min.js"></script>
		<script src="/static/bootstrap/js/bootstrap.min.js"></script>
	</head>
	<body>
		<div class="container">
			<div class="row">
				<a href="http://dh2016.adho.org"><img src="/static/images/logo_4.png" class="img-responsive"></a>
			</div>
			<div class="row">
				<ol class="breadcrumb">
					
						<li><a href="http://www.dh2016.adho.org">DH Home</a></li>
					
						<li><a href="/abstracts/">Abstracts</a></li>
					
						<li><a href="/abstracts/173">173</a></li>
					
				</ol>
			</div>
					
			
	<div class="row">
		<div class="col-lg-2">
		</div>
		<div class="col-lg-8 col-xs-12">
			<button class="btn btn-default" data-toggle="collapse" data-target="#head" style="margin-bottom: 5px;">Show info</button>
			<button class="btn btn-default" data-toggle="collapse" data-target="#cite" style="margin-bottom: 5px;">How to cite</button>
			<a href="/static/data/469.xml" class="btn btn-default" role="button" style="margin-bottom: 5px;" download="173.xml">XML Version</a>
			<div class="panel panel-success collapse" style="padding: 10px; border=none;" id="head">
				<div>
					<b>Title: </b>Significance Testing for the Classification of Literary Subgenres
					<br>
					<b>Authors: </b>
					Lena Hettinger, Fotis Jannidis, Isabella Reger, Andreas Hotho
					<br>
					<b>Category: </b>Paper:Long Paper
					<br>
					<b>Keywords: </b>subgenre classification, topic modelling, significance testing
				</div>
			</div>
			<div class="collapse" id="cite">
				<b>Hettinger, L., Jannidis, F., Reger, I., Hotho, A.</b> (2016). Significance Testing for the Classification of Literary Subgenres. In <i>Digital Humanities 2016: Conference Abstracts</i>. Jagiellonian University & Pedagogical University, Krak√≥w, 
				
					pp. 218-220.
				
			</div>
		</div>
		<div class="col-lg-2">
		</div>
	</div>
	<div class="row">
		<div class="col-lg-2">
		</div>
		<div class="col-lg-8">	
			<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8" /><!--THIS FILE IS GENERATED FROM AN XML MASTER. DO NOT EDIT (5)--><title>Significance Testing for the Classification of Literary Subgenres</title><meta name="author" content="Lena Hettinger , Fotis Jannidis , Isabella Reger , and Andreas Hotho" /><meta name="generator" content="Text Encoding Initiative Consortium XSLT stylesheets" /><meta name="DC.Title" content="Significance Testing for the Classification of Literary Subgenres" /><meta name="DC.Type" content="Text" /><meta name="DC.Format" content="text/html" /><link href="http://www.tei-c.org/release/xml/tei/stylesheet/tei.css" rel="stylesheet" type="text/css" /><link rel="stylesheet" media="print" type="text/css" href="http://www.tei-c.org/release/xml/tei/stylesheet/tei-print.css" /></head><body class="simple" id="TOP"><div class="stdheader autogenerated"><h1 class="maintitle">Significance Testing for the Classification of Literary Subgenres</h1></div><!--TEI front--><!--TEI body--><div class="DH-Heading1" id="index.xml-body.1_div.1"><h2 class="DH-Heading1"><span class="headingNumber">1. </span><span class="head">Introduction</span></h2><p>The automatic classification of literary genres, especially of novels, has become a research topic in the last years (Underwood, 2014; Jockers, 2013). In the following we report on the results from a series of experiments using features like most frequent words, character tetragrams and different amounts of topics (LDA) for genre classification on a corpus of German novels. Two problems will be in the main focus of this paper and they are both caused by the same factor: The small number of labeled novels. So how can experiments be designed and evaluated reliably in a setting like this. We are especially interested in testing results for significance to get a better understanding of the reliability of our research. While statistical significance testing is quite established in many disciplines ranging from psychology to medicine, it is unfortunately not yet standard in digital literary studies.</p><p>The scarcity of labeled data is also one of the reasons some researchers segment novels. We will show that without a test for significance it would be easy to misunderstand our results and we will also show that using segments of the same novel in the test and the training data leads to an overestimation of the predictive capabilities of the approach.</p></div><div class="DH-Heading1" id="h.v5r3hrqs5gxk"><h2 class="DH-Heading1"><span class="headingNumber">2. </span><span class="head">Setting</span></h2><p>In the following we will describe our corpus and feature sets. Our corpus consists of 628 German novels mainly from the 19th century obtained from sources like TextGrid Digital Library <span id="ftn1_return"><a class="notelink" title="textgrid.de/digitale-bibliothek" href="#ftn1"><sup>1</sup></a></span> or Projekt Gutenberg <span id="ftn2_return"><a class="notelink" title="gutenberg.spiegel.de" href="#ftn2"><sup>2</sup></a></span>. The novels have been manually labeled according to their subgenre after research in literary lexica and handbooks. The corpus contains 221 adventure novels, 57 social novels and 55 educational novels; the rest belongs to a different or more than one subgenre.</p><p>Features are extracted and normalized to a range of [0,1] based on the whole corpus consisting of 628 novels. We have tested several feature sets beforehand and found stylometric and topic based to be the most promising (c.f. Hettinger et al., 2015). To represent stylometric features we employ 3000 most frequent words (mfw3000) and top 1000 character tetragrams (4gram). Topic based features are created using Latent Dirichlet Allocation (LDA) by Blei et al. (2003). In literary texts topics sometimes represent themes, but more often they represent topoi, often used ways of telling a story or parts of it (see also Underwood, 2012; Rhody, 2012). For each novel we derive a topic distribution, i.e. we calculate how strongly each topic is associated with each novel. We try different topic numbers and build ten models for each setting to reduce the influence of randomness in LDA models. We remove a set of predefined stop words as well as Named Entities from the novels as we have shown before that the removal of Named Entities tends to improve results. </p></div><div class="DH-Heading1" id="h.h3q4c0oaksnc"><h2 class="DH-Heading1"><span class="headingNumber">3. </span><span class="head">Evaluation</span></h2><p>Classification is done by means of a linear Support Vector Machine (SVM) as we have already shown in Hettinger et al. (2015) that it works best in this setting (see also Yu, 2008). In each experiment we apply stratified 10-fold cross validation to the 333 labeled novels and report overall accuracy and F1-Score (c.f. Jockers, 2013). The majority vote (MV) baseline for our genre distribution yields an accuracy score of 0.66 and F1 score of 0.27 (see fig. 1). </p><div class="panel panel-default panel-figure"><img class="img-responsive" src="/static/data/469/image1.png" alt="Fig. 1: Cross table for majority vote baseline" class="inline" /><div class="caption">Fig. 1: Cross table for majority vote baseline</div></div><p>In the cross tables of Figure 1 and 2 each column represents the true class and each row the predicted genre. Correct assignments are shaded in grey, average accuracy in green and average F1 score in red. </p><div class="panel panel-default panel-figure"><img class="img-responsive" src="/static/data/469/image2.png" alt="Fig. 2: Cross table for mfw 3000 as an example for classification results" class="inline" /><div class="caption">Fig. 2: Cross table for mfw 3000 as an example for classification results</div></div><p>Because there are not many labeled novels for genre classification we expanded our corpus by splitting every novel into ten equal segments. Features are then constructed independently for the resulting 3330 novel segments. To test the influence of the LDA topic parameter <span style="font-style:italic">t</span> in conjunction with having more LDA documents we evaluate topic features for <span style="font-style:italic">t </span>=100, 200, 300, 400, 500 (see figure 3 and 4).</p><div class="panel panel-default panel-figure"><img class="img-responsive" src="/static/data/469/image3.png" alt="Fig. 3: Accuracy scores for novels and novel segments and different feature sets" class="inline" /><div class="caption">Fig. 3: Accuracy scores for novels and novel segments and different feature sets</div></div><div class="panel panel-default panel-figure"><img class="img-responsive" src="/static/data/469/image4.png" alt="Fig. 4: F1 scores for novels and novel segments and different feature sets" class="inline" /><div class="caption">Fig. 4: F1 scores for novels and novel segments and different feature sets</div></div><p>Results show that our evaluation metrics tend to drop if novels are segmented. This could mean that genre is indeed a label for the whole literary work and not parts of it. On the other hand many differences are pretty small. Therefore we would like to test if these differences are statistically significant or if they should be attributed to chance. </p></div><div class="DH-Heading1" id="h.uho96i5s80d"><h2 class="DH-Heading1"><span class="headingNumber">4. </span><span class="head">Tests of statistical significance </span></h2><p>When working with literary corpora there are few genre labels available for two reasons. First, the task of labeling the genre of a novel is strenuous; second, literary studies have mostly concentrated on a rather small sample, the canonical novels. Another issue is the creation of a balanced corpus, because for historical reasons the distribution of literary genres is not uniform and also the process of selecting novels for digitization has made the situation even more complicated. This generally results in data sets of less than 1000 items or even less than 100, see for example Jockers (2013) where 106 novels form a corpus or Hettinger et al. (2015) where we evaluate on only 32 novels. </p><p>The problem arising from small corpora is that small differences in results may originate from chance. This can be investigated by using statistical tests (c.f. Kenny, 2013; Nazar and S√°nchez Pol, 2006). A standard tool to detect if two data sets are significantly different is Student‚Äôs t-test which we will use in the following to control the results of our experiments.</p><p>We use two variations of Student‚Äôs t-test with <span style="font-style:italic">Œ±</span> = 0.05:</p><ul><li class="item">the one-sample t-test to compare the accuracy of a feature set against the baseline </li><li class="item">the two-sample t-test to compare accuracy results for two feature sets</li></ul><p>In both cases the data set considered consists of ten accuracy results from ten-fold cross validation and accordingly 100 data points for LDA from its ten models. Due to the small sample size we drop the assumption of equal variance for the two-sample t-test. The results for the one-sample t-tests show that every single feature set yields significantly better accuracy than the baseline (66.4%). We can therefore conclude that feature sets classify novels not randomly and that they do incorporate helpful genre clues. </p><div class="panel panel-default panel-figure"><img class="img-responsive" src="/static/data/469/image5.jpg" alt="Fig. 5: P-values for two sided t-test with = 0.05 on accuracy of genre classification using 333 German novels" class="inline" /><div class="caption">Fig. 5: P-values for two sided t-test with <span style="font-style:italic">Œ± </span>= 0.05 on accuracy of genre classification using 333 German novels</div></div><p>P-values for the two-sided t-tests are reported in Figure 5. Due to the large number of tests we apply Holm-Bonferroni correction; the resulting statistically significant outcomes are shaded in grey. From Figure 5 it follows that differences between segmented and not-segmented novels are <span style="font-weight:bold">not </span>statistically significant in most cases except for LDA with <span style="font-style:italic">t</span> = 100. Besides results do not differ significantly for different topic numbers <span style="font-style:italic">t</span> = 100, 200, 300, 400, 500.</p><p>An important assumption of the two-sample t-test is that both samples have to be independent. This is the case here as each time we do a cross validation we split the data independently from any other cross validation run. Thus, even if we repeat our experiments for a number of iterations (see e.g. Hettinger et al., 2015) we still get independent evaluation scenarios. Therefore we can apply the two-sided t-test in our setting to support our claims. In case of dependency of samples we could instead use paired t-tests on accuracy per novel. </p></div><div class="DH-Heading1" id="h.8ui9dtz3mgnn"><h2 class="DH-Heading1"><span class="headingNumber">5. </span><span class="head">Novel segmentation</span></h2><p>A crucial factor when segmenting novels is how to distribute the segments between test and training data set. We decided that in our case we have to put all of the ten segments a novel was divided into either in the test or in the training data set as we want to derive the genre of a novel not seen before. Another possibility which Jockers (2013) exploited is to distribute segments randomly between training and test set. In his work ‚ÄúMacroanalysis‚Äù Jockers investigates how function words can be used to research aspects of literary history like author, genre etc. In the following we want to replicate the part concerning genre prediction using German novels. </p><p>When segments of one novel appear in both test and training data we achieve an accuracy of 97.5% and F1 score of 95.9% - that is close to perfect (see fig. 6). Such a partitioning of the novels dramatically overestimates predictive performance on unseen texts. In comparison, Jockers (2013) achieves an average F1 score of 67% on twelve genre classes. His results are worse because we are only using three different genres while he is doing a multiclass classification with 12 classes. But nevertheless 67% probably still overestimates the real predictive power of this approach, because in our setup using the segments in both, test and training data, increased F1 by more than 17%.</p><div class="panel panel-default panel-figure"><img class="img-responsive" src="/static/data/469/image6.png" alt="Fig. 6: Results for different partitioning strategies" class="inline" /><div class="caption">Fig. 6: Results for different partitioning strategies</div></div></div><div class="DH-Heading1" id="h.75pj8ebi4kxq"><h2 class="DH-Heading1"><span class="headingNumber">6. </span><span class="head">Conclusion</span></h2><p>In this work we looked at the methodology and evaluation of genre classification of German novels and discussed some of the methodical pitfalls of working with data like this. We discovered that only some of our results turned out to be statistically significant whereas for example the statement, that stylometric perform better than topic-based features, could not be fortified. Therefore our opinion is that research findings on small data sets should be scrutinized especially carefully for example by using statistical tests. </p></div><!--TEI back--><div class="bibliogr" id="index.xml-back.1_div.1"><h2><span class="headingNumber"> </span></h2><div class="listhead">Bibliography</div><ol class="listBibl"><li id="index.xml-bibl-d30e387"><div class="biblfree"><span style="font-weight:bold">Blei, D., Ng, A. and Jordan, M.</span> (2003). Latent Dirichlet Allocation, <span style="font-style:italic">The Journal of Machine Learning Research</span>, <span style="font-weight:bold">3</span>: 993-1022.</div></li><li id="index.xml-bibl-d30e399"><div class="biblfree"><span style="font-weight:bold">Hettinger, L. et al.</span> (2015). Genre Classification on German Novels, <span style="font-style:italic">Proceedings of the 12th International Workshop on Text-based Information Retrieval,</span> Valencia, Spain.</div></li><li id="index.xml-bibl-d30e408"><div class="biblfree"><span style="font-weight:bold">Jockers, M. L.</span> (2013). <span style="font-style:italic">Macroanalysis: Digital Methods and Literary History</span>. Illinois: University of Illinois Press.</div></li><li id="index.xml-bibl-d30e417"><div class="biblfree"><span style="font-weight:bold">Kenny, A.</span> (1982). <span style="font-style:italic">The Computation of Style: An Introduction to Statistics for Students of Literature and Humanities</span>. New York: Elsevier.</div></li><li id="index.xml-bibl-d30e427"><div class="biblfree"><span style="font-weight:bold">Nazar, R. and S√°nchez Pol, M.</span> (2006). An Extremely Simple Authorship Attribution System, <span style="font-style:italic">Proceedings of the 2nd European IAFL Conference on Forensic Linguistics/Language and the Law</span>, Barcelona, Spain, 2006.</div></li><li id="index.xml-bibl-d30e436"><div class="biblfree"><span style="font-weight:bold">Rhody, L. M.</span> (2012). Topic Modeling and Figurative Language, <span style="font-style:italic">Journal of Digital Humanities</span>, <span style="font-weight:bold">2</span>(1). <a class="link_ref" href="http://journalofdigitalhumanities.org/2-1/">http://journalofdigitalhumanities.org/2-1/ </a> (accessed 1 November 2015).</div></li><li id="index.xml-bibl-d30e451"><div class="biblfree"><span style="font-weight:bold">Underwood, T.</span> (2012). Topic Modeling Made Just Simple Enough, <span style="font-style:italic">Blog post 7 April 2012</span>. <a class="link_ref" href="http://tedunderwood.com/2012/04/07/topic-modeling-made-just-simple-enough/">http://tedunderwood.com/2012/04/07/topic-modeling-made-just-simple-enough/ </a> (accessed 1 November 2015).</div></li><li id="index.xml-bibl-d30e463"><div class="biblfree"><span style="font-weight:bold">Underwood, T.</span> (2014). Understanding Genre in a Collection of a Million Volumes, <span style="font-style:italic">Interim Report</span>. <a class="link_ref" href="http://dx.doi.org/10.6084/m9.figshare.1281251">http://dx.doi.org/10.6084/m9.figshare.1281251</a> (accessed 26 August 2015).</div></li><li id="index.xml-bibl-d30e475"><div class="biblfree"><span style="font-weight:bold">Yu, B.</span>¬†(2008). An Evaluation of Text Classification Methods for Literary Study, <span style="font-style:italic">Literary and Linguistic Computing</span> <span style="font-weight:bold">23</span>: 327-43.</div></li></ol></div><!--Notes in [TEI]--><div class="notes"><div class="noteHeading">Notes</div><div class="note" id="ftn1"><span class="noteLabel">1. </span><div class="noteBody"><p>textgrid.de/digitale-bibliothek</p></div></div><div class="note" id="ftn2"><span class="noteLabel">2. </span><div class="noteBody"><p>gutenberg.spiegel.de</p></div></div></div></body></html>
		</div>
		<div class="col-lg-2">
		</div>
	</div>


		</div>
		<script>
		$(document).ready(function(){
			$('[data-toggle="tooltip"]').tooltip();
		});
		</script>			
	</body>
</html>