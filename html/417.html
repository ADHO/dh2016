<!DOCTYPE html>



<html lang="en">
	<head>
		<meta charset="utf-8">	
		<meta name="viewport" content="width=device-width, initial_scale=1">
		<title>DH 2016 Abstracts</title>
		<link rel="stylesheet" href="/static/bootstrap/css/bootstrap.min.css">
		<link rel="stylesheet" href="/static/bootstrap/css/bootstrap-theme.min.css">
		<link rel="stylesheet" href="/static/css/abstracts.css">
		<script src="/static/jquery/jquery-2.2.4.min.js"></script>
		<script src="/static/bootstrap/js/bootstrap.min.js"></script>
	</head>
	<body>
		<div class="container">
			<div class="row">
				<a href="http://dh2016.adho.org"><img src="/static/images/logo_4.png" class="img-responsive"></a>
			</div>
			<div class="row">
				<ol class="breadcrumb">
					
						<li><a href="http://www.dh2016.adho.org">DH Home</a></li>
					
						<li><a href="/abstracts/">Abstracts</a></li>
					
						<li><a href="/abstracts/417">417</a></li>
					
				</ol>
			</div>
					
			
	<div class="row">
		<div class="col-lg-2">
		</div>
		<div class="col-lg-8 col-xs-12">
			<button class="btn btn-default" data-toggle="collapse" data-target="#head" style="margin-bottom: 5px;">Show info</button>
			<button class="btn btn-default" data-toggle="collapse" data-target="#cite" style="margin-bottom: 5px;">How to cite</button>
			<a href="/static/data/312.xml" class="btn btn-default" role="button" style="margin-bottom: 5px;" download="417.xml">XML Version</a>
			<div class="panel panel-success collapse" style="padding: 10px; border=none;" id="head">
				<div>
					<b>Title: </b>OVAL: A Virtual Ecosystem for Immersive Scholarship and Teaching
					<br>
					<b>Authors: </b>
					Bill Endres, Matthew Cook, Will Kurlinkus
					<br>
					<b>Category: </b>Paper:Long Paper
					<br>
					<b>Keywords: </b>virtual reality, research, immersion, networked, teaching
				</div>
			</div>
			<div class="collapse" id="cite">
				<b>Endres, B., Cook, M., Kurlinkus, W.</b> (2016). OVAL: A Virtual Ecosystem for Immersive Scholarship and Teaching. In <i>Digital Humanities 2016: Conference Abstracts</i>. Jagiellonian University & Pedagogical University, Kraków, 
				
					pp. 186-188.
				
			</div>
		</div>
		<div class="col-lg-2">
		</div>
	</div>
	<div class="row">
		<div class="col-lg-2">
		</div>
		<div class="col-lg-8">	
			<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8" /><!--THIS FILE IS GENERATED FROM AN XML MASTER. DO NOT EDIT (5)--><title>OVAL: A Virtual Ecosystem for Immersive Scholarship and Teaching</title><meta name="author" content="Bill Endres , Matthew Cook and Will Kurlinkus" /><meta name="generator" content="Text Encoding Initiative Consortium XSLT stylesheets" /><meta name="DC.Title" content="OVAL: A Virtual Ecosystem for Immersive Scholarship and Teaching" /><meta name="DC.Type" content="Text" /><meta name="DC.Format" content="text/html" /><link href="http://www.tei-c.org/release/xml/tei/stylesheet/tei.css" rel="stylesheet" type="text/css" /><link rel="stylesheet" media="print" type="text/css" href="http://www.tei-c.org/release/xml/tei/stylesheet/tei-print.css" /></head><body class="simple" id="TOP"><div class="stdheader autogenerated"><h1 class="maintitle">OVAL: A Virtual Ecosystem for Immersive Scholarship and Teaching</h1></div><!--TEI front--><!--TEI body--><div class="DH-Heading1" id="index.xml-body.1_div.1"><h2 class="DH-Heading1"><span class="headingNumber">1. </span><span class="head">Introduction </span></h2><p>3D modeling is transforming scholarship and teaching. In 2004, when Taliban militia destroyed the Buddhas of Bamiyan (one, the tallest Buddha in the world), a team of researchers from the Swiss Federal Institute of Technology responded by generating 3D models of these lost Buddhas (Grün et al., 2004). Indeed, 3D and virtual reality (VR) have sparked scholarly interest because VR projects, such as the Buddhas and Rome Reborn (an international effort to generate a virtual surrogate of the ancient city), allow for the modeling of inaccessible or lost historic spaces and objects and the interactive testing of scholarly hypotheses (Dylla et al., 2010). </p><p>Now, with advances in digital imaging and replication, 3D models have proliferated. They can be easily downloaded from sites such as SketchFab, Smithsonian X3D, and NASA 3D Resources. Moreover, scholars can publish them in a new journal: <span style="font-style:italic">Digital Applications in Archaeology and Cultural Heritage</span>. However, this proliferation raises questions about best practices for viewing, archiving, and interacting with these complex digital assets. The primary interface for 3D remains the flat, relatively small, computer screen—miniscule when compared to a 53-meter Buddha.</p><p>One solution is to provide an immersive experience through VR, enabling viewers to share space with 3D artifacts. Such an interface, however, presents further problems. VR systems tend to follow one of two models: 1. The model of Rome Reborn, in which a virtual system houses one surrogate of a physical space, or 2. A laboratory, such as Stanford University’s CAVE system, in which sophisticated and costly VR equipment is employed for research. Can a virtual ecosystem be developed that not only makes uploading, hosting, and viewing VR assets easy but also is cost efficient and yet provides a robust, flexible, and accessible environment to meet divergent needs across a university and beyond?</p><p>In this presentation, we will discuss our answers to these questions derived from building a VR ecosystem housed in the library of the University of Oklahoma: the Oklahoma Virtual Academic Laboratory (OVAL). OVAL is a fully functioning VR environment. It is designed to deliver ease in uploading and engaging 3D assets, especially for non-technical users. Through digital immersion, multiple scholars and students simultaneously encounter VR assets, moving through and around and rotating and resizing them. Such engagement represents a paradigmatic shift in the computer interface: scholars and students are no longer limited by a flat monitor and instead share the virtual space with their objects of study. </p><p>Furthermore, OVAL encourages enhanced experiential learning (Hermon and Kalisperis, 2011; 60-61). It gives students and scholars opportunities to engage digital materials beyond their normal reach (such as interacting with atomic structures or cultural heritage artifacts). And, when partnered with museums, medical centers and other stakeholders, OVAL makes VR accessible to a wide scope of people, institutions, and industries. Thereby, OVAL offers a new model of accessible VR. </p></div><div class="DH-Heading1" id="index.xml-body.1_div.2"><h2 class="DH-Heading1"><span class="headingNumber">2. </span><span class="head">Challenges</span></h2><p>Building a VR ecosystem for a whole university poses daunting challenges. For OVAL, the overriding hurdle was cost. To accommodate scholars and students across the disciplines, building multiple, multi-million dollar VR labs was not feasible. Therefore, cost constantly reigned-in decisions but rarely reigned-in performance. </p><p>There were also challenges for choosing compatible hardware and software. To keep costs reasonable and minimize spatial requirements, we opted to have users seated while immersed in OVAL, with head, upper body, and hands tracked and imported into the VR environment. This reduces major challenges to selecting a software platform to develop the VR environment, graphics processing unit (GPU), head mounted display (and its software), hand-gesture sensor (and its software), computer, and chair assembly. When full-body sensing hardware and software become available at a reasonable price, we will explore incorporating them into OVAL. </p><p>For building the VR environment, perhaps the most important choice is selecting the software platform. Currently, game engines (software platforms for generating 2D and immersive 3D environments) are the best option. To select an appropriate game engine, we established five criteria:</p><ol><li class="item">Minimally priced or free during development of VR environment</li><li class="item">Compatible with multiple platforms, including desktop, mobile, and Web</li><li class="item">Compatible with multiple headsets, such as Oculus Rift, HTC Vive, Google Cardboard, Gear VR, and Microsoft HoloLens</li><li class="item">Active and robust developer community</li><li class="item">Extensive online documentation</li></ol></div><div class="DH-Heading1" id="index.xml-body.1_div.3"><h2 class="DH-Heading1"><span class="headingNumber">3. </span><span class="head">Our solution</span></h2><p>Our criteria limited our choices to two main video game engines: Unity3D and Unreal. Although, since our initial choice, a number of major companies (Google, Amazon, etc.) have developed game engines, we still champion Unity3D because of its low cost and robust developer community, which attests to its capability and compatibility. Part of Unity3D’s appeal is one of our main criteria: strong cross-platform compatible. Currently, it is compatible with 21 different operating systems, including Apple, Windows, Linux, and a variety of mobile devices. Furthermore, Unity3D provides strong online documentation, including tutorials. </p><p>For software sub-systems, choices had their complexities, and we will discuss them more fully in the presentation. They included Photon Unity Networking for networking the headsets; Oculus runtime software to support a camera with two “eyes”; and the LeapMotion SDK for hand-tracked interactions. These choices allow OVAL to preserve embodied interaction with hand and upper body tracking (leaning in produces a closer look at an object, and hand movements control features such as scaling and rotating objects) (Shapiro, 2014).</p><p>Selecting hardware was less complicated. Available headsets are surprisingly limited. Our only real choice was Oculus Rift. Another headset, the HTC Vive, is set for release soon. Most headsets are developed and sold as part of a complete VR system. </p><p>For the chair-assembly, a unique on-campus resource simplified our choice. The University of Oklahoma houses a high-powered physics fabrication lab. We worked with them to develop a custom railed-chair assembly (ergonomically designed for a 360° range of motion). This railed-chair allows the computer to reside under the chair and out of the way. For a robust virtual environment, the computer contains a GeForce GTX 980 graphics card. It delivers a 75-frames/second refresh-rate (the human eye generally resolves 25 frames/second), insuring an instantaneous visual experience when manipulating 3D objects or when turning one’s head. </p><p>Finally, by integrating networking software into OVAL, a shared VR experience can occur across a range of clients. All changes made on a master workstation—including scale, rotation, lighting, and background imagery—are immediately transmitted to all co-participants, regardless of their physical location. In a classroom environment, for example, this means that students automatically see what the teacher sees. But this also allows OVAL to become a worldwide network. To facilitate such a network, all 3D models are uploaded via a public Dropbox, which immediately syncs with all OVAL clients. This means that all uploaded 3D asset are available to all OVAL clients. For a shared VR experience, each client only needs a short set of instructions concerning file names and how to manipulate them during a session. </p></div><div class="DH-Heading1" id="index.xml-body.1_div.4"><h2 class="DH-Heading1"><span class="headingNumber">4. </span><span class="head">Research and teaching</span></h2><p>In our presentation, we will also discuss ongoing uses of OVAL at the University of Oklahoma and explore their implications. Despite its recent completion, OVAL has already had extensive use. Undergraduate biology students have analyzed the atomic structure of hemoglobin and oxyhemoglobin. Architecture faculty has analyzed student projects for unseen flaws pertaining to safety and accessibility of interior spaces. The Sam Noble Museum of Natural History has uploaded their recently discovered <span style="font-style:italic">Aquilops Americanus </span>skull into the OVAL system for curators and researchers. Art History faculty has begun analyzing sculpturally significant 3D scans for preserving what was once ephemeral art. A budding partnership with the Medical Imaging Facility has demonstrated how CT-to-OVAL workflows facilitate mammographic research. Finally, Bill Endres has begun to develop guided, immersive tours of the St Chad Gospels, an 8 <sup>th</sup>-century illuminated manuscript.</p></div><div class="DH-Heading1" id="index.xml-body.1_div.5"><h2 class="DH-Heading1"><span class="headingNumber">5. </span><span class="head">Conclusion </span></h2><p>The rapid production of 3D models makes having VR systems available for their viewing a pressing concern. 3D models of massive structures, such as the large Buddhas of Bamiyan, highlight the limitations of interacting through a computer screen. OVAL provides one cost-efficient solution. In our next phase, we plan to add collaborators and make OVAL available. We are also interested in hosting 3D assets in an archive-quality database. However, the most effective and efficient means of doing these has yet to be determined. We are looking forward to presenting at DH 2016 and conversing about possibilities for OVAL and the wide-ranging opportunities for research and teaching through VR.</p></div><!--TEI back--><div class="bibliogr" id="index.xml-back.1_div.1"><h2><span class="headingNumber"> </span></h2><div class="listhead">Bibliography</div><ol class="listBibl"><li id="index.xml-bibl-d30e286"><div class="biblfree"><span style="font-weight:bold">Dylla, K., et al.</span> (2010). Rome Reborn 2.0: A Case Study of Virtual City Reconstruction Using Procedural Modeling Techniques. Frischer, B., Crawford, J. and Koller, D. (eds), <span style="font-style:italic">Making History Interactive: 37</span> <sup style="font-style:italic">th</sup> <span style="font-style:italic">Proceedings of the CAA Conference</span>, Williamsburg, VA, March 2009. Oxford: Archaeopress, pp. 62-66.</div></li><li id="index.xml-bibl-d30e301"><div class="biblfree"><span style="font-weight:bold">Grün, A., Remondino, F. and Zhang, L.</span> (2004). Photogrametric Reconsctruction of the Great Buddha of Bamiyan, Afghanistan. <span style="font-style:italic">The Photogrammetric Record,</span> <span style="font-weight:bold">19</span>(107): 177-99.</div></li><li id="index.xml-bibl-d30e313"><div class="biblfree"><span style="font-weight:bold">Hermon, S. and Kalisperis, L.</span> (2011). Between the Real and the Virtual: 3D Visualization in the Cultural Heritage Domain – Expectations and Prospects. <span style="font-style:italic">Virtual Archaeology Review,</span> <span style="font-weight:bold">2</span>(4): 59-63.</div></li><li id="index.xml-bibl-d30e325"><div class="biblfree"><span style="font-weight:bold">Shapiro, L. </span>(ed) (2014). <span style="font-style:italic">The Routledge Handbook of Embodied Cognition</span>. New York: Routledge.</div></li></ol></div></body></html>
		</div>
		<div class="col-lg-2">
		</div>
	</div>


		</div>
		<script>
		$(document).ready(function(){
			$('[data-toggle="tooltip"]').tooltip();
		});
		</script>			
	</body>
</html>